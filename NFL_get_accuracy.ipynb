{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 110,
   "metadata": {},
   "outputs": [],
   "source": [
    "# probably going to have to install this if you haven't already\n",
    "from sportsreference.nfl.boxscore import Boxscores, Boxscore\n",
    "\n",
    "# the usual imports\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "# for models\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.metrics import accuracy_score\n",
    "from sklearn.preprocessing import StandardScaler,OneHotEncoder\n",
    "\n",
    "import tensorflow as tf\n",
    "from tensorflow.keras.layers import Dense\n",
    "from tensorflow.keras.models import Sequential\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "pd.set_option('display.max_columns', None)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 247,
   "metadata": {},
   "outputs": [],
   "source": [
    "# The game_Data function is extracting game statistics for each game. It loops through each game and each week grabbing the statistics referenced.\n",
    "# This function creates the foundation for our final dataset.\n",
    "def game_data(game_df,game_stats):\n",
    "    try:\n",
    "        # Creates a dataframe for the away_team and the home_team. Sets column names to be exact matches between the two.\n",
    "        away_team_df = game_df[['away_name', 'away_abbr', 'away_score']].rename(columns = {'away_name': 'team_name', 'away_abbr': 'team_abbr', 'away_score': 'score'})\n",
    "        home_team_df = game_df[['home_name','home_abbr', 'home_score']].rename(columns = {'home_name': 'team_name', 'home_abbr': 'team_abbr', 'home_score': 'score'})\n",
    "        try:\n",
    "            if game_df.loc[0,'away_score'] > game_df.loc[0,'home_score']:\n",
    "                away_team_df = pd.merge(away_team_df, pd.DataFrame({'game_won' : [1], 'game_lost' : [0]}),left_index = True, right_index = True)\n",
    "                home_team_df = pd.merge(home_team_df, pd.DataFrame({'game_won' : [0], 'game_lost' : [1]}),left_index = True, right_index = True)\n",
    "            elif game_df.loc[0,'away_score'] < game_df.loc[0,'home_score']:\n",
    "                away_team_df = pd.merge(away_team_df, pd.DataFrame({'game_won' : [0], 'game_lost' : [1]}),left_index = True, right_index = True)\n",
    "                home_team_df = pd.merge(home_team_df, pd.DataFrame({'game_won' : [1], 'game_lost' : [0]}),left_index = True, right_index = True)\n",
    "            else: \n",
    "                away_team_df = pd.merge(away_team_df, pd.DataFrame({'game_won' : [0], 'game_lost' : [0]}),left_index = True, right_index = True)\n",
    "                home_team_df = pd.merge(home_team_df, pd.DataFrame({'game_won' : [0], 'game_lost' : [0]}),left_index = True, right_index = True)\n",
    "        except TypeError:\n",
    "                away_team_df = pd.merge(away_team_df, pd.DataFrame({'game_won' : [np.nan], 'game_lost' : [np.nan]}),left_index = True, right_index = True)\n",
    "                home_team_df = pd.merge(home_team_df, pd.DataFrame({'game_won' : [np.nan], 'game_lost' : [np.nan]}),left_index = True, right_index = True)        \n",
    "\n",
    "        # Creating the away_team & home_team stats dataframe. Grabbing the selected stats and then renaming them to match home == away dataframe column names.\n",
    "        away_stats_df = game_stats.dataframe[['away_first_downs', 'away_fourth_down_attempts',\n",
    "               'away_fourth_down_conversions', 'away_fumbles', 'away_fumbles_lost',\n",
    "               'away_interceptions', 'away_net_pass_yards', 'away_pass_attempts',\n",
    "               'away_pass_completions', 'away_pass_touchdowns', 'away_pass_yards',\n",
    "               'away_penalties', 'away_points', 'away_rush_attempts',\n",
    "               'away_rush_touchdowns', 'away_rush_yards', 'away_third_down_attempts',\n",
    "               'away_third_down_conversions', 'away_time_of_possession',\n",
    "               'away_times_sacked', 'away_total_yards', 'away_turnovers',\n",
    "               'away_yards_from_penalties', 'away_yards_lost_from_sacks']].reset_index().drop(columns ='index').rename(columns = {\n",
    "               'away_first_downs': 'first_downs', 'away_fourth_down_attempts':'fourth_down_attempts',\n",
    "               'away_fourth_down_conversions':'fourth_down_conversions' , 'away_fumbles': 'fumbles', 'away_fumbles_lost': 'fumbles_lost',\n",
    "               'away_interceptions': 'interceptions', 'away_net_pass_yards':'net_pass_yards' , 'away_pass_attempts': 'pass_attempts',\n",
    "               'away_pass_completions':'pass_completions' , 'away_pass_touchdowns': 'pass_touchdowns', 'away_pass_yards': 'pass_yards',\n",
    "               'away_penalties': 'penalties', 'away_points': 'points', 'away_rush_attempts': 'rush_attempts',\n",
    "               'away_rush_touchdowns': 'rush_touchdowns', 'away_rush_yards': 'rush_yards', 'away_third_down_attempts': 'third_down_attempts',\n",
    "               'away_third_down_conversions': 'third_down_conversions', 'away_time_of_possession': 'time_of_possession',\n",
    "               'away_times_sacked': 'times_sacked', 'away_total_yards': 'total_yards', 'away_turnovers': 'turnovers',\n",
    "               'away_yards_from_penalties':'yards_from_penalties', 'away_yards_lost_from_sacks': 'yards_lost_from_sacks'})\n",
    "\n",
    "        home_stats_df = game_stats.dataframe[['home_first_downs', 'home_fourth_down_attempts',\n",
    "               'home_fourth_down_conversions', 'home_fumbles', 'home_fumbles_lost',\n",
    "               'home_interceptions', 'home_net_pass_yards', 'home_pass_attempts',\n",
    "               'home_pass_completions', 'home_pass_touchdowns', 'home_pass_yards',\n",
    "               'home_penalties', 'home_points', 'home_rush_attempts',\n",
    "               'home_rush_touchdowns', 'home_rush_yards', 'home_third_down_attempts',\n",
    "               'home_third_down_conversions', 'home_time_of_possession',\n",
    "               'home_times_sacked', 'home_total_yards', 'home_turnovers',\n",
    "               'home_yards_from_penalties', 'home_yards_lost_from_sacks']].reset_index().drop(columns = 'index').rename(columns = {\n",
    "               'home_first_downs': 'first_downs', 'home_fourth_down_attempts':'fourth_down_attempts',\n",
    "               'home_fourth_down_conversions':'fourth_down_conversions' , 'home_fumbles': 'fumbles', 'home_fumbles_lost': 'fumbles_lost',\n",
    "               'home_interceptions': 'interceptions', 'home_net_pass_yards':'net_pass_yards' , 'home_pass_attempts': 'pass_attempts',\n",
    "               'home_pass_completions':'pass_completions' , 'home_pass_touchdowns': 'pass_touchdowns', 'home_pass_yards': 'pass_yards',\n",
    "               'home_penalties': 'penalties', 'home_points': 'points', 'home_rush_attempts': 'rush_attempts',\n",
    "               'home_rush_touchdowns': 'rush_touchdowns', 'home_rush_yards': 'rush_yards', 'home_third_down_attempts': 'third_down_attempts',\n",
    "               'home_third_down_conversions': 'third_down_conversions', 'home_time_of_possession': 'time_of_possession',\n",
    "               'home_times_sacked': 'times_sacked', 'home_total_yards': 'total_yards', 'home_turnovers': 'turnovers',\n",
    "               'home_yards_from_penalties':'yards_from_penalties', 'home_yards_lost_from_sacks': 'yards_lost_from_sacks'})\n",
    "        \n",
    "        # Merge the team_df & stats_df for both home & away teams. Set the left_index & right_index to True so that both dataframes merge on the same indices. \n",
    "        away_team_df = pd.merge(away_team_df, away_stats_df,left_index = True, right_index = True)\n",
    "        home_team_df = pd.merge(home_team_df, home_stats_df,left_index = True, right_index = True)\n",
    "        try:\n",
    "            # Converting time_of_possession from MM:SS format into seconds(int). \n",
    "            away_team_df['time_of_possession'] = (int(away_team_df['time_of_possession'].loc[0][0:2]) * 60) + int(away_team_df['time_of_possession'].loc[0][3:5])\n",
    "            home_team_df['time_of_possession'] = (int(home_team_df['time_of_possession'].loc[0][0:2]) * 60) + int(home_team_df['time_of_possession'].loc[0][3:5])\n",
    "        except TypeError:\n",
    "            away_team_df['time_of_possession'] = np.nan\n",
    "            home_team_df['time_of_possession'] = np.nan\n",
    "    except TypeError:\n",
    "        away_team_df = pd.DataFrame()\n",
    "        home_team_df = pd.DataFrame()\n",
    "    return away_team_df, home_team_df\n",
    "\n",
    "def game_data_up_to_week(weeks,year):\n",
    "    weeks_games_df = pd.DataFrame()\n",
    "    for w in range(len(weeks)):\n",
    "        date_string = str(weeks[w]) + '-' + str(year)\n",
    "        week_scores = Boxscores(weeks[w],year)\n",
    "        week_games_df = pd.DataFrame()\n",
    "        for g in range(len(week_scores.games[date_string])):\n",
    "            game_str = week_scores.games[date_string][g]['boxscore']\n",
    "            game_stats = Boxscore(game_str)\n",
    "            game_df = pd.DataFrame(week_scores.games[date_string][g], index = [0])\n",
    "            away_team_df, home_team_df = game_data(game_df,game_stats)\n",
    "            away_team_df['week'] = weeks[w]\n",
    "            home_team_df['week'] = weeks[w]\n",
    "            week_games_df = pd.concat([week_games_df,away_team_df])\n",
    "            week_games_df = pd.concat([week_games_df,home_team_df])\n",
    "        weeks_games_df = pd.concat([weeks_games_df,week_games_df])\n",
    "    return weeks_games_df\n",
    "\n",
    "def get_schedule(year):\n",
    "    weeks = list(range(1,18))\n",
    "    schedule_df = pd.DataFrame()\n",
    "    for w in range(len(weeks)):\n",
    "        date_string = str(weeks[w]) + '-' + str(year)\n",
    "        week_scores = Boxscores(weeks[w],year)\n",
    "        week_games_df = pd.DataFrame()\n",
    "        for g in range(len(week_scores.games[date_string])):\n",
    "            game = pd.DataFrame(week_scores.games[date_string][g], index = [0])[['away_name', 'away_abbr','home_name', 'home_abbr','winning_name', 'winning_abbr' ]]\n",
    "            game['week'] = weeks[w]\n",
    "            week_games_df = pd.concat([week_games_df,game])\n",
    "        schedule_df = pd.concat([schedule_df, week_games_df]).reset_index().drop(columns = 'index') \n",
    "    return schedule_df \n",
    "\n",
    "def agg_weekly_data(schedule_df,weeks_games_df,current_week,weeks):\n",
    "    schedule_df = schedule_df[schedule_df.week < current_week]\n",
    "    agg_games_df = pd.DataFrame()\n",
    "    for w in range(1,len(weeks)):\n",
    "        games_df = schedule_df[schedule_df.week == weeks[w]]\n",
    "        agg_weekly_df = weeks_games_df[weeks_games_df.week < weeks[w]].drop(columns = ['score','week','game_won', 'game_lost']).groupby(by=[\"team_name\", \"team_abbr\"]).mean().reset_index()\n",
    "        win_loss_df = weeks_games_df[weeks_games_df.week < weeks[w]][[\"team_name\", \"team_abbr\",'game_won', 'game_lost']].groupby(by=[\"team_name\", \"team_abbr\"]).sum().reset_index()\n",
    "        win_loss_df['win_perc'] = win_loss_df['game_won'] / (win_loss_df['game_won'] + win_loss_df['game_lost'])\n",
    "        win_loss_df = win_loss_df.drop(columns = ['game_won', 'game_lost'])\n",
    "\n",
    "        try:\n",
    "            agg_weekly_df['fourth_down_perc'] = agg_weekly_df['fourth_down_conversions'] / agg_weekly_df['fourth_down_attempts']  \n",
    "        except ZeroDivisionError:\n",
    "            agg_weekly_df['fourth_down_perc'] = 0 \n",
    "        agg_weekly_df['fourth_down_perc'] = agg_weekly_df['fourth_down_perc'].fillna(0)\n",
    "\n",
    "        try:\n",
    "            agg_weekly_df['third_down_perc'] = agg_weekly_df['third_down_conversions'] / agg_weekly_df['third_down_attempts']  \n",
    "        except ZeroDivisionError:\n",
    "            agg_weekly_df['third_down_perc'] = 0\n",
    "        agg_weekly_df['third_down_perc'] = agg_weekly_df['third_down_perc'].fillna(0)  \n",
    "\n",
    "        agg_weekly_df = agg_weekly_df.drop(columns = ['fourth_down_attempts', 'fourth_down_conversions', 'third_down_attempts', 'third_down_conversions'])\n",
    "        agg_weekly_df = pd.merge(win_loss_df,agg_weekly_df,left_on = ['team_name', 'team_abbr'], right_on = ['team_name', 'team_abbr'])\n",
    "\n",
    "        away_df = pd.merge(games_df,agg_weekly_df,how = 'inner', left_on = ['away_name', 'away_abbr'], right_on = ['team_name', 'team_abbr']).drop(columns = ['team_name', 'team_abbr']).rename(columns = {\n",
    "                'win_perc': 'away_win_perc',\n",
    "               'first_downs': 'away_first_downs', 'fumbles': 'away_fumbles', 'fumbles_lost':'away_fumbles_lost', 'interceptions':'away_interceptions',\n",
    "               'net_pass_yards': 'away_net_pass_yards', 'pass_attempts':'away_pass_attempts', 'pass_completions':'away_pass_completions',\n",
    "               'pass_touchdowns':'away_pass_touchdowns', 'pass_yards':'away_pass_yards', 'penalties':'away_penalties', 'points':'away_points', 'rush_attempts':'away_rush_attempts',\n",
    "               'rush_touchdowns':'away_rush_touchdowns', 'rush_yards':'away_rush_yards', 'time_of_possession':'away_time_of_possession', 'times_sacked':'away_times_sacked',\n",
    "               'total_yards':'away_total_yards', 'turnovers':'away_turnovers', 'yards_from_penalties':'away_yards_from_penalties',\n",
    "               'yards_lost_from_sacks': 'away_yards_lost_from_sacks', 'fourth_down_perc':'away_fourth_down_perc', 'third_down_perc':'away_third_down_perc'})\n",
    "\n",
    "        home_df = pd.merge(games_df,agg_weekly_df,how = 'inner', left_on = ['home_name', 'home_abbr'], right_on = ['team_name', 'team_abbr']).drop(columns = ['team_name', 'team_abbr']).rename(columns = {\n",
    "                'win_perc': 'home_win_perc',\n",
    "               'first_downs': 'home_first_downs', 'fumbles': 'home_fumbles', 'fumbles_lost':'home_fumbles_lost', 'interceptions':'home_interceptions',\n",
    "               'net_pass_yards': 'home_net_pass_yards', 'pass_attempts':'home_pass_attempts', 'pass_completions':'home_pass_completions',\n",
    "               'pass_touchdowns':'home_pass_touchdowns', 'pass_yards':'home_pass_yards', 'penalties':'home_penalties', 'points':'home_points', 'rush_attempts':'home_rush_attempts',\n",
    "               'rush_touchdowns':'home_rush_touchdowns', 'rush_yards':'home_rush_yards', 'time_of_possession':'home_time_of_possession', 'times_sacked':'home_times_sacked',\n",
    "               'total_yards':'home_total_yards', 'turnovers':'home_turnovers', 'yards_from_penalties':'home_yards_from_penalties',\n",
    "               'yards_lost_from_sacks': 'home_yards_lost_from_sacks', 'fourth_down_perc':'home_fourth_down_perc', 'third_down_perc':'home_third_down_perc'})\n",
    "\n",
    "        agg_weekly_df = pd.merge(away_df,home_df,left_on = ['away_name', 'away_abbr', 'home_name', 'home_abbr', 'winning_name',\n",
    "               'winning_abbr', 'week'], right_on = ['away_name', 'away_abbr', 'home_name', 'home_abbr', 'winning_name',\n",
    "               'winning_abbr', 'week'])\n",
    "\n",
    "        agg_weekly_df['win_perc_dif'] = agg_weekly_df['away_win_perc'] - agg_weekly_df['home_win_perc']\n",
    "        agg_weekly_df['first_downs_dif'] = agg_weekly_df['away_first_downs'] - agg_weekly_df['home_first_downs']\n",
    "        agg_weekly_df['fumbles_dif'] = agg_weekly_df['away_fumbles'] - agg_weekly_df['home_fumbles']\n",
    "        agg_weekly_df['interceptions_dif'] = agg_weekly_df['away_interceptions'] - agg_weekly_df['home_interceptions']\n",
    "        agg_weekly_df['net_pass_yards_dif'] = agg_weekly_df['away_net_pass_yards'] - agg_weekly_df['home_net_pass_yards']\n",
    "        agg_weekly_df['pass_attempts_dif'] = agg_weekly_df['away_pass_attempts'] - agg_weekly_df['home_pass_attempts']\n",
    "        agg_weekly_df['pass_completions_dif'] = agg_weekly_df['away_pass_completions'] - agg_weekly_df['home_pass_completions']\n",
    "        agg_weekly_df['pass_touchdowns_dif'] = agg_weekly_df['away_pass_touchdowns'] - agg_weekly_df['home_pass_touchdowns']\n",
    "        agg_weekly_df['pass_yards_dif'] = agg_weekly_df['away_pass_yards'] - agg_weekly_df['home_pass_yards']\n",
    "        agg_weekly_df['penalties_dif'] = agg_weekly_df['away_penalties'] - agg_weekly_df['home_penalties']\n",
    "        agg_weekly_df['points_dif'] = agg_weekly_df['away_points'] - agg_weekly_df['home_points']\n",
    "        agg_weekly_df['rush_attempts_dif'] = agg_weekly_df['away_rush_attempts'] - agg_weekly_df['home_rush_attempts']\n",
    "        agg_weekly_df['rush_touchdowns_dif'] = agg_weekly_df['away_rush_touchdowns'] - agg_weekly_df['home_rush_touchdowns']\n",
    "        agg_weekly_df['rush_yards_dif'] = agg_weekly_df['away_rush_yards'] - agg_weekly_df['home_rush_yards']\n",
    "        agg_weekly_df['time_of_possession_dif'] = agg_weekly_df['away_time_of_possession'] - agg_weekly_df['home_time_of_possession']\n",
    "        agg_weekly_df['times_sacked_dif'] = agg_weekly_df['away_times_sacked'] - agg_weekly_df['home_times_sacked']\n",
    "        agg_weekly_df['total_yards_dif'] = agg_weekly_df['away_total_yards'] - agg_weekly_df['home_total_yards']\n",
    "        agg_weekly_df['turnovers_dif'] = agg_weekly_df['away_turnovers'] - agg_weekly_df['home_turnovers']\n",
    "        agg_weekly_df['yards_from_penalties_dif'] = agg_weekly_df['away_yards_from_penalties'] - agg_weekly_df['home_yards_from_penalties']\n",
    "        agg_weekly_df['yards_lost_from_sacks_dif'] = agg_weekly_df['away_yards_lost_from_sacks'] - agg_weekly_df['home_yards_lost_from_sacks']\n",
    "        agg_weekly_df['fourth_down_perc_dif'] = agg_weekly_df['away_fourth_down_perc'] - agg_weekly_df['home_fourth_down_perc']\n",
    "        agg_weekly_df['third_down_perc_dif'] = agg_weekly_df['away_third_down_perc'] - agg_weekly_df['home_third_down_perc']\n",
    "\n",
    "        agg_weekly_df = agg_weekly_df.drop(columns = ['away_win_perc',\n",
    "               'away_first_downs', 'away_fumbles', 'away_fumbles_lost', 'away_interceptions',\n",
    "               'away_net_pass_yards', 'away_pass_attempts','away_pass_completions',\n",
    "               'away_pass_touchdowns', 'away_pass_yards', 'away_penalties', 'away_points', 'away_rush_attempts',\n",
    "               'away_rush_touchdowns', 'away_rush_yards', 'away_time_of_possession', 'away_times_sacked',\n",
    "               'away_total_yards', 'away_turnovers', 'away_yards_from_penalties',\n",
    "               'away_yards_lost_from_sacks','away_fourth_down_perc', 'away_third_down_perc','home_win_perc',\n",
    "               'home_first_downs', 'home_fumbles', 'home_fumbles_lost', 'home_interceptions',\n",
    "               'home_net_pass_yards', 'home_pass_attempts','home_pass_completions',\n",
    "               'home_pass_touchdowns', 'home_pass_yards', 'home_penalties', 'home_points', 'home_rush_attempts',\n",
    "               'home_rush_touchdowns', 'home_rush_yards', 'home_time_of_possession', 'home_times_sacked',\n",
    "               'home_total_yards', 'home_turnovers', 'home_yards_from_penalties',\n",
    "               'home_yards_lost_from_sacks','home_fourth_down_perc', 'home_third_down_perc'])\n",
    "        \n",
    "        if (agg_weekly_df['winning_name'].isnull().values.any() and weeks[w] > 3):\n",
    "            agg_weekly_df['result'] = np.nan\n",
    "            print(f\"Week {weeks[w]} games have not finished yet.\")\n",
    "        else:\n",
    "            agg_weekly_df['result'] = agg_weekly_df['winning_name'] == agg_weekly_df['away_name']\n",
    "            agg_weekly_df['result'] = agg_weekly_df['result'].astype('float')\n",
    "        agg_weekly_df = agg_weekly_df.drop(columns = ['winning_name', 'winning_abbr'])\n",
    "        agg_games_df = pd.concat([agg_games_df, agg_weekly_df])\n",
    "    agg_games_df = agg_games_df.reset_index().drop(columns = 'index')\n",
    "    # What is .drop(index = 20) doing?\n",
    "    agg_games_df = agg_games_df.drop(index = 20, axis=0)\n",
    "    return agg_games_df\n",
    "\n",
    "def get_elo():\n",
    "    elo_df = pd.read_csv('https://projects.fivethirtyeight.com/nfl-api/nfl_elo_latest.csv')\n",
    "    elo_df = elo_df.drop(columns = ['season','neutral' ,'playoff', 'elo_prob1', 'elo_prob2', 'elo1_post', 'elo2_post',\n",
    "           'qbelo1_pre', 'qbelo2_pre', 'qb1', 'qb2', 'qb1_adj', 'qb2_adj', 'qbelo_prob1', 'qbelo_prob2',\n",
    "           'qb1_game_value', 'qb2_game_value', 'qb1_value_post', 'qb2_value_post',\n",
    "           'qbelo1_post', 'qbelo2_post', 'score1', 'score2', 'quality', 'importance', 'total_rating'])\n",
    "    elo_df.date = pd.to_datetime(elo_df.date)\n",
    "    elo_df = elo_df[elo_df.date < '01-05-2022']\n",
    "\n",
    "    elo_df['team1'] = elo_df['team1'].replace(['KC', 'JAX', 'CAR', 'BAL', 'BUF', 'MIN', 'DET', 'ATL', 'NE', 'WSH',\n",
    "           'CIN', 'NO', 'SF', 'LAR', 'NYG', 'DEN', 'CLE', 'IND', 'TEN', 'NYJ',\n",
    "           'TB', 'MIA', 'PIT', 'PHI', 'GB', 'CHI', 'DAL', 'ARI', 'LAC', 'HOU',\n",
    "           'SEA', 'OAK'],\n",
    "            ['kan','jax','car', 'rav', 'buf', 'min', 'det', 'atl', 'nwe', 'was', \n",
    "            'cin', 'nor', 'sfo', 'ram', 'nyg', 'den', 'cle', 'clt', 'oti', 'nyj', \n",
    "             'tam','mia', 'pit', 'phi', 'gnb', 'chi', 'dal', 'crd', 'sdg', 'htx', 'sea', 'rai' ])\n",
    "    elo_df['team2'] = elo_df['team2'].replace(['KC', 'JAX', 'CAR', 'BAL', 'BUF', 'MIN', 'DET', 'ATL', 'NE', 'WSH',\n",
    "           'CIN', 'NO', 'SF', 'LAR', 'NYG', 'DEN', 'CLE', 'IND', 'TEN', 'NYJ',\n",
    "           'TB', 'MIA', 'PIT', 'PHI', 'GB', 'CHI', 'DAL', 'ARI', 'LAC', 'HOU',\n",
    "           'SEA', 'OAK'],\n",
    "            ['kan','jax','car', 'rav', 'buf', 'min', 'det', 'atl', 'nwe', 'was', \n",
    "            'cin', 'nor', 'sfo', 'ram', 'nyg', 'den', 'cle', 'clt', 'oti', 'nyj', \n",
    "             'tam','mia', 'pit', 'phi', 'gnb', 'chi', 'dal', 'crd', 'sdg', 'htx', 'sea', 'rai' ])\n",
    "    return elo_df\n",
    "\n",
    "def merge_rankings(agg_games_df,elo_df):\n",
    "    agg_games_df = pd.merge(agg_games_df, elo_df, how = 'inner', left_on = ['home_abbr', 'away_abbr'], right_on = ['team1', 'team2']).drop(columns = ['date','team1', 'team2'])\n",
    "    agg_games_df['elo_dif'] = agg_games_df['elo2_pre'] - agg_games_df['elo1_pre']\n",
    "    agg_games_df['qb_dif'] = agg_games_df['qb2_value_pre'] - agg_games_df['qb1_value_pre']\n",
    "    agg_games_df = agg_games_df.drop(columns = ['elo1_pre', 'elo2_pre', 'qb1_value_pre', 'qb2_value_pre'])\n",
    "    return agg_games_df\n",
    "\n",
    "def prep_test_train(current_week,weeks,year):\n",
    "    current_week = current_week + 1\n",
    "    schedule_df  = get_schedule(year)\n",
    "    weeks_games_df = game_data_up_to_week(weeks,year)\n",
    "    agg_games_df = agg_weekly_data(schedule_df,weeks_games_df,current_week,weeks)\n",
    "    elo_df = get_elo()\n",
    "    agg_games_df = merge_rankings(agg_games_df, elo_df)\n",
    "    train_df = agg_games_df[agg_games_df.result.notna()]\n",
    "    current_week = current_week - 1\n",
    "    test_df = agg_games_df[agg_games_df.week == current_week]\n",
    "    return test_df, train_df\n",
    "\n",
    "def display(y_pred,X_test):\n",
    "    for g in range(len(y_pred)):\n",
    "        win_prob = np.round(y_pred[g],2)\n",
    "        #win_prob = int(y_pred[g] * 100)\n",
    "        away_team = X_test.reset_index().drop(columns = 'index').loc[g,'away_name']\n",
    "        home_team = X_test.reset_index().drop(columns = 'index').loc[g,'home_name']\n",
    "        print(f'The {away_team} have a probability of {win_prob}% of beating the {home_team}.')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Get all the data for 2021, up to the current week 13"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 195,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Week 10 games have not finished yet.\n"
     ]
    }
   ],
   "source": [
    "# this step takes about five minutes to run \n",
    "current_week = 12\n",
    "weeks = list(range(1,current_week + 1))\n",
    "year = 2021\n",
    "\n",
    "pred_games_df, comp_games_df = prep_test_train(current_week,weeks,year)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 196,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>away_name</th>\n",
       "      <th>away_abbr</th>\n",
       "      <th>home_name</th>\n",
       "      <th>home_abbr</th>\n",
       "      <th>week</th>\n",
       "      <th>win_perc_dif</th>\n",
       "      <th>first_downs_dif</th>\n",
       "      <th>fumbles_dif</th>\n",
       "      <th>interceptions_dif</th>\n",
       "      <th>net_pass_yards_dif</th>\n",
       "      <th>pass_attempts_dif</th>\n",
       "      <th>pass_completions_dif</th>\n",
       "      <th>pass_touchdowns_dif</th>\n",
       "      <th>pass_yards_dif</th>\n",
       "      <th>penalties_dif</th>\n",
       "      <th>points_dif</th>\n",
       "      <th>rush_attempts_dif</th>\n",
       "      <th>rush_touchdowns_dif</th>\n",
       "      <th>rush_yards_dif</th>\n",
       "      <th>time_of_possession_dif</th>\n",
       "      <th>times_sacked_dif</th>\n",
       "      <th>total_yards_dif</th>\n",
       "      <th>turnovers_dif</th>\n",
       "      <th>yards_from_penalties_dif</th>\n",
       "      <th>yards_lost_from_sacks_dif</th>\n",
       "      <th>fourth_down_perc_dif</th>\n",
       "      <th>third_down_perc_dif</th>\n",
       "      <th>result</th>\n",
       "      <th>elo_dif</th>\n",
       "      <th>qb_dif</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>158</th>\n",
       "      <td>Los Angeles Chargers</td>\n",
       "      <td>sdg</td>\n",
       "      <td>Denver Broncos</td>\n",
       "      <td>den</td>\n",
       "      <td>12</td>\n",
       "      <td>0.100000</td>\n",
       "      <td>3.800000</td>\n",
       "      <td>-0.100000</td>\n",
       "      <td>0.200000</td>\n",
       "      <td>49.800000</td>\n",
       "      <td>5.300000</td>\n",
       "      <td>2.700000</td>\n",
       "      <td>0.8</td>\n",
       "      <td>42.500000</td>\n",
       "      <td>1.800000</td>\n",
       "      <td>6.000000</td>\n",
       "      <td>-1.600000</td>\n",
       "      <td>0.300000</td>\n",
       "      <td>-5.400000</td>\n",
       "      <td>-163.900000</td>\n",
       "      <td>-1.200000</td>\n",
       "      <td>44.400000</td>\n",
       "      <td>-0.100000</td>\n",
       "      <td>16.600000</td>\n",
       "      <td>-7.300000</td>\n",
       "      <td>-0.055556</td>\n",
       "      <td>0.105924</td>\n",
       "      <td>0.0</td>\n",
       "      <td>74.721833</td>\n",
       "      <td>99.202771</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>159</th>\n",
       "      <td>Minnesota Vikings</td>\n",
       "      <td>min</td>\n",
       "      <td>San Francisco 49ers</td>\n",
       "      <td>sfo</td>\n",
       "      <td>12</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.100000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>-0.400000</td>\n",
       "      <td>31.700000</td>\n",
       "      <td>7.400000</td>\n",
       "      <td>6.100000</td>\n",
       "      <td>0.6</td>\n",
       "      <td>32.000000</td>\n",
       "      <td>1.400000</td>\n",
       "      <td>0.900000</td>\n",
       "      <td>-1.100000</td>\n",
       "      <td>-0.700000</td>\n",
       "      <td>-4.000000</td>\n",
       "      <td>41.600000</td>\n",
       "      <td>-0.500000</td>\n",
       "      <td>27.700000</td>\n",
       "      <td>-0.800000</td>\n",
       "      <td>5.300000</td>\n",
       "      <td>0.300000</td>\n",
       "      <td>0.155844</td>\n",
       "      <td>0.009179</td>\n",
       "      <td>0.0</td>\n",
       "      <td>6.369632</td>\n",
       "      <td>92.115953</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>160</th>\n",
       "      <td>Los Angeles Rams</td>\n",
       "      <td>ram</td>\n",
       "      <td>Green Bay Packers</td>\n",
       "      <td>gnb</td>\n",
       "      <td>12</td>\n",
       "      <td>-0.027273</td>\n",
       "      <td>0.700000</td>\n",
       "      <td>-0.490909</td>\n",
       "      <td>0.445455</td>\n",
       "      <td>46.300000</td>\n",
       "      <td>3.154545</td>\n",
       "      <td>2.609091</td>\n",
       "      <td>0.4</td>\n",
       "      <td>44.918182</td>\n",
       "      <td>0.163636</td>\n",
       "      <td>4.645455</td>\n",
       "      <td>-1.336364</td>\n",
       "      <td>0.063636</td>\n",
       "      <td>-10.100000</td>\n",
       "      <td>-205.163636</td>\n",
       "      <td>-0.500000</td>\n",
       "      <td>36.200000</td>\n",
       "      <td>0.281818</td>\n",
       "      <td>-3.627273</td>\n",
       "      <td>-1.381818</td>\n",
       "      <td>-0.071795</td>\n",
       "      <td>-0.002783</td>\n",
       "      <td>0.0</td>\n",
       "      <td>-77.381374</td>\n",
       "      <td>-42.459544</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>161</th>\n",
       "      <td>Cleveland Browns</td>\n",
       "      <td>cle</td>\n",
       "      <td>Baltimore Ravens</td>\n",
       "      <td>rav</td>\n",
       "      <td>12</td>\n",
       "      <td>-0.154545</td>\n",
       "      <td>-3.772727</td>\n",
       "      <td>-0.027273</td>\n",
       "      <td>-0.354545</td>\n",
       "      <td>-45.963636</td>\n",
       "      <td>-6.236364</td>\n",
       "      <td>-4.272727</td>\n",
       "      <td>-0.4</td>\n",
       "      <td>-47.590909</td>\n",
       "      <td>1.472727</td>\n",
       "      <td>-2.518182</td>\n",
       "      <td>-1.690909</td>\n",
       "      <td>0.345455</td>\n",
       "      <td>5.818182</td>\n",
       "      <td>-187.427273</td>\n",
       "      <td>-0.581818</td>\n",
       "      <td>-40.145455</td>\n",
       "      <td>-0.300000</td>\n",
       "      <td>15.800000</td>\n",
       "      <td>-1.627273</td>\n",
       "      <td>-0.257576</td>\n",
       "      <td>0.020200</td>\n",
       "      <td>0.0</td>\n",
       "      <td>-51.409517</td>\n",
       "      <td>-103.082625</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>162</th>\n",
       "      <td>Seattle Seahawks</td>\n",
       "      <td>sea</td>\n",
       "      <td>Washington Football Team</td>\n",
       "      <td>was</td>\n",
       "      <td>12</td>\n",
       "      <td>-0.100000</td>\n",
       "      <td>-4.100000</td>\n",
       "      <td>-0.700000</td>\n",
       "      <td>-0.500000</td>\n",
       "      <td>-24.700000</td>\n",
       "      <td>-4.800000</td>\n",
       "      <td>-3.100000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>-13.700000</td>\n",
       "      <td>-0.500000</td>\n",
       "      <td>-1.800000</td>\n",
       "      <td>-5.000000</td>\n",
       "      <td>0.100000</td>\n",
       "      <td>-24.500000</td>\n",
       "      <td>-336.400000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>-49.200000</td>\n",
       "      <td>-0.900000</td>\n",
       "      <td>-9.300000</td>\n",
       "      <td>11.000000</td>\n",
       "      <td>-0.355072</td>\n",
       "      <td>-0.068234</td>\n",
       "      <td>0.0</td>\n",
       "      <td>26.031709</td>\n",
       "      <td>32.264597</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                away_name away_abbr                 home_name home_abbr  week  \\\n",
       "158  Los Angeles Chargers       sdg            Denver Broncos       den    12   \n",
       "159     Minnesota Vikings       min       San Francisco 49ers       sfo    12   \n",
       "160      Los Angeles Rams       ram         Green Bay Packers       gnb    12   \n",
       "161      Cleveland Browns       cle          Baltimore Ravens       rav    12   \n",
       "162      Seattle Seahawks       sea  Washington Football Team       was    12   \n",
       "\n",
       "     win_perc_dif  first_downs_dif  fumbles_dif  interceptions_dif  \\\n",
       "158      0.100000         3.800000    -0.100000           0.200000   \n",
       "159      0.000000         0.100000     0.000000          -0.400000   \n",
       "160     -0.027273         0.700000    -0.490909           0.445455   \n",
       "161     -0.154545        -3.772727    -0.027273          -0.354545   \n",
       "162     -0.100000        -4.100000    -0.700000          -0.500000   \n",
       "\n",
       "     net_pass_yards_dif  pass_attempts_dif  pass_completions_dif  \\\n",
       "158           49.800000           5.300000              2.700000   \n",
       "159           31.700000           7.400000              6.100000   \n",
       "160           46.300000           3.154545              2.609091   \n",
       "161          -45.963636          -6.236364             -4.272727   \n",
       "162          -24.700000          -4.800000             -3.100000   \n",
       "\n",
       "     pass_touchdowns_dif  pass_yards_dif  penalties_dif  points_dif  \\\n",
       "158                  0.8       42.500000       1.800000    6.000000   \n",
       "159                  0.6       32.000000       1.400000    0.900000   \n",
       "160                  0.4       44.918182       0.163636    4.645455   \n",
       "161                 -0.4      -47.590909       1.472727   -2.518182   \n",
       "162                  0.0      -13.700000      -0.500000   -1.800000   \n",
       "\n",
       "     rush_attempts_dif  rush_touchdowns_dif  rush_yards_dif  \\\n",
       "158          -1.600000             0.300000       -5.400000   \n",
       "159          -1.100000            -0.700000       -4.000000   \n",
       "160          -1.336364             0.063636      -10.100000   \n",
       "161          -1.690909             0.345455        5.818182   \n",
       "162          -5.000000             0.100000      -24.500000   \n",
       "\n",
       "     time_of_possession_dif  times_sacked_dif  total_yards_dif  turnovers_dif  \\\n",
       "158             -163.900000         -1.200000        44.400000      -0.100000   \n",
       "159               41.600000         -0.500000        27.700000      -0.800000   \n",
       "160             -205.163636         -0.500000        36.200000       0.281818   \n",
       "161             -187.427273         -0.581818       -40.145455      -0.300000   \n",
       "162             -336.400000          1.000000       -49.200000      -0.900000   \n",
       "\n",
       "     yards_from_penalties_dif  yards_lost_from_sacks_dif  \\\n",
       "158                 16.600000                  -7.300000   \n",
       "159                  5.300000                   0.300000   \n",
       "160                 -3.627273                  -1.381818   \n",
       "161                 15.800000                  -1.627273   \n",
       "162                 -9.300000                  11.000000   \n",
       "\n",
       "     fourth_down_perc_dif  third_down_perc_dif  result    elo_dif      qb_dif  \n",
       "158             -0.055556             0.105924     0.0  74.721833   99.202771  \n",
       "159              0.155844             0.009179     0.0   6.369632   92.115953  \n",
       "160             -0.071795            -0.002783     0.0 -77.381374  -42.459544  \n",
       "161             -0.257576             0.020200     0.0 -51.409517 -103.082625  \n",
       "162             -0.355072            -0.068234     0.0  26.031709   32.264597  "
      ]
     },
     "execution_count": 196,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "comp_games_df.tail()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Write out 2021 info, so I don't have to load it all the time\n",
    "df = pd.concat([comp_games_df, pred_games_df], axis=0)\n",
    "df.to_csv(\"2021_week_2_through_13.csv\", index = False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [],
   "source": [
    "# read the full dataframe in and drop an unneeded column\n",
    "df = pd.read_csv('2021_week_2_through_13.csv')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Logistic Regression Predictions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 242,
   "metadata": {},
   "outputs": [],
   "source": [
    "pred_week = 13\n",
    "comp_games_df = df[df['week'] < pred_week]\n",
    "pred_games_df = df[df['week'] == pred_week]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 243,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_df = comp_games_df\n",
    "test_df = pred_games_df\n",
    "\n",
    "X_train = train_df.drop(columns = ['away_name', 'away_abbr', 'home_name', 'home_abbr', 'week','result'])\n",
    "y_train = train_df[['result']] \n",
    "X_test = test_df.drop(columns = ['away_name', 'away_abbr', 'home_name', 'home_abbr', 'week','result'])\n",
    "y_test = test_df[['result']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 244,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create a StandardScaler instance\n",
    "scaler = StandardScaler()\n",
    "\n",
    "# Fit the scaler to the features training dataset\n",
    "X_scaler = scaler.fit(X_train)\n",
    "\n",
    "# Fit the scaler to the features training dataset\n",
    "X_train_scaled = X_scaler.transform(X_train)\n",
    "X_test_scaled = X_scaler.transform(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 253,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Logistic Regression - Unscaled\n",
      "\n",
      "The Dallas Cowboys have a probability of 0.83% of beating the New Orleans Saints.\n",
      "The Arizona Cardinals have a probability of 0.79% of beating the Chicago Bears.\n",
      "The Tampa Bay Buccaneers have a probability of 0.86% of beating the Atlanta Falcons.\n",
      "The Philadelphia Eagles have a probability of 0.39% of beating the New York Jets.\n",
      "The New York Giants have a probability of 0.44% of beating the Miami Dolphins.\n",
      "The Denver Broncos have a probability of 0.33% of beating the Kansas City Chiefs.\n",
      "The Indianapolis Colts have a probability of 0.92% of beating the Houston Texans.\n",
      "The Minnesota Vikings have a probability of 0.68% of beating the Detroit Lions.\n",
      "The Los Angeles Chargers have a probability of 0.25% of beating the Cincinnati Bengals.\n",
      "The Washington Football Team have a probability of 0.45% of beating the Las Vegas Raiders.\n",
      "The Jacksonville Jaguars have a probability of 0.17% of beating the Los Angeles Rams.\n",
      "The Baltimore Ravens have a probability of 0.87% of beating the Pittsburgh Steelers.\n",
      "The San Francisco 49ers have a probability of 0.73% of beating the Seattle Seahawks.\n",
      "The New England Patriots have a probability of 0.37% of beating the Buffalo Bills.\n",
      "\n",
      "Logistic Regression - Scaled\n",
      "\n",
      "The Dallas Cowboys have a probability of 0.75% of beating the New Orleans Saints.\n",
      "The Arizona Cardinals have a probability of 0.76% of beating the Chicago Bears.\n",
      "The Tampa Bay Buccaneers have a probability of 0.84% of beating the Atlanta Falcons.\n",
      "The Philadelphia Eagles have a probability of 0.47% of beating the New York Jets.\n",
      "The New York Giants have a probability of 0.44% of beating the Miami Dolphins.\n",
      "The Denver Broncos have a probability of 0.25% of beating the Kansas City Chiefs.\n",
      "The Indianapolis Colts have a probability of 0.88% of beating the Houston Texans.\n",
      "The Minnesota Vikings have a probability of 0.73% of beating the Detroit Lions.\n",
      "The Los Angeles Chargers have a probability of 0.38% of beating the Cincinnati Bengals.\n",
      "The Washington Football Team have a probability of 0.52% of beating the Las Vegas Raiders.\n",
      "The Jacksonville Jaguars have a probability of 0.2% of beating the Los Angeles Rams.\n",
      "The Baltimore Ravens have a probability of 0.85% of beating the Pittsburgh Steelers.\n",
      "The San Francisco 49ers have a probability of 0.75% of beating the Seattle Seahawks.\n",
      "The New England Patriots have a probability of 0.43% of beating the Buffalo Bills.\n"
     ]
    }
   ],
   "source": [
    "# Logistic Model\n",
    "clf_unscaled = LogisticRegression(penalty='l1', dual=False, tol=0.001, C=1.0, fit_intercept=True, \n",
    "                   intercept_scaling=1, class_weight='balanced', random_state=None, \n",
    "                   solver='liblinear', max_iter=1000, multi_class='ovr', verbose=0)\n",
    "\n",
    "clf_scaled = LogisticRegression(penalty='l1', dual=False, tol=0.001, C=1.0, fit_intercept=True, \n",
    "                   intercept_scaling=1, class_weight='balanced', random_state=None, \n",
    "                   solver='liblinear', max_iter=1000, multi_class='ovr', verbose=0)\n",
    "\n",
    "clf_unscaled.fit(X_train, np.ravel(y_train.values))\n",
    "clf_scaled.fit(X_train_scaled, np.ravel(y_train.values))\n",
    "\n",
    "y_pred_unscaled = clf_unscaled.predict_proba(X_test)\n",
    "y_pred_scaled = clf_scaled.predict_proba(X_test_scaled)\n",
    "\n",
    "y_pred_unscaled = y_pred_unscaled[:,1]\n",
    "y_pred_scaled = y_pred_scaled[:,1]\n",
    "\n",
    "print(\"Logistic Regression - Unscaled\\n\")\n",
    "display(y_pred_unscaled,test_df)\n",
    "\n",
    "print(\"\\nLogistic Regression - Scaled\\n\")\n",
    "display(y_pred_scaled,test_df)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Logistic Regression"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Get Logistic Regression Accuracy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 191,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# make a for loop to the get accuracy for each week\n",
    "def accuracy_score_log_reg(df):\n",
    "    \n",
    "    accuracy = pd.DataFrame(columns=['week', 'Logistic Regression Accuracy - Unscaled', 'Logistic Regeression Accuracy - Scaled'])\n",
    "    \n",
    "    for w in df['week'].unique()[1:-1]:\n",
    "        train_df = df[df['week'] < w]\n",
    "        test_df = df[df['week'] == w]\n",
    "        \n",
    "        X_train = train_df.drop(columns = ['away_name', 'away_abbr', 'home_name', 'home_abbr', 'week','result'])\n",
    "        y_train = train_df[['result']] \n",
    "        X_test = test_df.drop(columns = ['away_name', 'away_abbr', 'home_name', 'home_abbr', 'week','result'])\n",
    "        y_test = test_df[['result']]\n",
    "        \n",
    "        # Create a StandardScaler instance\n",
    "        scaler = StandardScaler()\n",
    "\n",
    "        # Fit the scaler to the features training dataset\n",
    "        X_scaler = scaler.fit(X_train)\n",
    "\n",
    "        # Fit the scaler to the features training dataset\n",
    "        X_train_scaled = X_scaler.transform(X_train)\n",
    "        X_test_scaled = X_scaler.transform(X_test)\n",
    "        \n",
    "        clf = LogisticRegression(penalty='l1', dual=False, tol=0.001, C=1.0, fit_intercept=True, \n",
    "                   intercept_scaling=1, class_weight='balanced', random_state=None, \n",
    "                   solver='liblinear', max_iter=1000, multi_class='ovr', verbose=0)\n",
    "\n",
    "        clf.fit(X_train, np.ravel(y_train.values))\n",
    "        clf.fit(X_train_scaled, np.ravel(y_train.values))\n",
    "        \n",
    "        y_pred_unscaled = clf.predict_proba(X_test)\n",
    "        y_pred_scaled = clf.predict_proba(X_test_scaled)\n",
    "        \n",
    "        y_pred_unscaled = y_pred_unscaled[:,1]\n",
    "        y_pred_scaled = y_pred_scaled[:,1]\n",
    "        \n",
    "        accuracy_score_unscaled = accuracy_score(y_test,np.round(y_pred_unscaled))\n",
    "        accuracy_score_scaled = accuracy_score(y_test,np.round(y_pred_scaled))\n",
    "        \n",
    "        accuracy.loc[w,:] = [w, accuracy_score_unscaled, accuracy_score_scaled]\n",
    "        \n",
    "    return(accuracy)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 193,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>week</th>\n",
       "      <th>Logistic Regression Accuracy - Unscaled</th>\n",
       "      <th>Logistic Regeression Accuracy - Scaled</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>3</td>\n",
       "      <td>0.6</td>\n",
       "      <td>0.466667</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>4</td>\n",
       "      <td>0.5625</td>\n",
       "      <td>0.6875</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>5</td>\n",
       "      <td>0.75</td>\n",
       "      <td>0.625</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>6</td>\n",
       "      <td>0.785714</td>\n",
       "      <td>0.857143</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>7</td>\n",
       "      <td>0.769231</td>\n",
       "      <td>0.769231</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>8</td>\n",
       "      <td>0.533333</td>\n",
       "      <td>0.466667</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>9</td>\n",
       "      <td>0.642857</td>\n",
       "      <td>0.714286</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>11</td>\n",
       "      <td>0.533333</td>\n",
       "      <td>0.733333</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>12</td>\n",
       "      <td>0.533333</td>\n",
       "      <td>0.666667</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   week Logistic Regression Accuracy - Unscaled  \\\n",
       "3     3                                     0.6   \n",
       "4     4                                  0.5625   \n",
       "5     5                                    0.75   \n",
       "6     6                                0.785714   \n",
       "7     7                                0.769231   \n",
       "8     8                                0.533333   \n",
       "9     9                                0.642857   \n",
       "11   11                                0.533333   \n",
       "12   12                                0.533333   \n",
       "\n",
       "   Logistic Regeression Accuracy - Scaled  \n",
       "3                                0.466667  \n",
       "4                                  0.6875  \n",
       "5                                   0.625  \n",
       "6                                0.857143  \n",
       "7                                0.769231  \n",
       "8                                0.466667  \n",
       "9                                0.714286  \n",
       "11                               0.733333  \n",
       "12                               0.666667  "
      ]
     },
     "execution_count": 193,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "logistic_regression_accuracy = accuracy_score_log_reg(df)\n",
    "logistic_regression_accuracy"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Tensorflow "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 115,
   "metadata": {},
   "outputs": [],
   "source": [
    "# load a previously built model.\n",
    "nn = tf.keras.models.load_model(\"Resources/model_nn_2021_1_12_not_scaled_relu_relu_sigmoid_loss='binary_crossentropy', optimizer='adam', metrics=['accuracy']_1000 epochs.h5\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 184,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# make a for loop to the get accuracy for each week\n",
    "def accuracy_score_tensorflow(df):\n",
    "    \n",
    "    accuracy = pd.DataFrame(columns=['week', 'Tensorflow Accuracy - Unscaled', 'Tensorflow Accuracy - Scaled'])\n",
    "    \n",
    "    for w in df['week'].unique()[1:-1]:\n",
    "        train_df = df[df['week'] < w]\n",
    "        test_df = df[df['week'] == w]\n",
    "        \n",
    "        X_train = train_df.drop(columns = ['away_name', 'away_abbr', 'home_name', 'home_abbr', 'week','result'])\n",
    "        y_train = train_df[['result']] \n",
    "        X_test = test_df.drop(columns = ['away_name', 'away_abbr', 'home_name', 'home_abbr', 'week','result'])\n",
    "        y_test = test_df[['result']]\n",
    "        \n",
    "        # Create a StandardScaler instance\n",
    "        scaler = StandardScaler()\n",
    "\n",
    "        # Fit the scaler to the features training dataset\n",
    "        X_scaler = scaler.fit(X_train)\n",
    "\n",
    "        # Fit the scaler to the features training dataset\n",
    "        X_train_scaled = X_scaler.transform(X_train)\n",
    "        X_test_scaled = X_scaler.transform(X_test)\n",
    "        \n",
    "        # Evaluate the model loss and accuracy metrics using the evaluate method and the test data        \n",
    "        model_accuracy_unscaled = nn.evaluate(X_test, y_test, verbose=0)       \n",
    "        model_accuracy_scaled = nn.evaluate(X_test_scaled, y_test, verbose=0)\n",
    "    \n",
    "        # Assign the accuracy to \n",
    "        accuracy.loc[w,:] = [w, model_accuracy_unscaled[1], model_accuracy_scaled[1]]\n",
    "        \n",
    "    return(accuracy)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 185,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>week</th>\n",
       "      <th>Tensorflow Accuracy - Unscaled</th>\n",
       "      <th>Tensorflow Accuracy - Scaled</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>3</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.6</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>4</td>\n",
       "      <td>0.875</td>\n",
       "      <td>0.5625</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>5</td>\n",
       "      <td>0.875</td>\n",
       "      <td>0.625</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>6</td>\n",
       "      <td>0.5</td>\n",
       "      <td>0.642857</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>7</td>\n",
       "      <td>0.615385</td>\n",
       "      <td>0.538462</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>8</td>\n",
       "      <td>0.533333</td>\n",
       "      <td>0.733333</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>9</td>\n",
       "      <td>0.571429</td>\n",
       "      <td>0.428571</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>11</td>\n",
       "      <td>0.6</td>\n",
       "      <td>0.666667</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>12</td>\n",
       "      <td>0.266667</td>\n",
       "      <td>0.4</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   week Tensorflow Accuracy - Unscaled Tensorflow Accuracy - Scaled\n",
       "3     3                            1.0                          0.6\n",
       "4     4                          0.875                       0.5625\n",
       "5     5                          0.875                        0.625\n",
       "6     6                            0.5                     0.642857\n",
       "7     7                       0.615385                     0.538462\n",
       "8     8                       0.533333                     0.733333\n",
       "9     9                       0.571429                     0.428571\n",
       "11   11                            0.6                     0.666667\n",
       "12   12                       0.266667                          0.4"
      ]
     },
     "execution_count": 185,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Run the accuracy_score_Tensorflow function to get an array of accuracies\n",
    "tensorflow_accuracy = accuracy_score_tensorflow_scaled(df)\n",
    "tensorflow_accuracy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 205,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>week</th>\n",
       "      <th>Logistic Regression Accuracy - Unscaled</th>\n",
       "      <th>Logistic Regeression Accuracy - Scaled</th>\n",
       "      <th>Tensorflow Accuracy - Unscaled</th>\n",
       "      <th>Tensorflow Accuracy - Scaled</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>3</td>\n",
       "      <td>0.6</td>\n",
       "      <td>0.466667</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.6</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>4</td>\n",
       "      <td>0.5625</td>\n",
       "      <td>0.6875</td>\n",
       "      <td>0.875</td>\n",
       "      <td>0.5625</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>5</td>\n",
       "      <td>0.75</td>\n",
       "      <td>0.625</td>\n",
       "      <td>0.875</td>\n",
       "      <td>0.625</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>6</td>\n",
       "      <td>0.785714</td>\n",
       "      <td>0.857143</td>\n",
       "      <td>0.5</td>\n",
       "      <td>0.642857</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>7</td>\n",
       "      <td>0.769231</td>\n",
       "      <td>0.769231</td>\n",
       "      <td>0.615385</td>\n",
       "      <td>0.538462</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>8</td>\n",
       "      <td>0.533333</td>\n",
       "      <td>0.466667</td>\n",
       "      <td>0.533333</td>\n",
       "      <td>0.733333</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>9</td>\n",
       "      <td>0.642857</td>\n",
       "      <td>0.714286</td>\n",
       "      <td>0.571429</td>\n",
       "      <td>0.428571</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>11</td>\n",
       "      <td>0.533333</td>\n",
       "      <td>0.733333</td>\n",
       "      <td>0.6</td>\n",
       "      <td>0.666667</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>12</td>\n",
       "      <td>0.533333</td>\n",
       "      <td>0.666667</td>\n",
       "      <td>0.266667</td>\n",
       "      <td>0.4</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   week Logistic Regression Accuracy - Unscaled  \\\n",
       "3     3                                     0.6   \n",
       "4     4                                  0.5625   \n",
       "5     5                                    0.75   \n",
       "6     6                                0.785714   \n",
       "7     7                                0.769231   \n",
       "8     8                                0.533333   \n",
       "9     9                                0.642857   \n",
       "11   11                                0.533333   \n",
       "12   12                                0.533333   \n",
       "\n",
       "   Logistic Regeression Accuracy - Scaled Tensorflow Accuracy - Unscaled  \\\n",
       "3                                0.466667                            1.0   \n",
       "4                                  0.6875                          0.875   \n",
       "5                                   0.625                          0.875   \n",
       "6                                0.857143                            0.5   \n",
       "7                                0.769231                       0.615385   \n",
       "8                                0.466667                       0.533333   \n",
       "9                                0.714286                       0.571429   \n",
       "11                               0.733333                            0.6   \n",
       "12                               0.666667                       0.266667   \n",
       "\n",
       "   Tensorflow Accuracy - Scaled  \n",
       "3                           0.6  \n",
       "4                        0.5625  \n",
       "5                         0.625  \n",
       "6                      0.642857  \n",
       "7                      0.538462  \n",
       "8                      0.733333  \n",
       "9                      0.428571  \n",
       "11                     0.666667  \n",
       "12                          0.4  "
      ]
     },
     "execution_count": 205,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pd.concat(\n",
    "    [logistic_regression_accuracy, tensorflow_accuracy.drop(columns=['week'])], axis=1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Tensorflow Predictions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 218,
   "metadata": {},
   "outputs": [],
   "source": [
    "pred_week = 5\n",
    "comp_games_df = df[df['week'] < pred_week]\n",
    "pred_games_df = df[df['week'] == pred_week]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 219,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_df = comp_games_df\n",
    "test_df = pred_games_df\n",
    "\n",
    "X_train = train_df.drop(columns = ['away_name', 'away_abbr', 'home_name', 'home_abbr', 'week','result'])\n",
    "y_train = train_df[['result']] \n",
    "X_test = test_df.drop(columns = ['away_name', 'away_abbr', 'home_name', 'home_abbr', 'week','result'])\n",
    "y_test = test_df[['result']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 208,
   "metadata": {},
   "outputs": [
    {
     "ename": "TypeError",
     "evalue": "type numpy.ndarray doesn't define __round__ method",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-208-1b4a746603ab>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[0my_pred\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mnn\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mpredict\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mX_test\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 2\u001b[1;33m \u001b[0mdisplay\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mnp\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mround\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0my_pred\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;36m2\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0mtest_df\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[1;32m<ipython-input-28-5e9446e32202>\u001b[0m in \u001b[0;36mdisplay\u001b[1;34m(y_pred, X_test)\u001b[0m\n\u001b[0;32m    249\u001b[0m \u001b[1;32mdef\u001b[0m \u001b[0mdisplay\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0my_pred\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0mX_test\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    250\u001b[0m     \u001b[1;32mfor\u001b[0m \u001b[0mg\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mrange\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mlen\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0my_pred\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 251\u001b[1;33m         \u001b[0mwin_prob\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mround\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0my_pred\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mg\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;36m2\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    252\u001b[0m         \u001b[0maway_team\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mX_test\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mreset_index\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mdrop\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mcolumns\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;34m'index'\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mloc\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mg\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;34m'away_name'\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    253\u001b[0m         \u001b[0mhome_team\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mX_test\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mreset_index\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mdrop\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mcolumns\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;34m'index'\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mloc\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mg\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;34m'home_name'\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mTypeError\u001b[0m: type numpy.ndarray doesn't define __round__ method"
     ]
    }
   ],
   "source": [
    "y_pred = nn.predict(X_test)\n",
    "display(np.round(y_pred, 2),test_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 216,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[array([90.], dtype=float32),\n",
       " array([0.], dtype=float32),\n",
       " array([92.], dtype=float32),\n",
       " array([100.], dtype=float32),\n",
       " array([60.000004], dtype=float32),\n",
       " array([2.], dtype=float32),\n",
       " array([60.000004], dtype=float32),\n",
       " array([86.], dtype=float32),\n",
       " array([95.], dtype=float32),\n",
       " array([0.], dtype=float32),\n",
       " array([0.], dtype=float32),\n",
       " array([60.000004], dtype=float32),\n",
       " array([60.000004], dtype=float32)]"
      ]
     },
     "execution_count": 216,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "list(np.round(y_pred,2) * 100)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Tensorflow play area"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 134,
   "metadata": {},
   "outputs": [],
   "source": [
    "pred_week = 7\n",
    "comp_games_df = df[df['week'] < pred_week]\n",
    "pred_games_df = df[df['week'] == pred_week]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 135,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_df = comp_games_df\n",
    "test_df = pred_games_df\n",
    "\n",
    "X_train = train_df.drop(columns = ['away_name', 'away_abbr', 'home_name', 'home_abbr', 'week','result'])\n",
    "y_train = train_df[['result']] \n",
    "X_test = test_df.drop(columns = ['away_name', 'away_abbr', 'home_name', 'home_abbr', 'week','result'])\n",
    "y_test = test_df[['result']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 125,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " dense (Dense)               (None, 12)                300       \n",
      "                                                                 \n",
      " dense_1 (Dense)             (None, 6)                 78        \n",
      "                                                                 \n",
      " dense_2 (Dense)             (None, 1)                 7         \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 385\n",
      "Trainable params: 385\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "# Define the the number of inputs (features) to the model\n",
    "number_input_features = X_train.shape[1]\n",
    "\n",
    "# Review the number of features\n",
    "number_input_features\n",
    "\n",
    "# Define the number of neurons in the output layer\n",
    "number_output_neurons = 1\n",
    "\n",
    "# Define the number of hidden nodes for the first hidden layer\n",
    "hidden_nodes_layer1 =  (number_input_features + 1) // 2\n",
    "\n",
    "# Review the number hidden nodes in the first layer\n",
    "hidden_nodes_layer1\n",
    "\n",
    "# Define the number of hidden nodes for the second hidden layer\n",
    "hidden_nodes_layer2 = (hidden_nodes_layer1 + 1) // 2\n",
    "\n",
    "# Review the number hidden nodes in the second layer\n",
    "hidden_nodes_layer2\n",
    "\n",
    "# Create the Sequential model instance\n",
    "nn = Sequential()\n",
    "\n",
    "# Add the first hidden layer\n",
    "nn.add(Dense(units=hidden_nodes_layer1, activation='relu', input_dim=number_input_features))\n",
    "# Add the second hidden layer\n",
    "nn.add(Dense(units=hidden_nodes_layer2, activation='relu'))\n",
    "# Add the output layer to the model specifying the number of output neurons and activation function\n",
    "nn.add(Dense(units=number_output_neurons, activation='sigmoid'))\n",
    "# Display the Sequential model summary\n",
    "nn.summary()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Step 2: Compile and fit the model using the `binary_crossentropy` loss function, the `adam` optimizer, and the `accuracy` evaluation metric."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 132,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Compile the Sequential model\n",
    "nn.compile(loss='binary_crossentropy', optimizer='adam', metrics=['accuracy'])\n",
    "\n",
    "# Fit the model using 50 epochs and the training data\n",
    "fit_model = nn.fit(X_train, y_train, epochs=100, verbose=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 136,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1/1 - 0s - loss: 2.1989 - accuracy: 0.6154 - 35ms/epoch - 35ms/step\n",
      "Loss: 2.198853015899658, Accuracy: 0.6153846383094788\n"
     ]
    }
   ],
   "source": [
    "# Evaluate the model loss and accuracy metrics using the evaluate method and the test data\n",
    "model_loss, model_accuracy = nn.evaluate(X_test, y_test, verbose=2)\n",
    "\n",
    "# Display the model loss and accuracy results\n",
    "print(f\"Loss: {model_loss}, Accuracy: {model_accuracy}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 137,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.6153846383094788"
      ]
     },
     "execution_count": 137,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model_accuracy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
