{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 110,
   "metadata": {},
   "outputs": [],
   "source": [
    "# probably going to have to install this if you haven't already\n",
    "from sportsreference.nfl.boxscore import Boxscores, Boxscore\n",
    "\n",
    "# the usual imports\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "# for models\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.metrics import accuracy_score\n",
    "from sklearn.preprocessing import StandardScaler,OneHotEncoder\n",
    "\n",
    "import tensorflow as tf\n",
    "from tensorflow.keras.layers import Dense\n",
    "from tensorflow.keras.models import Sequential\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "pd.set_option('display.max_columns', None)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 283,
   "metadata": {},
   "outputs": [],
   "source": [
    "# The game_Data function is extracting game statistics for each game. It loops through each game and each week grabbing the statistics referenced.\n",
    "# This function creates the foundation for our final dataset.\n",
    "def game_data(game_df,game_stats):\n",
    "    try:\n",
    "        # Creates a dataframe for the away_team and the home_team. Sets column names to be exact matches between the two.\n",
    "        away_team_df = game_df[['away_name', 'away_abbr', 'away_score']].rename(columns = {'away_name': 'team_name', 'away_abbr': 'team_abbr', 'away_score': 'score'})\n",
    "        home_team_df = game_df[['home_name','home_abbr', 'home_score']].rename(columns = {'home_name': 'team_name', 'home_abbr': 'team_abbr', 'home_score': 'score'})\n",
    "        try:\n",
    "            if game_df.loc[0,'away_score'] > game_df.loc[0,'home_score']:\n",
    "                away_team_df = pd.merge(away_team_df, pd.DataFrame({'game_won' : [1], 'game_lost' : [0]}),left_index = True, right_index = True)\n",
    "                home_team_df = pd.merge(home_team_df, pd.DataFrame({'game_won' : [0], 'game_lost' : [1]}),left_index = True, right_index = True)\n",
    "            elif game_df.loc[0,'away_score'] < game_df.loc[0,'home_score']:\n",
    "                away_team_df = pd.merge(away_team_df, pd.DataFrame({'game_won' : [0], 'game_lost' : [1]}),left_index = True, right_index = True)\n",
    "                home_team_df = pd.merge(home_team_df, pd.DataFrame({'game_won' : [1], 'game_lost' : [0]}),left_index = True, right_index = True)\n",
    "            else: \n",
    "                away_team_df = pd.merge(away_team_df, pd.DataFrame({'game_won' : [0], 'game_lost' : [0]}),left_index = True, right_index = True)\n",
    "                home_team_df = pd.merge(home_team_df, pd.DataFrame({'game_won' : [0], 'game_lost' : [0]}),left_index = True, right_index = True)\n",
    "        except TypeError:\n",
    "                away_team_df = pd.merge(away_team_df, pd.DataFrame({'game_won' : [np.nan], 'game_lost' : [np.nan]}),left_index = True, right_index = True)\n",
    "                home_team_df = pd.merge(home_team_df, pd.DataFrame({'game_won' : [np.nan], 'game_lost' : [np.nan]}),left_index = True, right_index = True)        \n",
    "\n",
    "        # Creating the away_team & home_team stats dataframe. Grabbing the selected stats and then renaming them to match home == away dataframe column names.\n",
    "        away_stats_df = game_stats.dataframe[['away_first_downs', 'away_fourth_down_attempts',\n",
    "               'away_fourth_down_conversions', 'away_fumbles', 'away_fumbles_lost',\n",
    "               'away_interceptions', 'away_net_pass_yards', 'away_pass_attempts',\n",
    "               'away_pass_completions', 'away_pass_touchdowns', 'away_pass_yards',\n",
    "               'away_penalties', 'away_points', 'away_rush_attempts',\n",
    "               'away_rush_touchdowns', 'away_rush_yards', 'away_third_down_attempts',\n",
    "               'away_third_down_conversions', 'away_time_of_possession',\n",
    "               'away_times_sacked', 'away_total_yards', 'away_turnovers',\n",
    "               'away_yards_from_penalties', 'away_yards_lost_from_sacks']].reset_index().drop(columns ='index').rename(columns = {\n",
    "               'away_first_downs': 'first_downs', 'away_fourth_down_attempts':'fourth_down_attempts',\n",
    "               'away_fourth_down_conversions':'fourth_down_conversions' , 'away_fumbles': 'fumbles', 'away_fumbles_lost': 'fumbles_lost',\n",
    "               'away_interceptions': 'interceptions', 'away_net_pass_yards':'net_pass_yards' , 'away_pass_attempts': 'pass_attempts',\n",
    "               'away_pass_completions':'pass_completions' , 'away_pass_touchdowns': 'pass_touchdowns', 'away_pass_yards': 'pass_yards',\n",
    "               'away_penalties': 'penalties', 'away_points': 'points', 'away_rush_attempts': 'rush_attempts',\n",
    "               'away_rush_touchdowns': 'rush_touchdowns', 'away_rush_yards': 'rush_yards', 'away_third_down_attempts': 'third_down_attempts',\n",
    "               'away_third_down_conversions': 'third_down_conversions', 'away_time_of_possession': 'time_of_possession',\n",
    "               'away_times_sacked': 'times_sacked', 'away_total_yards': 'total_yards', 'away_turnovers': 'turnovers',\n",
    "               'away_yards_from_penalties':'yards_from_penalties', 'away_yards_lost_from_sacks': 'yards_lost_from_sacks'})\n",
    "\n",
    "        home_stats_df = game_stats.dataframe[['home_first_downs', 'home_fourth_down_attempts',\n",
    "               'home_fourth_down_conversions', 'home_fumbles', 'home_fumbles_lost',\n",
    "               'home_interceptions', 'home_net_pass_yards', 'home_pass_attempts',\n",
    "               'home_pass_completions', 'home_pass_touchdowns', 'home_pass_yards',\n",
    "               'home_penalties', 'home_points', 'home_rush_attempts',\n",
    "               'home_rush_touchdowns', 'home_rush_yards', 'home_third_down_attempts',\n",
    "               'home_third_down_conversions', 'home_time_of_possession',\n",
    "               'home_times_sacked', 'home_total_yards', 'home_turnovers',\n",
    "               'home_yards_from_penalties', 'home_yards_lost_from_sacks']].reset_index().drop(columns = 'index').rename(columns = {\n",
    "               'home_first_downs': 'first_downs', 'home_fourth_down_attempts':'fourth_down_attempts',\n",
    "               'home_fourth_down_conversions':'fourth_down_conversions' , 'home_fumbles': 'fumbles', 'home_fumbles_lost': 'fumbles_lost',\n",
    "               'home_interceptions': 'interceptions', 'home_net_pass_yards':'net_pass_yards' , 'home_pass_attempts': 'pass_attempts',\n",
    "               'home_pass_completions':'pass_completions' , 'home_pass_touchdowns': 'pass_touchdowns', 'home_pass_yards': 'pass_yards',\n",
    "               'home_penalties': 'penalties', 'home_points': 'points', 'home_rush_attempts': 'rush_attempts',\n",
    "               'home_rush_touchdowns': 'rush_touchdowns', 'home_rush_yards': 'rush_yards', 'home_third_down_attempts': 'third_down_attempts',\n",
    "               'home_third_down_conversions': 'third_down_conversions', 'home_time_of_possession': 'time_of_possession',\n",
    "               'home_times_sacked': 'times_sacked', 'home_total_yards': 'total_yards', 'home_turnovers': 'turnovers',\n",
    "               'home_yards_from_penalties':'yards_from_penalties', 'home_yards_lost_from_sacks': 'yards_lost_from_sacks'})\n",
    "        \n",
    "        # Merge the team_df & stats_df for both home & away teams. Set the left_index & right_index to True so that both dataframes merge on the same indices. \n",
    "        away_team_df = pd.merge(away_team_df, away_stats_df,left_index = True, right_index = True)\n",
    "        home_team_df = pd.merge(home_team_df, home_stats_df,left_index = True, right_index = True)\n",
    "        try:\n",
    "            # Converting time_of_possession from MM:SS format into seconds(int). \n",
    "            away_team_df['time_of_possession'] = (int(away_team_df['time_of_possession'].loc[0][0:2]) * 60) + int(away_team_df['time_of_possession'].loc[0][3:5])\n",
    "            home_team_df['time_of_possession'] = (int(home_team_df['time_of_possession'].loc[0][0:2]) * 60) + int(home_team_df['time_of_possession'].loc[0][3:5])\n",
    "        except TypeError:\n",
    "            away_team_df['time_of_possession'] = np.nan\n",
    "            home_team_df['time_of_possession'] = np.nan\n",
    "    except TypeError:\n",
    "        away_team_df = pd.DataFrame()\n",
    "        home_team_df = pd.DataFrame()\n",
    "    return away_team_df, home_team_df\n",
    "\n",
    "def game_data_up_to_week(weeks,year):\n",
    "    weeks_games_df = pd.DataFrame()\n",
    "    for w in range(len(weeks)):\n",
    "        date_string = str(weeks[w]) + '-' + str(year)\n",
    "        week_scores = Boxscores(weeks[w],year)\n",
    "        week_games_df = pd.DataFrame()\n",
    "        for g in range(len(week_scores.games[date_string])):\n",
    "            game_str = week_scores.games[date_string][g]['boxscore']\n",
    "            game_stats = Boxscore(game_str)\n",
    "            game_df = pd.DataFrame(week_scores.games[date_string][g], index = [0])\n",
    "            away_team_df, home_team_df = game_data(game_df,game_stats)\n",
    "            away_team_df['week'] = weeks[w]\n",
    "            home_team_df['week'] = weeks[w]\n",
    "            week_games_df = pd.concat([week_games_df,away_team_df])\n",
    "            week_games_df = pd.concat([week_games_df,home_team_df])\n",
    "        weeks_games_df = pd.concat([weeks_games_df,week_games_df])\n",
    "    return weeks_games_df\n",
    "\n",
    "def get_schedule(year):\n",
    "    weeks = list(range(1,18))\n",
    "    schedule_df = pd.DataFrame()\n",
    "    for w in range(len(weeks)):\n",
    "        date_string = str(weeks[w]) + '-' + str(year)\n",
    "        week_scores = Boxscores(weeks[w],year)\n",
    "        week_games_df = pd.DataFrame()\n",
    "        for g in range(len(week_scores.games[date_string])):\n",
    "            game = pd.DataFrame(week_scores.games[date_string][g], index = [0])[['away_name', 'away_abbr','home_name', 'home_abbr','winning_name', 'winning_abbr' ]]\n",
    "            game['week'] = weeks[w]\n",
    "            week_games_df = pd.concat([week_games_df,game])\n",
    "        schedule_df = pd.concat([schedule_df, week_games_df]).reset_index().drop(columns = 'index') \n",
    "    return schedule_df \n",
    "\n",
    "def agg_weekly_data(schedule_df,weeks_games_df,current_week,weeks):\n",
    "    schedule_df = schedule_df[schedule_df.week < current_week]\n",
    "    agg_games_df = pd.DataFrame()\n",
    "    for w in range(1,len(weeks)):\n",
    "        games_df = schedule_df[schedule_df.week == weeks[w]]\n",
    "        agg_weekly_df = weeks_games_df[weeks_games_df.week < weeks[w]].drop(columns = ['score','week','game_won', 'game_lost']).groupby(by=[\"team_name\", \"team_abbr\"]).mean().reset_index()\n",
    "        win_loss_df = weeks_games_df[weeks_games_df.week < weeks[w]][[\"team_name\", \"team_abbr\",'game_won', 'game_lost']].groupby(by=[\"team_name\", \"team_abbr\"]).sum().reset_index()\n",
    "        win_loss_df['win_perc'] = win_loss_df['game_won'] / (win_loss_df['game_won'] + win_loss_df['game_lost'])\n",
    "        win_loss_df = win_loss_df.drop(columns = ['game_won', 'game_lost'])\n",
    "\n",
    "        try:\n",
    "            agg_weekly_df['fourth_down_perc'] = agg_weekly_df['fourth_down_conversions'] / agg_weekly_df['fourth_down_attempts']  \n",
    "        except ZeroDivisionError:\n",
    "            agg_weekly_df['fourth_down_perc'] = 0 \n",
    "        agg_weekly_df['fourth_down_perc'] = agg_weekly_df['fourth_down_perc'].fillna(0)\n",
    "\n",
    "        try:\n",
    "            agg_weekly_df['third_down_perc'] = agg_weekly_df['third_down_conversions'] / agg_weekly_df['third_down_attempts']  \n",
    "        except ZeroDivisionError:\n",
    "            agg_weekly_df['third_down_perc'] = 0\n",
    "        agg_weekly_df['third_down_perc'] = agg_weekly_df['third_down_perc'].fillna(0)  \n",
    "\n",
    "        agg_weekly_df = agg_weekly_df.drop(columns = ['fourth_down_attempts', 'fourth_down_conversions', 'third_down_attempts', 'third_down_conversions'])\n",
    "        agg_weekly_df = pd.merge(win_loss_df,agg_weekly_df,left_on = ['team_name', 'team_abbr'], right_on = ['team_name', 'team_abbr'])\n",
    "\n",
    "        away_df = pd.merge(games_df,agg_weekly_df,how = 'inner', left_on = ['away_name', 'away_abbr'], right_on = ['team_name', 'team_abbr']).drop(columns = ['team_name', 'team_abbr']).rename(columns = {\n",
    "                'win_perc': 'away_win_perc',\n",
    "               'first_downs': 'away_first_downs', 'fumbles': 'away_fumbles', 'fumbles_lost':'away_fumbles_lost', 'interceptions':'away_interceptions',\n",
    "               'net_pass_yards': 'away_net_pass_yards', 'pass_attempts':'away_pass_attempts', 'pass_completions':'away_pass_completions',\n",
    "               'pass_touchdowns':'away_pass_touchdowns', 'pass_yards':'away_pass_yards', 'penalties':'away_penalties', 'points':'away_points', 'rush_attempts':'away_rush_attempts',\n",
    "               'rush_touchdowns':'away_rush_touchdowns', 'rush_yards':'away_rush_yards', 'time_of_possession':'away_time_of_possession', 'times_sacked':'away_times_sacked',\n",
    "               'total_yards':'away_total_yards', 'turnovers':'away_turnovers', 'yards_from_penalties':'away_yards_from_penalties',\n",
    "               'yards_lost_from_sacks': 'away_yards_lost_from_sacks', 'fourth_down_perc':'away_fourth_down_perc', 'third_down_perc':'away_third_down_perc'})\n",
    "\n",
    "        home_df = pd.merge(games_df,agg_weekly_df,how = 'inner', left_on = ['home_name', 'home_abbr'], right_on = ['team_name', 'team_abbr']).drop(columns = ['team_name', 'team_abbr']).rename(columns = {\n",
    "                'win_perc': 'home_win_perc',\n",
    "               'first_downs': 'home_first_downs', 'fumbles': 'home_fumbles', 'fumbles_lost':'home_fumbles_lost', 'interceptions':'home_interceptions',\n",
    "               'net_pass_yards': 'home_net_pass_yards', 'pass_attempts':'home_pass_attempts', 'pass_completions':'home_pass_completions',\n",
    "               'pass_touchdowns':'home_pass_touchdowns', 'pass_yards':'home_pass_yards', 'penalties':'home_penalties', 'points':'home_points', 'rush_attempts':'home_rush_attempts',\n",
    "               'rush_touchdowns':'home_rush_touchdowns', 'rush_yards':'home_rush_yards', 'time_of_possession':'home_time_of_possession', 'times_sacked':'home_times_sacked',\n",
    "               'total_yards':'home_total_yards', 'turnovers':'home_turnovers', 'yards_from_penalties':'home_yards_from_penalties',\n",
    "               'yards_lost_from_sacks': 'home_yards_lost_from_sacks', 'fourth_down_perc':'home_fourth_down_perc', 'third_down_perc':'home_third_down_perc'})\n",
    "\n",
    "        agg_weekly_df = pd.merge(away_df,home_df,left_on = ['away_name', 'away_abbr', 'home_name', 'home_abbr', 'winning_name',\n",
    "               'winning_abbr', 'week'], right_on = ['away_name', 'away_abbr', 'home_name', 'home_abbr', 'winning_name',\n",
    "               'winning_abbr', 'week'])\n",
    "\n",
    "        agg_weekly_df['win_perc_dif'] = agg_weekly_df['away_win_perc'] - agg_weekly_df['home_win_perc']\n",
    "        agg_weekly_df['first_downs_dif'] = agg_weekly_df['away_first_downs'] - agg_weekly_df['home_first_downs']\n",
    "        agg_weekly_df['fumbles_dif'] = agg_weekly_df['away_fumbles'] - agg_weekly_df['home_fumbles']\n",
    "        agg_weekly_df['interceptions_dif'] = agg_weekly_df['away_interceptions'] - agg_weekly_df['home_interceptions']\n",
    "        agg_weekly_df['net_pass_yards_dif'] = agg_weekly_df['away_net_pass_yards'] - agg_weekly_df['home_net_pass_yards']\n",
    "        agg_weekly_df['pass_attempts_dif'] = agg_weekly_df['away_pass_attempts'] - agg_weekly_df['home_pass_attempts']\n",
    "        agg_weekly_df['pass_completions_dif'] = agg_weekly_df['away_pass_completions'] - agg_weekly_df['home_pass_completions']\n",
    "        agg_weekly_df['pass_touchdowns_dif'] = agg_weekly_df['away_pass_touchdowns'] - agg_weekly_df['home_pass_touchdowns']\n",
    "        agg_weekly_df['pass_yards_dif'] = agg_weekly_df['away_pass_yards'] - agg_weekly_df['home_pass_yards']\n",
    "        agg_weekly_df['penalties_dif'] = agg_weekly_df['away_penalties'] - agg_weekly_df['home_penalties']\n",
    "        agg_weekly_df['points_dif'] = agg_weekly_df['away_points'] - agg_weekly_df['home_points']\n",
    "        agg_weekly_df['rush_attempts_dif'] = agg_weekly_df['away_rush_attempts'] - agg_weekly_df['home_rush_attempts']\n",
    "        agg_weekly_df['rush_touchdowns_dif'] = agg_weekly_df['away_rush_touchdowns'] - agg_weekly_df['home_rush_touchdowns']\n",
    "        agg_weekly_df['rush_yards_dif'] = agg_weekly_df['away_rush_yards'] - agg_weekly_df['home_rush_yards']\n",
    "        agg_weekly_df['time_of_possession_dif'] = agg_weekly_df['away_time_of_possession'] - agg_weekly_df['home_time_of_possession']\n",
    "        agg_weekly_df['times_sacked_dif'] = agg_weekly_df['away_times_sacked'] - agg_weekly_df['home_times_sacked']\n",
    "        agg_weekly_df['total_yards_dif'] = agg_weekly_df['away_total_yards'] - agg_weekly_df['home_total_yards']\n",
    "        agg_weekly_df['turnovers_dif'] = agg_weekly_df['away_turnovers'] - agg_weekly_df['home_turnovers']\n",
    "        agg_weekly_df['yards_from_penalties_dif'] = agg_weekly_df['away_yards_from_penalties'] - agg_weekly_df['home_yards_from_penalties']\n",
    "        agg_weekly_df['yards_lost_from_sacks_dif'] = agg_weekly_df['away_yards_lost_from_sacks'] - agg_weekly_df['home_yards_lost_from_sacks']\n",
    "        agg_weekly_df['fourth_down_perc_dif'] = agg_weekly_df['away_fourth_down_perc'] - agg_weekly_df['home_fourth_down_perc']\n",
    "        agg_weekly_df['third_down_perc_dif'] = agg_weekly_df['away_third_down_perc'] - agg_weekly_df['home_third_down_perc']\n",
    "\n",
    "        agg_weekly_df = agg_weekly_df.drop(columns = ['away_win_perc',\n",
    "               'away_first_downs', 'away_fumbles', 'away_fumbles_lost', 'away_interceptions',\n",
    "               'away_net_pass_yards', 'away_pass_attempts','away_pass_completions',\n",
    "               'away_pass_touchdowns', 'away_pass_yards', 'away_penalties', 'away_points', 'away_rush_attempts',\n",
    "               'away_rush_touchdowns', 'away_rush_yards', 'away_time_of_possession', 'away_times_sacked',\n",
    "               'away_total_yards', 'away_turnovers', 'away_yards_from_penalties',\n",
    "               'away_yards_lost_from_sacks','away_fourth_down_perc', 'away_third_down_perc','home_win_perc',\n",
    "               'home_first_downs', 'home_fumbles', 'home_fumbles_lost', 'home_interceptions',\n",
    "               'home_net_pass_yards', 'home_pass_attempts','home_pass_completions',\n",
    "               'home_pass_touchdowns', 'home_pass_yards', 'home_penalties', 'home_points', 'home_rush_attempts',\n",
    "               'home_rush_touchdowns', 'home_rush_yards', 'home_time_of_possession', 'home_times_sacked',\n",
    "               'home_total_yards', 'home_turnovers', 'home_yards_from_penalties',\n",
    "               'home_yards_lost_from_sacks','home_fourth_down_perc', 'home_third_down_perc'])\n",
    "        \n",
    "        if (agg_weekly_df['winning_name'].isnull().values.any() and weeks[w] > 3):\n",
    "            agg_weekly_df['result'] = np.nan\n",
    "            print(f\"Week {weeks[w]} games have not finished yet.\")\n",
    "        else:\n",
    "            agg_weekly_df['result'] = agg_weekly_df['winning_name'] == agg_weekly_df['away_name']\n",
    "            agg_weekly_df['result'] = agg_weekly_df['result'].astype('float')\n",
    "        agg_weekly_df = agg_weekly_df.drop(columns = ['winning_name', 'winning_abbr'])\n",
    "        agg_games_df = pd.concat([agg_games_df, agg_weekly_df])\n",
    "    agg_games_df = agg_games_df.reset_index().drop(columns = 'index')\n",
    "    # What is .drop(index = 20) doing?\n",
    "    agg_games_df = agg_games_df.drop(index = 20, axis=0)\n",
    "    return agg_games_df\n",
    "\n",
    "def get_elo():\n",
    "    elo_df = pd.read_csv('https://projects.fivethirtyeight.com/nfl-api/nfl_elo_latest.csv')\n",
    "    elo_df = elo_df.drop(columns = ['season','neutral' ,'playoff', 'elo_prob1', 'elo_prob2', 'elo1_post', 'elo2_post',\n",
    "           'qbelo1_pre', 'qbelo2_pre', 'qb1', 'qb2', 'qb1_adj', 'qb2_adj', 'qbelo_prob1', 'qbelo_prob2',\n",
    "           'qb1_game_value', 'qb2_game_value', 'qb1_value_post', 'qb2_value_post',\n",
    "           'qbelo1_post', 'qbelo2_post', 'score1', 'score2', 'quality', 'importance', 'total_rating'])\n",
    "    elo_df.date = pd.to_datetime(elo_df.date)\n",
    "    elo_df = elo_df[elo_df.date < '01-05-2022']\n",
    "\n",
    "    elo_df['team1'] = elo_df['team1'].replace(['KC', 'JAX', 'CAR', 'BAL', 'BUF', 'MIN', 'DET', 'ATL', 'NE', 'WSH',\n",
    "           'CIN', 'NO', 'SF', 'LAR', 'NYG', 'DEN', 'CLE', 'IND', 'TEN', 'NYJ',\n",
    "           'TB', 'MIA', 'PIT', 'PHI', 'GB', 'CHI', 'DAL', 'ARI', 'LAC', 'HOU',\n",
    "           'SEA', 'OAK'],\n",
    "            ['kan','jax','car', 'rav', 'buf', 'min', 'det', 'atl', 'nwe', 'was', \n",
    "            'cin', 'nor', 'sfo', 'ram', 'nyg', 'den', 'cle', 'clt', 'oti', 'nyj', \n",
    "             'tam','mia', 'pit', 'phi', 'gnb', 'chi', 'dal', 'crd', 'sdg', 'htx', 'sea', 'rai' ])\n",
    "    elo_df['team2'] = elo_df['team2'].replace(['KC', 'JAX', 'CAR', 'BAL', 'BUF', 'MIN', 'DET', 'ATL', 'NE', 'WSH',\n",
    "           'CIN', 'NO', 'SF', 'LAR', 'NYG', 'DEN', 'CLE', 'IND', 'TEN', 'NYJ',\n",
    "           'TB', 'MIA', 'PIT', 'PHI', 'GB', 'CHI', 'DAL', 'ARI', 'LAC', 'HOU',\n",
    "           'SEA', 'OAK'],\n",
    "            ['kan','jax','car', 'rav', 'buf', 'min', 'det', 'atl', 'nwe', 'was', \n",
    "            'cin', 'nor', 'sfo', 'ram', 'nyg', 'den', 'cle', 'clt', 'oti', 'nyj', \n",
    "             'tam','mia', 'pit', 'phi', 'gnb', 'chi', 'dal', 'crd', 'sdg', 'htx', 'sea', 'rai' ])\n",
    "    return elo_df\n",
    "\n",
    "def merge_rankings(agg_games_df,elo_df):\n",
    "    agg_games_df = pd.merge(agg_games_df, elo_df, how = 'inner', left_on = ['home_abbr', 'away_abbr'], right_on = ['team1', 'team2']).drop(columns = ['date','team1', 'team2'])\n",
    "    agg_games_df['elo_dif'] = agg_games_df['elo2_pre'] - agg_games_df['elo1_pre']\n",
    "    agg_games_df['qb_dif'] = agg_games_df['qb2_value_pre'] - agg_games_df['qb1_value_pre']\n",
    "    agg_games_df = agg_games_df.drop(columns = ['elo1_pre', 'elo2_pre', 'qb1_value_pre', 'qb2_value_pre'])\n",
    "    return agg_games_df\n",
    "\n",
    "def prep_test_train(current_week,weeks,year):\n",
    "    current_week = current_week + 1\n",
    "    schedule_df  = get_schedule(year)\n",
    "    weeks_games_df = game_data_up_to_week(weeks,year)\n",
    "    agg_games_df = agg_weekly_data(schedule_df,weeks_games_df,current_week,weeks)\n",
    "    elo_df = get_elo()\n",
    "    agg_games_df = merge_rankings(agg_games_df, elo_df)\n",
    "    train_df = agg_games_df[agg_games_df.result.notna()]\n",
    "    current_week = current_week - 1\n",
    "    test_df = agg_games_df[agg_games_df.week == current_week]\n",
    "    return test_df, train_df\n",
    "\n",
    "def display(y_pred,X_test):\n",
    "    for g in range(len(y_pred)):\n",
    "        #win_prob = np.round(y_pred[g],2)\n",
    "        win_prob = int(y_pred[g] * 100)\n",
    "        away_team = X_test.reset_index().drop(columns = 'index').loc[g,'away_name']\n",
    "        home_team = X_test.reset_index().drop(columns = 'index').loc[g,'home_name']\n",
    "        print(f'The {away_team} have a probability of {win_prob}% of beating the {home_team}.')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Get all the data for 2021, up to the current week 13"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 195,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Week 10 games have not finished yet.\n"
     ]
    }
   ],
   "source": [
    "# this step takes about five minutes to run \n",
    "current_week = 13\n",
    "weeks = list(range(1,current_week + 1))\n",
    "year = 2021\n",
    "\n",
    "pred_games_df, comp_games_df = prep_test_train(current_week,weeks,year)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Write out 2021 info, so I don't have to load it all the time\n",
    "df = pd.concat([comp_games_df, pred_games_df], axis=0)\n",
    "df.to_csv(\"2021_week_2_through_13.csv\", index = False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [],
   "source": [
    "# read the full dataframe in and drop an unneeded column\n",
    "df = pd.read_csv('2021_week_2_through_13.csv')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Logistic Regression"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Logistic Regression Predictions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 242,
   "metadata": {},
   "outputs": [],
   "source": [
    "pred_week = 13\n",
    "comp_games_df = df[df['week'] < pred_week]\n",
    "pred_games_df = df[df['week'] == pred_week]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 243,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_df = comp_games_df\n",
    "test_df = pred_games_df\n",
    "\n",
    "X_train = train_df.drop(columns = ['away_name', 'away_abbr', 'home_name', 'home_abbr', 'week','result'])\n",
    "y_train = train_df[['result']] \n",
    "X_test = test_df.drop(columns = ['away_name', 'away_abbr', 'home_name', 'home_abbr', 'week','result'])\n",
    "y_test = test_df[['result']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 244,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create a StandardScaler instance\n",
    "scaler = StandardScaler()\n",
    "\n",
    "# Fit the scaler to the features training dataset\n",
    "X_scaler = scaler.fit(X_train)\n",
    "\n",
    "# Fit the scaler to the features training dataset\n",
    "X_train_scaled = X_scaler.transform(X_train)\n",
    "X_test_scaled = X_scaler.transform(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 264,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Logistic Regression - Unscaled\n",
      "\n",
      "The Los Angeles Rams have a probability of 0.13% of beating the Seattle Seahawks.\n",
      "The New York Jets have a probability of 0.98% of beating the Atlanta Falcons.\n",
      "The Philadelphia Eagles have a probability of 0.58% of beating the Carolina Panthers.\n",
      "The New Orleans Saints have a probability of 0.79% of beating the Washington Football Team.\n",
      "The Miami Dolphins have a probability of 0.15% of beating the Tampa Bay Buccaneers.\n",
      "The Denver Broncos have a probability of 0.96% of beating the Pittsburgh Steelers.\n",
      "The Detroit Lions have a probability of 0.78% of beating the Minnesota Vikings.\n",
      "The Tennessee Titans have a probability of 0.67% of beating the Jacksonville Jaguars.\n",
      "The New England Patriots have a probability of 0.93% of beating the Houston Texans.\n",
      "The Green Bay Packers have a probability of 0.06% of beating the Cincinnati Bengals.\n",
      "The Cleveland Browns have a probability of 0.94% of beating the Los Angeles Chargers.\n",
      "The Chicago Bears have a probability of 0.24% of beating the Las Vegas Raiders.\n",
      "The New York Giants have a probability of 0.38% of beating the Dallas Cowboys.\n",
      "The San Francisco 49ers have a probability of 0.01% of beating the Arizona Cardinals.\n",
      "The Buffalo Bills have a probability of 0.01% of beating the Kansas City Chiefs.\n",
      "The Indianapolis Colts have a probability of 0.01% of beating the Baltimore Ravens.\n",
      "\n",
      "Logistic Regression - Scaled\n",
      "\n",
      "The Los Angeles Rams have a probability of 0.56% of beating the Seattle Seahawks.\n",
      "The New York Jets have a probability of 0.54% of beating the Atlanta Falcons.\n",
      "The Philadelphia Eagles have a probability of 0.32% of beating the Carolina Panthers.\n",
      "The New Orleans Saints have a probability of 0.62% of beating the Washington Football Team.\n",
      "The Miami Dolphins have a probability of 0.19% of beating the Tampa Bay Buccaneers.\n",
      "The Denver Broncos have a probability of 0.66% of beating the Pittsburgh Steelers.\n",
      "The Detroit Lions have a probability of 0.37% of beating the Minnesota Vikings.\n",
      "The Tennessee Titans have a probability of 0.79% of beating the Jacksonville Jaguars.\n",
      "The New England Patriots have a probability of 0.72% of beating the Houston Texans.\n",
      "The Green Bay Packers have a probability of 0.59% of beating the Cincinnati Bengals.\n",
      "The Cleveland Browns have a probability of 0.66% of beating the Los Angeles Chargers.\n",
      "The Chicago Bears have a probability of 0.26% of beating the Las Vegas Raiders.\n",
      "The New York Giants have a probability of 0.29% of beating the Dallas Cowboys.\n",
      "The San Francisco 49ers have a probability of 0.1% of beating the Arizona Cardinals.\n",
      "The Buffalo Bills have a probability of 0.44% of beating the Kansas City Chiefs.\n",
      "The Indianapolis Colts have a probability of 0.09% of beating the Baltimore Ravens.\n"
     ]
    }
   ],
   "source": [
    "# Logistic Model\n",
    "clf_unscaled = LogisticRegression(penalty='l1', dual=False, tol=0.001, C=1.0, fit_intercept=True, \n",
    "                   intercept_scaling=1, class_weight='balanced', random_state=None, \n",
    "                   solver='liblinear', max_iter=1000, multi_class='ovr', verbose=0)\n",
    "\n",
    "clf_scaled = LogisticRegression(penalty='l1', dual=False, tol=0.001, C=1.0, fit_intercept=True, \n",
    "                   intercept_scaling=1, class_weight='balanced', random_state=None, \n",
    "                   solver='liblinear', max_iter=1000, multi_class='ovr', verbose=0)\n",
    "\n",
    "clf_unscaled.fit(X_train, np.ravel(y_train.values))\n",
    "clf_scaled.fit(X_train_scaled, np.ravel(y_train.values))\n",
    "\n",
    "y_pred_unscaled = clf_unscaled.predict_proba(X_test)\n",
    "y_pred_scaled = clf_scaled.predict_proba(X_test_scaled)\n",
    "\n",
    "y_pred_unscaled = y_pred_unscaled[:,1]\n",
    "y_pred_scaled = y_pred_scaled[:,1]\n",
    "\n",
    "print(\"Logistic Regression - Unscaled\\n\")\n",
    "display(y_pred_unscaled,test_df)\n",
    "\n",
    "print(\"\\nLogistic Regression - Scaled\\n\")\n",
    "display(y_pred_scaled,test_df)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Get Logistic Regression Accuracy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 372,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# make a for loop to the get accuracy for each week\n",
    "def accuracy_score_log_reg(df):\n",
    "    \n",
    "    accuracy = pd.DataFrame(columns=['week', 'Logistic Regression Accuracy - Unscaled', 'Logistic Regeression Accuracy - Scaled'])\n",
    "    \n",
    "    for w in df['week'].unique()[1:-1]:\n",
    "        train_df = df[df['week'] < w]\n",
    "        test_df = df[df['week'] == w]\n",
    "        \n",
    "        X_train = train_df.drop(columns = ['away_name', 'away_abbr', 'home_name', 'home_abbr', 'week','result'])\n",
    "        y_train = train_df[['result']] \n",
    "        X_test = test_df.drop(columns = ['away_name', 'away_abbr', 'home_name', 'home_abbr', 'week','result'])\n",
    "        y_test = test_df[['result']]\n",
    "        \n",
    "        # Create a StandardScaler instance\n",
    "        scaler = StandardScaler()\n",
    "\n",
    "        # Fit the scaler to the features training dataset\n",
    "        X_scaler = scaler.fit(X_train)\n",
    "\n",
    "        # Fit the scaler to the features training dataset\n",
    "        X_train_scaled = X_scaler.transform(X_train)\n",
    "        X_test_scaled = X_scaler.transform(X_test)\n",
    "        \n",
    "        clf = LogisticRegression(penalty='l1', dual=False, tol=0.001, C=1.0, fit_intercept=True, \n",
    "                   intercept_scaling=1, class_weight='balanced', random_state=None, \n",
    "                   solver='liblinear', max_iter=1000, multi_class='ovr', verbose=0)\n",
    "\n",
    "        clf.fit(X_train, np.ravel(y_train.values))\n",
    "        clf.fit(X_train_scaled, np.ravel(y_train.values))\n",
    "        \n",
    "        y_pred_unscaled = clf.predict_proba(X_test)\n",
    "        y_pred_scaled = clf.predict_proba(X_test_scaled)\n",
    "        \n",
    "        y_pred_unscaled = y_pred_unscaled[:,1]\n",
    "        y_pred_scaled = y_pred_scaled[:,1]\n",
    "        \n",
    "        accuracy_score_unscaled = accuracy_score(y_test,np.round(y_pred_unscaled))\n",
    "        accuracy_score_scaled = accuracy_score(y_test,np.round(y_pred_scaled))\n",
    "        \n",
    "        accuracy.loc[w,:] = [w, accuracy_score_unscaled, accuracy_score_scaled]\n",
    "        \n",
    "    return(accuracy)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 373,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>week</th>\n",
       "      <th>Logistic Regression Accuracy - Unscaled</th>\n",
       "      <th>Logistic Regeression Accuracy - Scaled</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>3</td>\n",
       "      <td>0.533333</td>\n",
       "      <td>0.466667</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>4</td>\n",
       "      <td>0.5625</td>\n",
       "      <td>0.6875</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>5</td>\n",
       "      <td>0.75</td>\n",
       "      <td>0.625</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>6</td>\n",
       "      <td>0.785714</td>\n",
       "      <td>0.857143</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>7</td>\n",
       "      <td>0.769231</td>\n",
       "      <td>0.769231</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>8</td>\n",
       "      <td>0.533333</td>\n",
       "      <td>0.466667</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>9</td>\n",
       "      <td>0.642857</td>\n",
       "      <td>0.714286</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>11</td>\n",
       "      <td>0.533333</td>\n",
       "      <td>0.733333</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>12</td>\n",
       "      <td>0.533333</td>\n",
       "      <td>0.666667</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   week Logistic Regression Accuracy - Unscaled  \\\n",
       "3     3                                0.533333   \n",
       "4     4                                  0.5625   \n",
       "5     5                                    0.75   \n",
       "6     6                                0.785714   \n",
       "7     7                                0.769231   \n",
       "8     8                                0.533333   \n",
       "9     9                                0.642857   \n",
       "11   11                                0.533333   \n",
       "12   12                                0.533333   \n",
       "\n",
       "   Logistic Regeression Accuracy - Scaled  \n",
       "3                                0.466667  \n",
       "4                                  0.6875  \n",
       "5                                   0.625  \n",
       "6                                0.857143  \n",
       "7                                0.769231  \n",
       "8                                0.466667  \n",
       "9                                0.714286  \n",
       "11                               0.733333  \n",
       "12                               0.666667  "
      ]
     },
     "execution_count": 373,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "logistic_regression_accuracy = accuracy_score_log_reg(df)\n",
    "logistic_regression_accuracy"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "tags": []
   },
   "source": [
    "# Tensorflow "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Tensorflow Predictions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 115,
   "metadata": {},
   "outputs": [],
   "source": [
    "# load a previously built model.\n",
    "nn = tf.keras.models.load_model(\"Resources/model_nn_2021_1_12_not_scaled_relu_relu_sigmoid_loss='binary_crossentropy', optimizer='adam', metrics=['accuracy']_1000 epochs.h5\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 290,
   "metadata": {},
   "outputs": [],
   "source": [
    "pred_week = 13\n",
    "comp_games_df = df[df['week'] < pred_week]\n",
    "pred_games_df = df[df['week'] == pred_week]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 302,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_df = comp_games_df\n",
    "test_df = pred_games_df\n",
    "\n",
    "X_train = train_df.drop(columns = ['away_name', 'away_abbr', 'home_name', 'home_abbr', 'week','result'])\n",
    "y_train = train_df[['result']] \n",
    "X_test = test_df.drop(columns = ['away_name', 'away_abbr', 'home_name', 'home_abbr', 'week','result'])\n",
    "y_test = test_df[['result']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 303,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create a StandardScaler instance\n",
    "scaler = StandardScaler()\n",
    "\n",
    "# Fit the scaler to the features training dataset\n",
    "X_scaler = scaler.fit(X_train)\n",
    "\n",
    "# Fit the scaler to the features training dataset\n",
    "X_train_scaled = X_scaler.transform(X_train)\n",
    "X_test_scaled = X_scaler.transform(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 304,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Tensorflow - Unscaled \n",
      "\n",
      "The Dallas Cowboys have a probability of 99% of beating the New Orleans Saints.\n",
      "The Arizona Cardinals have a probability of 59% of beating the Chicago Bears.\n",
      "The Tampa Bay Buccaneers have a probability of 59% of beating the Atlanta Falcons.\n",
      "The Philadelphia Eagles have a probability of 28% of beating the New York Jets.\n",
      "The New York Giants have a probability of 43% of beating the Miami Dolphins.\n",
      "The Denver Broncos have a probability of 0% of beating the Kansas City Chiefs.\n",
      "The Indianapolis Colts have a probability of 59% of beating the Houston Texans.\n",
      "The Minnesota Vikings have a probability of 35% of beating the Detroit Lions.\n",
      "The Los Angeles Chargers have a probability of 4% of beating the Cincinnati Bengals.\n",
      "The Washington Football Team have a probability of 31% of beating the Las Vegas Raiders.\n",
      "The Jacksonville Jaguars have a probability of 0% of beating the Los Angeles Rams.\n",
      "The Baltimore Ravens have a probability of 59% of beating the Pittsburgh Steelers.\n",
      "The San Francisco 49ers have a probability of 59% of beating the Seattle Seahawks.\n",
      "The New England Patriots have a probability of 2% of beating the Buffalo Bills.\n",
      "\n",
      "Tensorflow - Scaled \n",
      "\n",
      "The Dallas Cowboys have a probability of 71% of beating the New Orleans Saints.\n",
      "The Arizona Cardinals have a probability of 50% of beating the Chicago Bears.\n",
      "The Tampa Bay Buccaneers have a probability of 54% of beating the Atlanta Falcons.\n",
      "The Philadelphia Eagles have a probability of 58% of beating the New York Jets.\n",
      "The New York Giants have a probability of 59% of beating the Miami Dolphins.\n",
      "The Denver Broncos have a probability of 48% of beating the Kansas City Chiefs.\n",
      "The Indianapolis Colts have a probability of 59% of beating the Houston Texans.\n",
      "The Minnesota Vikings have a probability of 61% of beating the Detroit Lions.\n",
      "The Los Angeles Chargers have a probability of 59% of beating the Cincinnati Bengals.\n",
      "The Washington Football Team have a probability of 59% of beating the Las Vegas Raiders.\n",
      "The Jacksonville Jaguars have a probability of 62% of beating the Los Angeles Rams.\n",
      "The Baltimore Ravens have a probability of 69% of beating the Pittsburgh Steelers.\n",
      "The San Francisco 49ers have a probability of 69% of beating the Seattle Seahawks.\n",
      "The New England Patriots have a probability of 58% of beating the Buffalo Bills.\n"
     ]
    }
   ],
   "source": [
    "# Evaluate the model loss and accuracy metrics using the evaluate method and the test data        \n",
    "nn_predictions_unscaled = nn.predict(X_test)       \n",
    "nn_predictions_scaled = nn.predict(X_test_scaled)\n",
    "\n",
    "print(\"Tensorflow - Unscaled \\n\")\n",
    "display(nn_predictions_unscaled.squeeze(),test_df)\n",
    "\n",
    "print(\"\\nTensorflow - Scaled \\n\")\n",
    "display(nn_predictions_scaled.squeeze(),test_df)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Tensorflow Accuracy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 184,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# make a for loop to the get accuracy for each week\n",
    "def accuracy_score_tensorflow(df):\n",
    "    \n",
    "    accuracy = pd.DataFrame(columns=['week', 'Tensorflow Accuracy - Unscaled', 'Tensorflow Accuracy - Scaled'])\n",
    "    \n",
    "    for w in df['week'].unique()[1:-1]:\n",
    "        train_df = df[df['week'] < w]\n",
    "        test_df = df[df['week'] == w]\n",
    "        \n",
    "        X_train = train_df.drop(columns = ['away_name', 'away_abbr', 'home_name', 'home_abbr', 'week','result'])\n",
    "        y_train = train_df[['result']] \n",
    "        X_test = test_df.drop(columns = ['away_name', 'away_abbr', 'home_name', 'home_abbr', 'week','result'])\n",
    "        y_test = test_df[['result']]\n",
    "        \n",
    "        # Create a StandardScaler instance\n",
    "        scaler = StandardScaler()\n",
    "\n",
    "        # Fit the scaler to the features training dataset\n",
    "        X_scaler = scaler.fit(X_train)\n",
    "\n",
    "        # Fit the scaler to the features training dataset\n",
    "        X_train_scaled = X_scaler.transform(X_train)\n",
    "        X_test_scaled = X_scaler.transform(X_test)\n",
    "        \n",
    "        # Evaluate the model loss and accuracy metrics using the evaluate method and the test data        \n",
    "        model_accuracy_unscaled = nn.evaluate(X_test, y_test, verbose=0)       \n",
    "        model_accuracy_scaled = nn.evaluate(X_test_scaled, y_test, verbose=0)\n",
    "    \n",
    "        # Assign the accuracy to \n",
    "        accuracy.loc[w,:] = [w, model_accuracy_unscaled[1], model_accuracy_scaled[1]]\n",
    "        \n",
    "    return(accuracy)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 185,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>week</th>\n",
       "      <th>Tensorflow Accuracy - Unscaled</th>\n",
       "      <th>Tensorflow Accuracy - Scaled</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>3</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.6</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>4</td>\n",
       "      <td>0.875</td>\n",
       "      <td>0.5625</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>5</td>\n",
       "      <td>0.875</td>\n",
       "      <td>0.625</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>6</td>\n",
       "      <td>0.5</td>\n",
       "      <td>0.642857</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>7</td>\n",
       "      <td>0.615385</td>\n",
       "      <td>0.538462</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>8</td>\n",
       "      <td>0.533333</td>\n",
       "      <td>0.733333</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>9</td>\n",
       "      <td>0.571429</td>\n",
       "      <td>0.428571</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>11</td>\n",
       "      <td>0.6</td>\n",
       "      <td>0.666667</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>12</td>\n",
       "      <td>0.266667</td>\n",
       "      <td>0.4</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   week Tensorflow Accuracy - Unscaled Tensorflow Accuracy - Scaled\n",
       "3     3                            1.0                          0.6\n",
       "4     4                          0.875                       0.5625\n",
       "5     5                          0.875                        0.625\n",
       "6     6                            0.5                     0.642857\n",
       "7     7                       0.615385                     0.538462\n",
       "8     8                       0.533333                     0.733333\n",
       "9     9                       0.571429                     0.428571\n",
       "11   11                            0.6                     0.666667\n",
       "12   12                       0.266667                          0.4"
      ]
     },
     "execution_count": 185,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Run the accuracy_score_Tensorflow function to get an array of accuracies\n",
    "tensorflow_accuracy = accuracy_score_tensorflow_scaled(df)\n",
    "tensorflow_accuracy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 205,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>week</th>\n",
       "      <th>Logistic Regression Accuracy - Unscaled</th>\n",
       "      <th>Logistic Regeression Accuracy - Scaled</th>\n",
       "      <th>Tensorflow Accuracy - Unscaled</th>\n",
       "      <th>Tensorflow Accuracy - Scaled</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>3</td>\n",
       "      <td>0.6</td>\n",
       "      <td>0.466667</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.6</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>4</td>\n",
       "      <td>0.5625</td>\n",
       "      <td>0.6875</td>\n",
       "      <td>0.875</td>\n",
       "      <td>0.5625</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>5</td>\n",
       "      <td>0.75</td>\n",
       "      <td>0.625</td>\n",
       "      <td>0.875</td>\n",
       "      <td>0.625</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>6</td>\n",
       "      <td>0.785714</td>\n",
       "      <td>0.857143</td>\n",
       "      <td>0.5</td>\n",
       "      <td>0.642857</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>7</td>\n",
       "      <td>0.769231</td>\n",
       "      <td>0.769231</td>\n",
       "      <td>0.615385</td>\n",
       "      <td>0.538462</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>8</td>\n",
       "      <td>0.533333</td>\n",
       "      <td>0.466667</td>\n",
       "      <td>0.533333</td>\n",
       "      <td>0.733333</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>9</td>\n",
       "      <td>0.642857</td>\n",
       "      <td>0.714286</td>\n",
       "      <td>0.571429</td>\n",
       "      <td>0.428571</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>11</td>\n",
       "      <td>0.533333</td>\n",
       "      <td>0.733333</td>\n",
       "      <td>0.6</td>\n",
       "      <td>0.666667</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>12</td>\n",
       "      <td>0.533333</td>\n",
       "      <td>0.666667</td>\n",
       "      <td>0.266667</td>\n",
       "      <td>0.4</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   week Logistic Regression Accuracy - Unscaled  \\\n",
       "3     3                                     0.6   \n",
       "4     4                                  0.5625   \n",
       "5     5                                    0.75   \n",
       "6     6                                0.785714   \n",
       "7     7                                0.769231   \n",
       "8     8                                0.533333   \n",
       "9     9                                0.642857   \n",
       "11   11                                0.533333   \n",
       "12   12                                0.533333   \n",
       "\n",
       "   Logistic Regeression Accuracy - Scaled Tensorflow Accuracy - Unscaled  \\\n",
       "3                                0.466667                            1.0   \n",
       "4                                  0.6875                          0.875   \n",
       "5                                   0.625                          0.875   \n",
       "6                                0.857143                            0.5   \n",
       "7                                0.769231                       0.615385   \n",
       "8                                0.466667                       0.533333   \n",
       "9                                0.714286                       0.571429   \n",
       "11                               0.733333                            0.6   \n",
       "12                               0.666667                       0.266667   \n",
       "\n",
       "   Tensorflow Accuracy - Scaled  \n",
       "3                           0.6  \n",
       "4                        0.5625  \n",
       "5                         0.625  \n",
       "6                      0.642857  \n",
       "7                      0.538462  \n",
       "8                      0.733333  \n",
       "9                      0.428571  \n",
       "11                     0.666667  \n",
       "12                          0.4  "
      ]
     },
     "execution_count": 205,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pd.concat(\n",
    "    [logistic_regression_accuracy, tensorflow_accuracy.drop(columns=['week'])], axis=1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Random Forest Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 392,
   "metadata": {},
   "outputs": [],
   "source": [
    "pred_week = 13\n",
    "comp_games_df = df[df['week'] < pred_week]\n",
    "pred_games_df = df[df['week'] == pred_week]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 393,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_df = comp_games_df\n",
    "test_df = pred_games_df\n",
    "\n",
    "X_train = train_df.drop(columns = ['away_name', 'away_abbr', 'home_name', 'home_abbr', 'week','result'])\n",
    "y_train = train_df[['result']] \n",
    "X_test = test_df.drop(columns = ['away_name', 'away_abbr', 'home_name', 'home_abbr', 'week','result'])\n",
    "y_test = test_df[['result']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 394,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "RandomForest - Unscaled \n",
      "\n",
      "The Dallas Cowboys have a probability of 10% of beating the New Orleans Saints.\n",
      "The Arizona Cardinals have a probability of 26% of beating the Chicago Bears.\n",
      "The Tampa Bay Buccaneers have a probability of 27% of beating the Atlanta Falcons.\n",
      "The Philadelphia Eagles have a probability of 55% of beating the New York Jets.\n",
      "The New York Giants have a probability of 64% of beating the Miami Dolphins.\n",
      "The Denver Broncos have a probability of 84% of beating the Kansas City Chiefs.\n",
      "The Indianapolis Colts have a probability of 22% of beating the Houston Texans.\n",
      "The Minnesota Vikings have a probability of 38% of beating the Detroit Lions.\n",
      "The Los Angeles Chargers have a probability of 44% of beating the Cincinnati Bengals.\n",
      "The Washington Football Team have a probability of 47% of beating the Las Vegas Raiders.\n",
      "The Jacksonville Jaguars have a probability of 80% of beating the Los Angeles Rams.\n",
      "The Baltimore Ravens have a probability of 34% of beating the Pittsburgh Steelers.\n",
      "The San Francisco 49ers have a probability of 15% of beating the Seattle Seahawks.\n",
      "The New England Patriots have a probability of 50% of beating the Buffalo Bills.\n"
     ]
    }
   ],
   "source": [
    "# Create a random forest classifier\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.metrics import classification_report\n",
    "\n",
    "rf_model = RandomForestClassifier(n_estimators=100, random_state=1)\n",
    "\n",
    "# Fitting the model\n",
    "rf_fitted = rf_model.fit(X_train, np.ravel(y_train.values))\n",
    "\n",
    "# Making predictions using the testing data\n",
    "y_pred = rf_fitted.predict_proba(X_test)\n",
    "y_pred = y_pred[:,0]\n",
    "\n",
    "print(\"RandomForest - Unscaled \\n\")\n",
    "display(y_pred, test_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 395,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# make a for loop to the get accuracy for each week\n",
    "def accuracy_score_random_forest(df):\n",
    "    \n",
    "    accuracy = pd.DataFrame(columns=['week', 'Random Forest Accuracy'])\n",
    "    \n",
    "    for w in df['week'].unique()[1:-1]:\n",
    "        train_df = df[df['week'] < w]\n",
    "        test_df = df[df['week'] == w]\n",
    "        \n",
    "        X_train = train_df.drop(columns = ['away_name', 'away_abbr', 'home_name', 'home_abbr', 'week','result'])\n",
    "        y_train = train_df[['result']] \n",
    "        X_test = test_df.drop(columns = ['away_name', 'away_abbr', 'home_name', 'home_abbr', 'week','result'])\n",
    "        y_test = test_df[['result']]\n",
    "        \n",
    "        # Fitting the model\n",
    "        classifier = RandomForestClassifier(n_estimators=100, random_state=0)\n",
    "        classifier.fit(X_train, np.ravel(y_train.values))\n",
    "        y_pred = classifier.predict(X_test)\n",
    "        \n",
    "        model_accuracy = accuracy_score(y_test, y_pred)\n",
    "\n",
    "        # Assign the accuracy to \n",
    "        accuracy.loc[w,:] = [w, model_accuracy]\n",
    "        \n",
    "    return(accuracy)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 396,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>week</th>\n",
       "      <th>Random Forest Accuracy</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>3</td>\n",
       "      <td>0.666667</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>4</td>\n",
       "      <td>0.5625</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>5</td>\n",
       "      <td>0.75</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>6</td>\n",
       "      <td>0.714286</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>7</td>\n",
       "      <td>0.769231</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>8</td>\n",
       "      <td>0.533333</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>9</td>\n",
       "      <td>0.642857</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>11</td>\n",
       "      <td>0.8</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>12</td>\n",
       "      <td>0.466667</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   week Random Forest Accuracy\n",
       "3     3               0.666667\n",
       "4     4                 0.5625\n",
       "5     5                   0.75\n",
       "6     6               0.714286\n",
       "7     7               0.769231\n",
       "8     8               0.533333\n",
       "9     9               0.642857\n",
       "11   11                    0.8\n",
       "12   12               0.466667"
      ]
     },
     "execution_count": 396,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "random_forest_accuracy = accuracy_score_random_forest(df)\n",
    "random_forest_accuracy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 398,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   week Logistic Regression Accuracy - Unscaled  \\\n",
      "3     3                                0.533333   \n",
      "4     4                                  0.5625   \n",
      "5     5                                    0.75   \n",
      "6     6                                0.785714   \n",
      "7     7                                0.769231   \n",
      "8     8                                0.533333   \n",
      "9     9                                0.642857   \n",
      "11   11                                0.533333   \n",
      "12   12                                0.533333   \n",
      "\n",
      "   Logistic Regeression Accuracy - Scaled Tensorflow Accuracy - Unscaled  \\\n",
      "3                                0.466667                            1.0   \n",
      "4                                  0.6875                          0.875   \n",
      "5                                   0.625                          0.875   \n",
      "6                                0.857143                            0.5   \n",
      "7                                0.769231                       0.615385   \n",
      "8                                0.466667                       0.533333   \n",
      "9                                0.714286                       0.571429   \n",
      "11                               0.733333                            0.6   \n",
      "12                               0.666667                       0.266667   \n",
      "\n",
      "   Tensorflow Accuracy - Scaled Random Forest Accuracy  \n",
      "3                           0.6               0.666667  \n",
      "4                        0.5625                 0.5625  \n",
      "5                         0.625                   0.75  \n",
      "6                      0.642857               0.714286  \n",
      "7                      0.538462               0.769231  \n",
      "8                      0.733333               0.533333  \n",
      "9                      0.428571               0.642857  \n",
      "11                     0.666667                    0.8  \n",
      "12                          0.4               0.466667  \n"
     ]
    }
   ],
   "source": [
    "print(pd.concat(\n",
    "    [logistic_regression_accuracy, \n",
    "     tensorflow_accuracy.drop(columns=['week']),\n",
    "     random_forest_accuracy.drop(columns=['week'])], \n",
    "    axis=1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
