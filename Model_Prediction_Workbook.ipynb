{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import required libraries.\n",
    "from sportsipy.nfl.boxscore import Boxscores, Boxscore\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import hvplot.pandas\n",
    "\n",
    "pd.set_option('display.max_columns', None)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Add Display & Get_Schedule Function for use in model outputs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_schedule(year):\n",
    "    weeks = list(range(1,18))\n",
    "    schedule_df = pd.DataFrame()\n",
    "    for w in range(len(weeks)):\n",
    "        date_string = str(weeks[w]) + '-' + str(year)\n",
    "        week_scores = Boxscores(weeks[w],year)\n",
    "        week_games_df = pd.DataFrame()\n",
    "        for g in range(len(week_scores.games[date_string])):\n",
    "            game = pd.DataFrame(week_scores.games[date_string][g], index = [0])[['away_name', 'away_abbr','home_name', 'home_abbr','winning_name', 'winning_abbr' ]]\n",
    "            game['week'] = weeks[w]\n",
    "            week_games_df = pd.concat([week_games_df,game])\n",
    "        schedule_df = pd.concat([schedule_df, week_games_df]).reset_index().drop(columns = 'index') \n",
    "    return schedule_df\n",
    "\n",
    "def display(y_pred,X_test):\n",
    "    for g in range(len(y_pred)):\n",
    "        #win_prob = np.round(y_pred[g],2)\n",
    "        win_prob = int(y_pred[g] * 100)\n",
    "        away_team = X_test.reset_index().drop(columns = 'index').loc[g,'away_name']\n",
    "        home_team = X_test.reset_index().drop(columns = 'index').loc[g,'home_name']\n",
    "        print(f'The {away_team} have a probability of {win_prob}% of beating the {home_team}.')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Read in Dataset from csv"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>away_name</th>\n",
       "      <th>away_abbr</th>\n",
       "      <th>home_name</th>\n",
       "      <th>home_abbr</th>\n",
       "      <th>week</th>\n",
       "      <th>win_perc_dif</th>\n",
       "      <th>first_downs_dif</th>\n",
       "      <th>fumbles_dif</th>\n",
       "      <th>interceptions_dif</th>\n",
       "      <th>net_pass_yards_dif</th>\n",
       "      <th>pass_attempts_dif</th>\n",
       "      <th>pass_completions_dif</th>\n",
       "      <th>pass_touchdowns_dif</th>\n",
       "      <th>pass_yards_dif</th>\n",
       "      <th>penalties_dif</th>\n",
       "      <th>points_dif</th>\n",
       "      <th>rush_attempts_dif</th>\n",
       "      <th>rush_touchdowns_dif</th>\n",
       "      <th>rush_yards_dif</th>\n",
       "      <th>time_of_possession_dif</th>\n",
       "      <th>times_sacked_dif</th>\n",
       "      <th>total_yards_dif</th>\n",
       "      <th>turnovers_dif</th>\n",
       "      <th>yards_from_penalties_dif</th>\n",
       "      <th>yards_lost_from_sacks_dif</th>\n",
       "      <th>fourth_down_perc_dif</th>\n",
       "      <th>third_down_perc_dif</th>\n",
       "      <th>result</th>\n",
       "      <th>elo_dif</th>\n",
       "      <th>qb_dif</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>186</th>\n",
       "      <td>New York Giants</td>\n",
       "      <td>nyg</td>\n",
       "      <td>Los Angeles Chargers</td>\n",
       "      <td>sdg</td>\n",
       "      <td>14</td>\n",
       "      <td>-0.250000</td>\n",
       "      <td>-4.000000</td>\n",
       "      <td>0.666667</td>\n",
       "      <td>-0.083333</td>\n",
       "      <td>-60.083333</td>\n",
       "      <td>-3.333333</td>\n",
       "      <td>-3.500000</td>\n",
       "      <td>-1.333333</td>\n",
       "      <td>-58.416667</td>\n",
       "      <td>-1.500000</td>\n",
       "      <td>-8.583333</td>\n",
       "      <td>0.583333</td>\n",
       "      <td>-0.333333</td>\n",
       "      <td>-10.166667</td>\n",
       "      <td>-1.250000</td>\n",
       "      <td>0.083333</td>\n",
       "      <td>-70.250000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>-16.500000</td>\n",
       "      <td>1.666667</td>\n",
       "      <td>-0.119048</td>\n",
       "      <td>-0.080808</td>\n",
       "      <td>0.0</td>\n",
       "      <td>-110.229362</td>\n",
       "      <td>-126.445654</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>187</th>\n",
       "      <td>Detroit Lions</td>\n",
       "      <td>det</td>\n",
       "      <td>Denver Broncos</td>\n",
       "      <td>den</td>\n",
       "      <td>14</td>\n",
       "      <td>-0.409091</td>\n",
       "      <td>-0.916667</td>\n",
       "      <td>0.416667</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>-24.833333</td>\n",
       "      <td>1.416667</td>\n",
       "      <td>0.916667</td>\n",
       "      <td>-0.250000</td>\n",
       "      <td>-20.333333</td>\n",
       "      <td>1.500000</td>\n",
       "      <td>-2.833333</td>\n",
       "      <td>-1.666667</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>-8.166667</td>\n",
       "      <td>-165.000000</td>\n",
       "      <td>-0.083333</td>\n",
       "      <td>-33.000000</td>\n",
       "      <td>0.083333</td>\n",
       "      <td>9.333333</td>\n",
       "      <td>4.500000</td>\n",
       "      <td>-0.195971</td>\n",
       "      <td>-0.052985</td>\n",
       "      <td>0.0</td>\n",
       "      <td>-173.770079</td>\n",
       "      <td>-0.964572</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>188</th>\n",
       "      <td>Buffalo Bills</td>\n",
       "      <td>buf</td>\n",
       "      <td>Tampa Bay Buccaneers</td>\n",
       "      <td>tam</td>\n",
       "      <td>14</td>\n",
       "      <td>-0.166667</td>\n",
       "      <td>-2.000000</td>\n",
       "      <td>0.750000</td>\n",
       "      <td>0.083333</td>\n",
       "      <td>-51.750000</td>\n",
       "      <td>-5.750000</td>\n",
       "      <td>-5.000000</td>\n",
       "      <td>-0.666667</td>\n",
       "      <td>-49.500000</td>\n",
       "      <td>0.333333</td>\n",
       "      <td>-3.416667</td>\n",
       "      <td>3.916667</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>24.083333</td>\n",
       "      <td>26.583333</td>\n",
       "      <td>0.333333</td>\n",
       "      <td>-27.666667</td>\n",
       "      <td>0.083333</td>\n",
       "      <td>-0.416667</td>\n",
       "      <td>2.250000</td>\n",
       "      <td>-0.250000</td>\n",
       "      <td>0.003930</td>\n",
       "      <td>0.0</td>\n",
       "      <td>-44.281063</td>\n",
       "      <td>-16.339024</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>189</th>\n",
       "      <td>Chicago Bears</td>\n",
       "      <td>chi</td>\n",
       "      <td>Green Bay Packers</td>\n",
       "      <td>gnb</td>\n",
       "      <td>14</td>\n",
       "      <td>-0.416667</td>\n",
       "      <td>-2.166667</td>\n",
       "      <td>0.166667</td>\n",
       "      <td>0.750000</td>\n",
       "      <td>-74.583333</td>\n",
       "      <td>-5.250000</td>\n",
       "      <td>-4.833333</td>\n",
       "      <td>-1.166667</td>\n",
       "      <td>-63.166667</td>\n",
       "      <td>1.750000</td>\n",
       "      <td>-6.833333</td>\n",
       "      <td>2.333333</td>\n",
       "      <td>0.166667</td>\n",
       "      <td>18.416667</td>\n",
       "      <td>-189.166667</td>\n",
       "      <td>1.416667</td>\n",
       "      <td>-56.166667</td>\n",
       "      <td>0.750000</td>\n",
       "      <td>10.250000</td>\n",
       "      <td>11.416667</td>\n",
       "      <td>-0.088235</td>\n",
       "      <td>-0.075342</td>\n",
       "      <td>0.0</td>\n",
       "      <td>-239.644166</td>\n",
       "      <td>-177.084461</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>190</th>\n",
       "      <td>Los Angeles Rams</td>\n",
       "      <td>ram</td>\n",
       "      <td>Arizona Cardinals</td>\n",
       "      <td>crd</td>\n",
       "      <td>14</td>\n",
       "      <td>-0.166667</td>\n",
       "      <td>-0.250000</td>\n",
       "      <td>-1.250000</td>\n",
       "      <td>0.166667</td>\n",
       "      <td>44.416667</td>\n",
       "      <td>6.083333</td>\n",
       "      <td>1.833333</td>\n",
       "      <td>0.666667</td>\n",
       "      <td>38.833333</td>\n",
       "      <td>-1.416667</td>\n",
       "      <td>-0.583333</td>\n",
       "      <td>-6.833333</td>\n",
       "      <td>-0.916667</td>\n",
       "      <td>-26.250000</td>\n",
       "      <td>-176.250000</td>\n",
       "      <td>-0.750000</td>\n",
       "      <td>18.166667</td>\n",
       "      <td>0.250000</td>\n",
       "      <td>-14.083333</td>\n",
       "      <td>-5.583333</td>\n",
       "      <td>-0.200000</td>\n",
       "      <td>-0.026152</td>\n",
       "      <td>0.0</td>\n",
       "      <td>-61.165557</td>\n",
       "      <td>-20.046215</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "            away_name away_abbr             home_name home_abbr  week  \\\n",
       "186   New York Giants       nyg  Los Angeles Chargers       sdg    14   \n",
       "187     Detroit Lions       det        Denver Broncos       den    14   \n",
       "188     Buffalo Bills       buf  Tampa Bay Buccaneers       tam    14   \n",
       "189     Chicago Bears       chi     Green Bay Packers       gnb    14   \n",
       "190  Los Angeles Rams       ram     Arizona Cardinals       crd    14   \n",
       "\n",
       "     win_perc_dif  first_downs_dif  fumbles_dif  interceptions_dif  \\\n",
       "186     -0.250000        -4.000000     0.666667          -0.083333   \n",
       "187     -0.409091        -0.916667     0.416667           0.000000   \n",
       "188     -0.166667        -2.000000     0.750000           0.083333   \n",
       "189     -0.416667        -2.166667     0.166667           0.750000   \n",
       "190     -0.166667        -0.250000    -1.250000           0.166667   \n",
       "\n",
       "     net_pass_yards_dif  pass_attempts_dif  pass_completions_dif  \\\n",
       "186          -60.083333          -3.333333             -3.500000   \n",
       "187          -24.833333           1.416667              0.916667   \n",
       "188          -51.750000          -5.750000             -5.000000   \n",
       "189          -74.583333          -5.250000             -4.833333   \n",
       "190           44.416667           6.083333              1.833333   \n",
       "\n",
       "     pass_touchdowns_dif  pass_yards_dif  penalties_dif  points_dif  \\\n",
       "186            -1.333333      -58.416667      -1.500000   -8.583333   \n",
       "187            -0.250000      -20.333333       1.500000   -2.833333   \n",
       "188            -0.666667      -49.500000       0.333333   -3.416667   \n",
       "189            -1.166667      -63.166667       1.750000   -6.833333   \n",
       "190             0.666667       38.833333      -1.416667   -0.583333   \n",
       "\n",
       "     rush_attempts_dif  rush_touchdowns_dif  rush_yards_dif  \\\n",
       "186           0.583333            -0.333333      -10.166667   \n",
       "187          -1.666667             0.000000       -8.166667   \n",
       "188           3.916667             0.000000       24.083333   \n",
       "189           2.333333             0.166667       18.416667   \n",
       "190          -6.833333            -0.916667      -26.250000   \n",
       "\n",
       "     time_of_possession_dif  times_sacked_dif  total_yards_dif  turnovers_dif  \\\n",
       "186               -1.250000          0.083333       -70.250000       0.000000   \n",
       "187             -165.000000         -0.083333       -33.000000       0.083333   \n",
       "188               26.583333          0.333333       -27.666667       0.083333   \n",
       "189             -189.166667          1.416667       -56.166667       0.750000   \n",
       "190             -176.250000         -0.750000        18.166667       0.250000   \n",
       "\n",
       "     yards_from_penalties_dif  yards_lost_from_sacks_dif  \\\n",
       "186                -16.500000                   1.666667   \n",
       "187                  9.333333                   4.500000   \n",
       "188                 -0.416667                   2.250000   \n",
       "189                 10.250000                  11.416667   \n",
       "190                -14.083333                  -5.583333   \n",
       "\n",
       "     fourth_down_perc_dif  third_down_perc_dif  result     elo_dif      qb_dif  \n",
       "186             -0.119048            -0.080808     0.0 -110.229362 -126.445654  \n",
       "187             -0.195971            -0.052985     0.0 -173.770079   -0.964572  \n",
       "188             -0.250000             0.003930     0.0  -44.281063  -16.339024  \n",
       "189             -0.088235            -0.075342     0.0 -239.644166 -177.084461  \n",
       "190             -0.200000            -0.026152     0.0  -61.165557  -20.046215  "
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df = pd.read_csv('2021_week_2_through_14.csv')\n",
    "\n",
    "# Preview dataset\n",
    "df.tail()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Logistic Regression"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Logistic Regression Predictions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import Logistic Regression & Sklearn modules\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.metrics import accuracy_score\n",
    "from sklearn.preprocessing import StandardScaler"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 90,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Set prediction week and split dataset workbook between prediction games and completed games.\n",
    "pred_week = 14\n",
    "comp_games_df = df[df['week'] < pred_week]\n",
    "pred_games_df = df[df['week'] == pred_week]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 91,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Rename train & test dataframes. Split features and results.\n",
    "train_df = comp_games_df\n",
    "test_df = pred_games_df\n",
    "\n",
    "X_train = train_df.drop(columns = ['away_name', 'away_abbr', 'home_name', 'home_abbr', 'week','result'])\n",
    "y_train = train_df[['result']] \n",
    "X_test = test_df.drop(columns = ['away_name', 'away_abbr', 'home_name', 'home_abbr', 'week','result'])\n",
    "y_test = test_df[['result']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create a StandardScaler instance\n",
    "scaler = StandardScaler()\n",
    "\n",
    "# Fit the scaler to the features training dataset\n",
    "X_scaler = scaler.fit(X_train)\n",
    "\n",
    "# Fit the scaler to the features training dataset\n",
    "X_train_scaled = X_scaler.transform(X_train)\n",
    "X_test_scaled = X_scaler.transform(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Logistic Regression - Unscaled\n",
      "\n",
      "The Pittsburgh Steelers have a probability of 53% of beating the Minnesota Vikings.\n",
      "The San Francisco 49ers have a probability of 28% of beating the Cincinnati Bengals.\n",
      "The Atlanta Falcons have a probability of 56% of beating the Carolina Panthers.\n",
      "The Dallas Cowboys have a probability of 66% of beating the Washington Football Team.\n",
      "The Jacksonville Jaguars have a probability of 17% of beating the Tennessee Titans.\n",
      "The New Orleans Saints have a probability of 42% of beating the New York Jets.\n",
      "The Las Vegas Raiders have a probability of 14% of beating the Kansas City Chiefs.\n",
      "The Seattle Seahawks have a probability of 71% of beating the Houston Texans.\n",
      "The Baltimore Ravens have a probability of 69% of beating the Cleveland Browns.\n",
      "The New York Giants have a probability of 30% of beating the Los Angeles Chargers.\n",
      "The Detroit Lions have a probability of 22% of beating the Denver Broncos.\n",
      "The Buffalo Bills have a probability of 40% of beating the Tampa Bay Buccaneers.\n",
      "The Chicago Bears have a probability of 19% of beating the Green Bay Packers.\n",
      "The Los Angeles Rams have a probability of 53% of beating the Arizona Cardinals.\n",
      "\n",
      "Logistic Regression - Scaled\n",
      "\n",
      "The Pittsburgh Steelers have a probability of 52% of beating the Minnesota Vikings.\n",
      "The San Francisco 49ers have a probability of 37% of beating the Cincinnati Bengals.\n",
      "The Atlanta Falcons have a probability of 53% of beating the Carolina Panthers.\n",
      "The Dallas Cowboys have a probability of 59% of beating the Washington Football Team.\n",
      "The Jacksonville Jaguars have a probability of 22% of beating the Tennessee Titans.\n",
      "The New Orleans Saints have a probability of 48% of beating the New York Jets.\n",
      "The Las Vegas Raiders have a probability of 11% of beating the Kansas City Chiefs.\n",
      "The Seattle Seahawks have a probability of 68% of beating the Houston Texans.\n",
      "The Baltimore Ravens have a probability of 71% of beating the Cleveland Browns.\n",
      "The New York Giants have a probability of 31% of beating the Los Angeles Chargers.\n",
      "The Detroit Lions have a probability of 24% of beating the Denver Broncos.\n",
      "The Buffalo Bills have a probability of 42% of beating the Tampa Bay Buccaneers.\n",
      "The Chicago Bears have a probability of 23% of beating the Green Bay Packers.\n",
      "The Los Angeles Rams have a probability of 51% of beating the Arizona Cardinals.\n"
     ]
    }
   ],
   "source": [
    "# Logistic Model\n",
    "clf_unscaled = LogisticRegression(penalty='l1', dual=False, tol=0.001, C=1.0, fit_intercept=True, \n",
    "                   intercept_scaling=1, class_weight='balanced', random_state=None, \n",
    "                   solver='liblinear', max_iter=1000, multi_class='ovr', verbose=0)\n",
    "\n",
    "clf_scaled = LogisticRegression(penalty='l1', dual=False, tol=0.001, C=1.0, fit_intercept=True, \n",
    "                   intercept_scaling=1, class_weight='balanced', random_state=None, \n",
    "                   solver='liblinear', max_iter=1000, multi_class='ovr', verbose=0)\n",
    "\n",
    "clf_unscaled.fit(X_train, np.ravel(y_train.values))\n",
    "clf_scaled.fit(X_train_scaled, np.ravel(y_train.values))\n",
    "\n",
    "y_pred_unscaled = clf_unscaled.predict_proba(X_test)\n",
    "y_pred_scaled = clf_scaled.predict_proba(X_test_scaled)\n",
    "\n",
    "y_pred_unscaled = y_pred_unscaled[:,1]\n",
    "y_pred_scaled = y_pred_scaled[:,1]\n",
    "\n",
    "print(\"Logistic Regression - Unscaled\\n\")\n",
    "display(y_pred_unscaled,test_df)\n",
    "\n",
    "print(\"\\nLogistic Regression - Scaled\\n\")\n",
    "display(y_pred_scaled,test_df)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Get Logistic Regression Accuracy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# make a for loop to the get accuracy for each week\n",
    "def accuracy_score_log_reg(df):\n",
    "    \n",
    "    accuracy = pd.DataFrame(\n",
    "        columns=[\n",
    "            'week', \n",
    "            'Logistic Regression Accuracy - Unscaled', \n",
    "            'Logistic Regeression Accuracy - Scaled',\n",
    "            'Log Reg - Unscaled - drop 40% to 60%',\n",
    "            'Log Reg - Scaled - drop 40% to 60%'\n",
    "        ])\n",
    "    \n",
    "    for w in df['week'].unique()[1:-1]:\n",
    "        train_df = df[df['week'] < w]\n",
    "        test_df = df[df['week'] == w]\n",
    "        \n",
    "        X_train = train_df.drop(columns = ['away_name', 'away_abbr', 'home_name', 'home_abbr', 'week','result'])\n",
    "        y_train = train_df[['result']] \n",
    "        X_test = test_df.drop(columns = ['away_name', 'away_abbr', 'home_name', 'home_abbr', 'week','result'])\n",
    "        y_test = test_df[['result']]\n",
    "        \n",
    "        # Create a StandardScaler instance\n",
    "        scaler = StandardScaler()\n",
    "\n",
    "        # Fit the scaler to the features training dataset\n",
    "        X_scaler = scaler.fit(X_train)\n",
    "\n",
    "        # Fit the scaler to the features training dataset\n",
    "        X_train_scaled = X_scaler.transform(X_train)\n",
    "        X_test_scaled = X_scaler.transform(X_test)\n",
    "        \n",
    "        clf_unscaled = LogisticRegression(penalty='l1', dual=False, tol=0.001, C=1.0, fit_intercept=True, \n",
    "                           intercept_scaling=1, class_weight='balanced', random_state=None, \n",
    "                           solver='liblinear', max_iter=1000, multi_class='ovr', verbose=0)\n",
    "\n",
    "        clf_scaled = LogisticRegression(penalty='l1', dual=False, tol=0.001, C=1.0, fit_intercept=True, \n",
    "                           intercept_scaling=1, class_weight='balanced', random_state=None, \n",
    "                           solver='liblinear', max_iter=1000, multi_class='ovr', verbose=0)\n",
    "\n",
    "        clf_unscaled.fit(X_train, np.ravel(y_train.values))\n",
    "        clf_scaled.fit(X_train_scaled, np.ravel(y_train.values))\n",
    "        \n",
    "        y_pred_unscaled = clf_unscaled.predict_proba(X_test)\n",
    "        y_pred_scaled = clf_scaled.predict_proba(X_test_scaled)\n",
    "        \n",
    "        y_pred_unscaled = y_pred_unscaled[:,1]\n",
    "        y_pred_scaled = y_pred_scaled[:,1]\n",
    "        \n",
    "        accuracy_score_unscaled = accuracy_score(y_test, np.round(y_pred_unscaled))\n",
    "        accuracy_score_scaled = accuracy_score(y_test, np.round(y_pred_scaled))\n",
    "        accuracy_score_unscaled_drop_40_60 = accuracy_score(y_test[(y_pred_unscaled < .4) | (y_pred_unscaled > .6)], np.round(y_pred_unscaled[(y_pred_unscaled < .4) | (y_pred_unscaled > .6)]))\n",
    "        accuracy_score_scaled_drop_40_60 = accuracy_score(y_test[(y_pred_scaled < .4) | (y_pred_scaled > .6)],np.round(y_pred_scaled[(y_pred_scaled < .4) | (y_pred_scaled > .6)]))\n",
    "        \n",
    "        accuracy.loc[w,:] = [w, accuracy_score_unscaled, accuracy_score_scaled, accuracy_score_unscaled_drop_40_60, accuracy_score_scaled_drop_40_60]\n",
    "        \n",
    "    return(accuracy)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>week</th>\n",
       "      <th>Logistic Regression Accuracy - Unscaled</th>\n",
       "      <th>Logistic Regeression Accuracy - Scaled</th>\n",
       "      <th>Log Reg - Unscaled - drop 40% to 60%</th>\n",
       "      <th>Log Reg - Scaled - drop 40% to 60%</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>3</td>\n",
       "      <td>0.6</td>\n",
       "      <td>0.533333</td>\n",
       "      <td>0.571429</td>\n",
       "      <td>0.625</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>4</td>\n",
       "      <td>0.625</td>\n",
       "      <td>0.6875</td>\n",
       "      <td>0.666667</td>\n",
       "      <td>0.692308</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>5</td>\n",
       "      <td>0.5</td>\n",
       "      <td>0.625</td>\n",
       "      <td>0.466667</td>\n",
       "      <td>0.666667</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>6</td>\n",
       "      <td>0.857143</td>\n",
       "      <td>0.857143</td>\n",
       "      <td>0.846154</td>\n",
       "      <td>0.909091</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>7</td>\n",
       "      <td>0.769231</td>\n",
       "      <td>0.769231</td>\n",
       "      <td>0.75</td>\n",
       "      <td>0.8</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>8</td>\n",
       "      <td>0.466667</td>\n",
       "      <td>0.466667</td>\n",
       "      <td>0.5</td>\n",
       "      <td>0.466667</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>9</td>\n",
       "      <td>0.642857</td>\n",
       "      <td>0.714286</td>\n",
       "      <td>0.6</td>\n",
       "      <td>0.636364</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>10</td>\n",
       "      <td>0.5</td>\n",
       "      <td>0.5</td>\n",
       "      <td>0.5</td>\n",
       "      <td>0.538462</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>11</td>\n",
       "      <td>0.666667</td>\n",
       "      <td>0.6</td>\n",
       "      <td>0.777778</td>\n",
       "      <td>0.777778</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>12</td>\n",
       "      <td>0.733333</td>\n",
       "      <td>0.6</td>\n",
       "      <td>0.8</td>\n",
       "      <td>0.714286</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>13</td>\n",
       "      <td>0.571429</td>\n",
       "      <td>0.571429</td>\n",
       "      <td>0.6</td>\n",
       "      <td>0.6</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   week Logistic Regression Accuracy - Unscaled  \\\n",
       "3     3                                     0.6   \n",
       "4     4                                   0.625   \n",
       "5     5                                     0.5   \n",
       "6     6                                0.857143   \n",
       "7     7                                0.769231   \n",
       "8     8                                0.466667   \n",
       "9     9                                0.642857   \n",
       "10   10                                     0.5   \n",
       "11   11                                0.666667   \n",
       "12   12                                0.733333   \n",
       "13   13                                0.571429   \n",
       "\n",
       "   Logistic Regeression Accuracy - Scaled  \\\n",
       "3                                0.533333   \n",
       "4                                  0.6875   \n",
       "5                                   0.625   \n",
       "6                                0.857143   \n",
       "7                                0.769231   \n",
       "8                                0.466667   \n",
       "9                                0.714286   \n",
       "10                                    0.5   \n",
       "11                                    0.6   \n",
       "12                                    0.6   \n",
       "13                               0.571429   \n",
       "\n",
       "   Log Reg - Unscaled - drop 40% to 60% Log Reg - Scaled - drop 40% to 60%  \n",
       "3                              0.571429                              0.625  \n",
       "4                              0.666667                           0.692308  \n",
       "5                              0.466667                           0.666667  \n",
       "6                              0.846154                           0.909091  \n",
       "7                                  0.75                                0.8  \n",
       "8                                   0.5                           0.466667  \n",
       "9                                   0.6                           0.636364  \n",
       "10                                  0.5                           0.538462  \n",
       "11                             0.777778                           0.777778  \n",
       "12                                  0.8                           0.714286  \n",
       "13                                  0.6                                0.6  "
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Call the accuracy function and output the df.\n",
    "logistic_regression_accuracy = accuracy_score_log_reg(df)\n",
    "logistic_regression_accuracy"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "tags": []
   },
   "source": [
    "# Tensorflow "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Tensorflow Predictions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "# import tensorflow libraries\n",
    "import tensorflow as tf\n",
    "from tensorflow.keras.layers import Dense\n",
    "from tensorflow.keras.models import Sequential\n",
    "from sklearn.model_selection import train_test_split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Set prediction week and split dataset workbook between prediction games and completed games.\n",
    "\n",
    "pred_week = 14\n",
    "comp_games_df = df[df['week'] < pred_week]\n",
    "pred_games_df = df[df['week'] == pred_week]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Rename train & test dataframes. Split features and results.\n",
    "train_df = comp_games_df\n",
    "test_df = pred_games_df\n",
    "\n",
    "X_train = train_df.drop(columns = ['away_name', 'away_abbr', 'home_name', 'home_abbr', 'week','result'])\n",
    "y_train = train_df[['result']] \n",
    "X_test = test_df.drop(columns = ['away_name', 'away_abbr', 'home_name', 'home_abbr', 'week','result'])\n",
    "y_test = test_df[['result']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>win_perc_dif</th>\n",
       "      <th>first_downs_dif</th>\n",
       "      <th>fumbles_dif</th>\n",
       "      <th>interceptions_dif</th>\n",
       "      <th>net_pass_yards_dif</th>\n",
       "      <th>pass_attempts_dif</th>\n",
       "      <th>pass_completions_dif</th>\n",
       "      <th>pass_touchdowns_dif</th>\n",
       "      <th>pass_yards_dif</th>\n",
       "      <th>penalties_dif</th>\n",
       "      <th>points_dif</th>\n",
       "      <th>rush_attempts_dif</th>\n",
       "      <th>rush_touchdowns_dif</th>\n",
       "      <th>rush_yards_dif</th>\n",
       "      <th>time_of_possession_dif</th>\n",
       "      <th>times_sacked_dif</th>\n",
       "      <th>total_yards_dif</th>\n",
       "      <th>turnovers_dif</th>\n",
       "      <th>yards_from_penalties_dif</th>\n",
       "      <th>yards_lost_from_sacks_dif</th>\n",
       "      <th>fourth_down_perc_dif</th>\n",
       "      <th>third_down_perc_dif</th>\n",
       "      <th>elo_dif</th>\n",
       "      <th>qb_dif</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.000000</td>\n",
       "      <td>4.000000</td>\n",
       "      <td>-2.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>121.000000</td>\n",
       "      <td>16.000000</td>\n",
       "      <td>8.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>132.000000</td>\n",
       "      <td>-5.000000</td>\n",
       "      <td>-3.000000</td>\n",
       "      <td>-7.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>-66.000000</td>\n",
       "      <td>55.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>55.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>-18.000000</td>\n",
       "      <td>11.000000</td>\n",
       "      <td>-0.666667</td>\n",
       "      <td>0.200000</td>\n",
       "      <td>-50.848658</td>\n",
       "      <td>100.316973</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1.000000</td>\n",
       "      <td>-4.000000</td>\n",
       "      <td>-1.000000</td>\n",
       "      <td>-1.000000</td>\n",
       "      <td>29.000000</td>\n",
       "      <td>-13.000000</td>\n",
       "      <td>-9.000000</td>\n",
       "      <td>2.000000</td>\n",
       "      <td>45.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>13.000000</td>\n",
       "      <td>10.000000</td>\n",
       "      <td>-1.000000</td>\n",
       "      <td>15.000000</td>\n",
       "      <td>-23.000000</td>\n",
       "      <td>2.000000</td>\n",
       "      <td>44.000000</td>\n",
       "      <td>-2.000000</td>\n",
       "      <td>-20.000000</td>\n",
       "      <td>16.000000</td>\n",
       "      <td>0.666667</td>\n",
       "      <td>-0.240260</td>\n",
       "      <td>-51.742731</td>\n",
       "      <td>34.616025</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.000000</td>\n",
       "      <td>4.000000</td>\n",
       "      <td>-1.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>-119.000000</td>\n",
       "      <td>-14.000000</td>\n",
       "      <td>-9.000000</td>\n",
       "      <td>4.000000</td>\n",
       "      <td>-128.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>19.000000</td>\n",
       "      <td>12.000000</td>\n",
       "      <td>-1.000000</td>\n",
       "      <td>60.000000</td>\n",
       "      <td>196.000000</td>\n",
       "      <td>-1.000000</td>\n",
       "      <td>-59.000000</td>\n",
       "      <td>-1.000000</td>\n",
       "      <td>-2.000000</td>\n",
       "      <td>-9.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.214286</td>\n",
       "      <td>204.627654</td>\n",
       "      <td>54.983874</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0.000000</td>\n",
       "      <td>10.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>232.000000</td>\n",
       "      <td>24.000000</td>\n",
       "      <td>16.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>247.000000</td>\n",
       "      <td>5.000000</td>\n",
       "      <td>10.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>2.000000</td>\n",
       "      <td>7.000000</td>\n",
       "      <td>445.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>239.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>30.000000</td>\n",
       "      <td>15.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.133333</td>\n",
       "      <td>-62.282436</td>\n",
       "      <td>-14.386838</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0.000000</td>\n",
       "      <td>-3.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>50.000000</td>\n",
       "      <td>-9.000000</td>\n",
       "      <td>-9.000000</td>\n",
       "      <td>-1.000000</td>\n",
       "      <td>55.000000</td>\n",
       "      <td>-7.000000</td>\n",
       "      <td>9.000000</td>\n",
       "      <td>-3.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>-42.000000</td>\n",
       "      <td>-270.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>8.000000</td>\n",
       "      <td>2.000000</td>\n",
       "      <td>-10.000000</td>\n",
       "      <td>5.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>-0.128205</td>\n",
       "      <td>36.874709</td>\n",
       "      <td>-13.318243</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>172</th>\n",
       "      <td>-0.090909</td>\n",
       "      <td>1.454545</td>\n",
       "      <td>0.272727</td>\n",
       "      <td>0.090909</td>\n",
       "      <td>-72.181818</td>\n",
       "      <td>-4.000000</td>\n",
       "      <td>-2.818182</td>\n",
       "      <td>-0.090909</td>\n",
       "      <td>-71.636364</td>\n",
       "      <td>-2.454545</td>\n",
       "      <td>-2.727273</td>\n",
       "      <td>5.818182</td>\n",
       "      <td>-0.181818</td>\n",
       "      <td>36.454545</td>\n",
       "      <td>81.818182</td>\n",
       "      <td>-0.090909</td>\n",
       "      <td>-35.727273</td>\n",
       "      <td>0.363636</td>\n",
       "      <td>-21.000000</td>\n",
       "      <td>0.545455</td>\n",
       "      <td>0.058462</td>\n",
       "      <td>0.048097</td>\n",
       "      <td>15.185078</td>\n",
       "      <td>-68.820114</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>173</th>\n",
       "      <td>-0.454545</td>\n",
       "      <td>-2.636364</td>\n",
       "      <td>0.727273</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>-81.181818</td>\n",
       "      <td>-0.545455</td>\n",
       "      <td>-3.181818</td>\n",
       "      <td>-1.636364</td>\n",
       "      <td>-83.727273</td>\n",
       "      <td>2.272727</td>\n",
       "      <td>-11.454545</td>\n",
       "      <td>-0.727273</td>\n",
       "      <td>0.272727</td>\n",
       "      <td>19.909091</td>\n",
       "      <td>-60.545455</td>\n",
       "      <td>0.272727</td>\n",
       "      <td>-61.272727</td>\n",
       "      <td>0.454545</td>\n",
       "      <td>13.909091</td>\n",
       "      <td>-2.545455</td>\n",
       "      <td>0.121429</td>\n",
       "      <td>-0.065264</td>\n",
       "      <td>-285.686464</td>\n",
       "      <td>-102.890676</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>174</th>\n",
       "      <td>0.227273</td>\n",
       "      <td>4.909091</td>\n",
       "      <td>-0.090909</td>\n",
       "      <td>0.545455</td>\n",
       "      <td>4.363636</td>\n",
       "      <td>-4.272727</td>\n",
       "      <td>-2.545455</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>9.636364</td>\n",
       "      <td>-0.636364</td>\n",
       "      <td>3.545455</td>\n",
       "      <td>9.090909</td>\n",
       "      <td>0.454545</td>\n",
       "      <td>63.636364</td>\n",
       "      <td>258.090909</td>\n",
       "      <td>1.090909</td>\n",
       "      <td>68.000000</td>\n",
       "      <td>0.272727</td>\n",
       "      <td>5.000000</td>\n",
       "      <td>5.272727</td>\n",
       "      <td>0.384615</td>\n",
       "      <td>-0.060289</td>\n",
       "      <td>107.685364</td>\n",
       "      <td>27.419825</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>175</th>\n",
       "      <td>-0.090909</td>\n",
       "      <td>-5.454545</td>\n",
       "      <td>-1.000000</td>\n",
       "      <td>-0.363636</td>\n",
       "      <td>-66.727273</td>\n",
       "      <td>-9.000000</td>\n",
       "      <td>-5.181818</td>\n",
       "      <td>-0.909091</td>\n",
       "      <td>-58.272727</td>\n",
       "      <td>-1.272727</td>\n",
       "      <td>-4.818182</td>\n",
       "      <td>0.909091</td>\n",
       "      <td>0.090909</td>\n",
       "      <td>2.818182</td>\n",
       "      <td>32.272727</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>-63.909091</td>\n",
       "      <td>-0.909091</td>\n",
       "      <td>-9.000000</td>\n",
       "      <td>8.454545</td>\n",
       "      <td>0.030303</td>\n",
       "      <td>-0.138340</td>\n",
       "      <td>-173.767258</td>\n",
       "      <td>-78.641705</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>176</th>\n",
       "      <td>0.030303</td>\n",
       "      <td>-1.500000</td>\n",
       "      <td>-0.636364</td>\n",
       "      <td>-0.333333</td>\n",
       "      <td>-31.000000</td>\n",
       "      <td>-5.416667</td>\n",
       "      <td>-2.280303</td>\n",
       "      <td>-0.772727</td>\n",
       "      <td>-24.727273</td>\n",
       "      <td>-1.598485</td>\n",
       "      <td>-1.636364</td>\n",
       "      <td>1.924242</td>\n",
       "      <td>0.075758</td>\n",
       "      <td>-2.772727</td>\n",
       "      <td>-7.659091</td>\n",
       "      <td>0.454545</td>\n",
       "      <td>-33.939394</td>\n",
       "      <td>-0.204545</td>\n",
       "      <td>-11.689394</td>\n",
       "      <td>6.272727</td>\n",
       "      <td>0.303030</td>\n",
       "      <td>-0.046053</td>\n",
       "      <td>-26.640118</td>\n",
       "      <td>-110.185754</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>177 rows Ã— 24 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "     win_perc_dif  first_downs_dif  fumbles_dif  interceptions_dif  \\\n",
       "0        0.000000         4.000000    -2.000000           0.000000   \n",
       "1        1.000000        -4.000000    -1.000000          -1.000000   \n",
       "2        0.000000         4.000000    -1.000000           0.000000   \n",
       "3        0.000000        10.000000     0.000000           1.000000   \n",
       "4        0.000000        -3.000000     0.000000           0.000000   \n",
       "..            ...              ...          ...                ...   \n",
       "172     -0.090909         1.454545     0.272727           0.090909   \n",
       "173     -0.454545        -2.636364     0.727273           0.000000   \n",
       "174      0.227273         4.909091    -0.090909           0.545455   \n",
       "175     -0.090909        -5.454545    -1.000000          -0.363636   \n",
       "176      0.030303        -1.500000    -0.636364          -0.333333   \n",
       "\n",
       "     net_pass_yards_dif  pass_attempts_dif  pass_completions_dif  \\\n",
       "0            121.000000          16.000000              8.000000   \n",
       "1             29.000000         -13.000000             -9.000000   \n",
       "2           -119.000000         -14.000000             -9.000000   \n",
       "3            232.000000          24.000000             16.000000   \n",
       "4             50.000000          -9.000000             -9.000000   \n",
       "..                  ...                ...                   ...   \n",
       "172          -72.181818          -4.000000             -2.818182   \n",
       "173          -81.181818          -0.545455             -3.181818   \n",
       "174            4.363636          -4.272727             -2.545455   \n",
       "175          -66.727273          -9.000000             -5.181818   \n",
       "176          -31.000000          -5.416667             -2.280303   \n",
       "\n",
       "     pass_touchdowns_dif  pass_yards_dif  penalties_dif  points_dif  \\\n",
       "0               0.000000      132.000000      -5.000000   -3.000000   \n",
       "1               2.000000       45.000000       0.000000   13.000000   \n",
       "2               4.000000     -128.000000       0.000000   19.000000   \n",
       "3               1.000000      247.000000       5.000000   10.000000   \n",
       "4              -1.000000       55.000000      -7.000000    9.000000   \n",
       "..                   ...             ...            ...         ...   \n",
       "172            -0.090909      -71.636364      -2.454545   -2.727273   \n",
       "173            -1.636364      -83.727273       2.272727  -11.454545   \n",
       "174             0.000000        9.636364      -0.636364    3.545455   \n",
       "175            -0.909091      -58.272727      -1.272727   -4.818182   \n",
       "176            -0.772727      -24.727273      -1.598485   -1.636364   \n",
       "\n",
       "     rush_attempts_dif  rush_touchdowns_dif  rush_yards_dif  \\\n",
       "0            -7.000000             1.000000      -66.000000   \n",
       "1            10.000000            -1.000000       15.000000   \n",
       "2            12.000000            -1.000000       60.000000   \n",
       "3             0.000000             2.000000        7.000000   \n",
       "4            -3.000000             1.000000      -42.000000   \n",
       "..                 ...                  ...             ...   \n",
       "172           5.818182            -0.181818       36.454545   \n",
       "173          -0.727273             0.272727       19.909091   \n",
       "174           9.090909             0.454545       63.636364   \n",
       "175           0.909091             0.090909        2.818182   \n",
       "176           1.924242             0.075758       -2.772727   \n",
       "\n",
       "     time_of_possession_dif  times_sacked_dif  total_yards_dif  turnovers_dif  \\\n",
       "0                 55.000000          1.000000        55.000000       0.000000   \n",
       "1                -23.000000          2.000000        44.000000      -2.000000   \n",
       "2                196.000000         -1.000000       -59.000000      -1.000000   \n",
       "3                445.000000          1.000000       239.000000       1.000000   \n",
       "4               -270.000000          0.000000         8.000000       2.000000   \n",
       "..                      ...               ...              ...            ...   \n",
       "172               81.818182         -0.090909       -35.727273       0.363636   \n",
       "173              -60.545455          0.272727       -61.272727       0.454545   \n",
       "174              258.090909          1.090909        68.000000       0.272727   \n",
       "175               32.272727          1.000000       -63.909091      -0.909091   \n",
       "176               -7.659091          0.454545       -33.939394      -0.204545   \n",
       "\n",
       "     yards_from_penalties_dif  yards_lost_from_sacks_dif  \\\n",
       "0                  -18.000000                  11.000000   \n",
       "1                  -20.000000                  16.000000   \n",
       "2                   -2.000000                  -9.000000   \n",
       "3                   30.000000                  15.000000   \n",
       "4                  -10.000000                   5.000000   \n",
       "..                        ...                        ...   \n",
       "172                -21.000000                   0.545455   \n",
       "173                 13.909091                  -2.545455   \n",
       "174                  5.000000                   5.272727   \n",
       "175                 -9.000000                   8.454545   \n",
       "176                -11.689394                   6.272727   \n",
       "\n",
       "     fourth_down_perc_dif  third_down_perc_dif     elo_dif      qb_dif  \n",
       "0               -0.666667             0.200000  -50.848658  100.316973  \n",
       "1                0.666667            -0.240260  -51.742731   34.616025  \n",
       "2                1.000000             0.214286  204.627654   54.983874  \n",
       "3                0.000000             0.133333  -62.282436  -14.386838  \n",
       "4                0.000000            -0.128205   36.874709  -13.318243  \n",
       "..                    ...                  ...         ...         ...  \n",
       "172              0.058462             0.048097   15.185078  -68.820114  \n",
       "173              0.121429            -0.065264 -285.686464 -102.890676  \n",
       "174              0.384615            -0.060289  107.685364   27.419825  \n",
       "175              0.030303            -0.138340 -173.767258  -78.641705  \n",
       "176              0.303030            -0.046053  -26.640118 -110.185754  \n",
       "\n",
       "[177 rows x 24 columns]"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Preview train & test dataframes\n",
    "X_train"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Fit and build the tensorflow model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " dense (Dense)               (None, 12)                300       \n",
      "                                                                 \n",
      " dense_1 (Dense)             (None, 6)                 78        \n",
      "                                                                 \n",
      " dense_2 (Dense)             (None, 3)                 21        \n",
      "                                                                 \n",
      " dense_3 (Dense)             (None, 1)                 4         \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 403\n",
      "Trainable params: 403\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "# Define the the number of inputs (features) to the model\n",
    "number_input_features = X_train.shape[1]\n",
    "\n",
    "# Define the number of neurons in the output layer\n",
    "number_output_neurons = 1\n",
    "\n",
    "# Define the number of hidden nodes for three layer\n",
    "hidden_nodes_layer1 =  (number_input_features + 1) // 2\n",
    "hidden_nodes_layer2 = (hidden_nodes_layer1 + 1) // 2\n",
    "hidden_nodes_layer3 = (hidden_nodes_layer2 + 1) // 2\n",
    "\n",
    "# Create the Sequential model instance\n",
    "nn = Sequential()\n",
    "\n",
    "# Add the hidden layers\n",
    "nn.add(Dense(units=hidden_nodes_layer1, activation='relu', input_dim=number_input_features))\n",
    "nn.add(Dense(units=hidden_nodes_layer2, activation='relu'))\n",
    "nn.add(Dense(units=hidden_nodes_layer3, activation='relu'))\n",
    "\n",
    "# Add the output layer to the model specifying the number of output neurons and activation function\n",
    "nn.add(Dense(units=number_output_neurons, activation='sigmoid'))\n",
    "\n",
    "# Display the Sequential model summary\n",
    "nn.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Compile the Sequential model\n",
    "nn.compile(loss='binary_crossentropy', optimizer='adam', metrics=['accuracy'])\n",
    "\n",
    "# Fit the model using 50 epochs and the training data\n",
    "fit_model = nn.fit(X_train, y_train, epochs=500, verbose=0)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Export the tensorflow model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Set the model's file path\n",
    "#file_path = \"Resources/model_nn_2021_2_12_not_scaled_relu_relu_sigmoid_loss='binary_crossentropy', optimizer='adam', metrics=['accuracy']_1000 epochs.h5\"\n",
    "file_path = \"Resources/model_nn_2021_weeks_2_through_13.h5\"\n",
    "\n",
    "# Export your model to a HDF5 file\n",
    "nn.save(file_path)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Import the tensorflow model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "# load a previously built model.\n",
    "#file_path = \"Resources/model_nn_relu_relu_sigmoid_loss='binary_crossentropy', optimizer='adam', metrics=['accuracy']_200 epochs.h5\"\n",
    "#file_path = \"Resources/model_nn_relu_relu_sigmoid_loss='binary_crossentropy', optimizer='adam', metrics=['accuracy']_200 epochs.h5\"\n",
    "\n",
    "nn = tf.keras.models.load_model(file_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Tensorflow - Unscaled \n",
      "\n",
      "The Pittsburgh Steelers have a probability of 97% of beating the Minnesota Vikings.\n",
      "The San Francisco 49ers have a probability of 99% of beating the Cincinnati Bengals.\n",
      "The Atlanta Falcons have a probability of 83% of beating the Carolina Panthers.\n",
      "The Dallas Cowboys have a probability of 70% of beating the Washington Football Team.\n",
      "The Jacksonville Jaguars have a probability of 4% of beating the Tennessee Titans.\n",
      "The New Orleans Saints have a probability of 21% of beating the New York Jets.\n",
      "The Las Vegas Raiders have a probability of 4% of beating the Kansas City Chiefs.\n",
      "The Seattle Seahawks have a probability of 63% of beating the Houston Texans.\n",
      "The Baltimore Ravens have a probability of 63% of beating the Cleveland Browns.\n",
      "The New York Giants have a probability of 92% of beating the Los Angeles Chargers.\n",
      "The Detroit Lions have a probability of 9% of beating the Denver Broncos.\n",
      "The Buffalo Bills have a probability of 24% of beating the Tampa Bay Buccaneers.\n",
      "The Chicago Bears have a probability of 0% of beating the Green Bay Packers.\n",
      "The Los Angeles Rams have a probability of 89% of beating the Arizona Cardinals.\n"
     ]
    }
   ],
   "source": [
    "# Evaluate the model loss and accuracy metrics using the evaluate method and the test data        \n",
    "nn_predictions_unscaled = nn.predict(X_test)       \n",
    "\n",
    "print(\"Tensorflow - Unscaled \\n\")\n",
    "display(nn_predictions_unscaled.squeeze(),test_df)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Tensorflow Accuracy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Make a for loop to the get accuracy for each week of the NN Model.\n",
    "def accuracy_score_tensorflow(df):\n",
    "    \n",
    "    accuracy = pd.DataFrame(columns=['week', 'Tensorflow Accuracy - Unscaled'])\n",
    "    \n",
    "    for w in df['week'].unique()[1:-1]:\n",
    "        train_df = df[df['week'] < w]\n",
    "        test_df = df[df['week'] == w]\n",
    "        \n",
    "        X_train = train_df.drop(columns = ['away_name', 'away_abbr', 'home_name', 'home_abbr', 'week','result'])\n",
    "        y_train = train_df[['result']] \n",
    "        X_test = test_df.drop(columns = ['away_name', 'away_abbr', 'home_name', 'home_abbr', 'week','result'])\n",
    "        y_test = test_df[['result']]\n",
    "        \n",
    "        # Build the model\n",
    "        # Define the the number of inputs (features) to the model\n",
    "        number_input_features = X_train.shape[1]\n",
    "\n",
    "        # Define the number of neurons in the output layer\n",
    "        number_output_neurons = 1\n",
    "\n",
    "        # Define the number of hidden nodes for three layer\n",
    "        hidden_nodes_layer1 =  (number_input_features + 1) // 2\n",
    "        hidden_nodes_layer2 = (hidden_nodes_layer1 + 1) // 2\n",
    "        hidden_nodes_layer3 = (hidden_nodes_layer2 + 1) // 2\n",
    "\n",
    "        # Create the Sequential model instance\n",
    "        nn = Sequential()\n",
    "\n",
    "        # Add the hidden layers\n",
    "        nn.add(Dense(units=hidden_nodes_layer1, activation='relu', input_dim=number_input_features))\n",
    "        nn.add(Dense(units=hidden_nodes_layer2, activation='relu'))\n",
    "        nn.add(Dense(units=hidden_nodes_layer3, activation='relu'))\n",
    "\n",
    "        # Add the output layer to the model specifying the number of output neurons and activation function\n",
    "        nn.add(Dense(units=number_output_neurons, activation='sigmoid'))\n",
    "        \n",
    "        # Fit the model\n",
    "        # Compile the Sequential model\n",
    "        nn.compile(loss='binary_crossentropy', optimizer='adam', metrics=['accuracy'])\n",
    "\n",
    "        # Fit the model using 500 epochs and the training data\n",
    "        nn.fit(X_train, y_train, epochs=500, verbose=0)\n",
    "        \n",
    "        # Evaluate the model loss and accuracy metrics using the evaluate method and the test data        \n",
    "        model_accuracy_unscaled = nn.evaluate(X_test, y_test, verbose=0)       \n",
    "    \n",
    "        # Assign the accuracy to \n",
    "        accuracy.loc[w,:] = [w, model_accuracy_unscaled[1]]\n",
    "        \n",
    "    return(accuracy)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:5 out of the last 5 calls to <function Model.make_test_function.<locals>.test_function at 0x7fdf3d09d5f0> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/guide/function#controlling_retracing and https://www.tensorflow.org/api_docs/python/tf/function for  more details.\n",
      "WARNING:tensorflow:6 out of the last 6 calls to <function Model.make_test_function.<locals>.test_function at 0x7fdf4a01d3b0> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/guide/function#controlling_retracing and https://www.tensorflow.org/api_docs/python/tf/function for  more details.\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>week</th>\n",
       "      <th>Tensorflow Accuracy - Unscaled</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>3</td>\n",
       "      <td>0.466667</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>4</td>\n",
       "      <td>0.5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>5</td>\n",
       "      <td>0.6875</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>6</td>\n",
       "      <td>0.785714</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>7</td>\n",
       "      <td>0.692308</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>8</td>\n",
       "      <td>0.666667</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>9</td>\n",
       "      <td>0.714286</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>10</td>\n",
       "      <td>0.714286</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>11</td>\n",
       "      <td>0.6</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>12</td>\n",
       "      <td>0.466667</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>13</td>\n",
       "      <td>0.571429</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   week Tensorflow Accuracy - Unscaled\n",
       "3     3                       0.466667\n",
       "4     4                            0.5\n",
       "5     5                         0.6875\n",
       "6     6                       0.785714\n",
       "7     7                       0.692308\n",
       "8     8                       0.666667\n",
       "9     9                       0.714286\n",
       "10   10                       0.714286\n",
       "11   11                            0.6\n",
       "12   12                       0.466667\n",
       "13   13                       0.571429"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Run the accuracy_score_Tensorflow function to get an array of accuracies\n",
    "tensorflow_accuracy = accuracy_score_tensorflow(df)\n",
    "tensorflow_accuracy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>week</th>\n",
       "      <th>Logistic Regression Accuracy - Unscaled</th>\n",
       "      <th>Logistic Regeression Accuracy - Scaled</th>\n",
       "      <th>Log Reg - Unscaled - drop 40% to 60%</th>\n",
       "      <th>Log Reg - Scaled - drop 40% to 60%</th>\n",
       "      <th>Tensorflow Accuracy - Unscaled</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>3</td>\n",
       "      <td>0.6</td>\n",
       "      <td>0.533333</td>\n",
       "      <td>0.571429</td>\n",
       "      <td>0.625</td>\n",
       "      <td>0.466667</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>4</td>\n",
       "      <td>0.625</td>\n",
       "      <td>0.6875</td>\n",
       "      <td>0.666667</td>\n",
       "      <td>0.692308</td>\n",
       "      <td>0.5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>5</td>\n",
       "      <td>0.5</td>\n",
       "      <td>0.625</td>\n",
       "      <td>0.466667</td>\n",
       "      <td>0.666667</td>\n",
       "      <td>0.6875</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>6</td>\n",
       "      <td>0.857143</td>\n",
       "      <td>0.857143</td>\n",
       "      <td>0.846154</td>\n",
       "      <td>0.909091</td>\n",
       "      <td>0.785714</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>7</td>\n",
       "      <td>0.769231</td>\n",
       "      <td>0.769231</td>\n",
       "      <td>0.75</td>\n",
       "      <td>0.8</td>\n",
       "      <td>0.692308</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>8</td>\n",
       "      <td>0.466667</td>\n",
       "      <td>0.466667</td>\n",
       "      <td>0.5</td>\n",
       "      <td>0.466667</td>\n",
       "      <td>0.666667</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>9</td>\n",
       "      <td>0.642857</td>\n",
       "      <td>0.714286</td>\n",
       "      <td>0.6</td>\n",
       "      <td>0.636364</td>\n",
       "      <td>0.714286</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>10</td>\n",
       "      <td>0.5</td>\n",
       "      <td>0.5</td>\n",
       "      <td>0.5</td>\n",
       "      <td>0.538462</td>\n",
       "      <td>0.714286</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>11</td>\n",
       "      <td>0.666667</td>\n",
       "      <td>0.6</td>\n",
       "      <td>0.777778</td>\n",
       "      <td>0.777778</td>\n",
       "      <td>0.6</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>12</td>\n",
       "      <td>0.733333</td>\n",
       "      <td>0.6</td>\n",
       "      <td>0.8</td>\n",
       "      <td>0.714286</td>\n",
       "      <td>0.466667</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>13</td>\n",
       "      <td>0.571429</td>\n",
       "      <td>0.571429</td>\n",
       "      <td>0.6</td>\n",
       "      <td>0.6</td>\n",
       "      <td>0.571429</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   week Logistic Regression Accuracy - Unscaled  \\\n",
       "3     3                                     0.6   \n",
       "4     4                                   0.625   \n",
       "5     5                                     0.5   \n",
       "6     6                                0.857143   \n",
       "7     7                                0.769231   \n",
       "8     8                                0.466667   \n",
       "9     9                                0.642857   \n",
       "10   10                                     0.5   \n",
       "11   11                                0.666667   \n",
       "12   12                                0.733333   \n",
       "13   13                                0.571429   \n",
       "\n",
       "   Logistic Regeression Accuracy - Scaled  \\\n",
       "3                                0.533333   \n",
       "4                                  0.6875   \n",
       "5                                   0.625   \n",
       "6                                0.857143   \n",
       "7                                0.769231   \n",
       "8                                0.466667   \n",
       "9                                0.714286   \n",
       "10                                    0.5   \n",
       "11                                    0.6   \n",
       "12                                    0.6   \n",
       "13                               0.571429   \n",
       "\n",
       "   Log Reg - Unscaled - drop 40% to 60% Log Reg - Scaled - drop 40% to 60%  \\\n",
       "3                              0.571429                              0.625   \n",
       "4                              0.666667                           0.692308   \n",
       "5                              0.466667                           0.666667   \n",
       "6                              0.846154                           0.909091   \n",
       "7                                  0.75                                0.8   \n",
       "8                                   0.5                           0.466667   \n",
       "9                                   0.6                           0.636364   \n",
       "10                                  0.5                           0.538462   \n",
       "11                             0.777778                           0.777778   \n",
       "12                                  0.8                           0.714286   \n",
       "13                                  0.6                                0.6   \n",
       "\n",
       "   Tensorflow Accuracy - Unscaled  \n",
       "3                        0.466667  \n",
       "4                             0.5  \n",
       "5                          0.6875  \n",
       "6                        0.785714  \n",
       "7                        0.692308  \n",
       "8                        0.666667  \n",
       "9                        0.714286  \n",
       "10                       0.714286  \n",
       "11                            0.6  \n",
       "12                       0.466667  \n",
       "13                       0.571429  "
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "accuracy_df = pd.concat(\n",
    "    [logistic_regression_accuracy, tensorflow_accuracy.drop(columns=['week'])], axis=1)\n",
    "accuracy_df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Random Forest Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Set prediction week and split dataframe into completed & prediction games.\n",
    "pred_week = 14\n",
    "comp_games_df = df[df['week'] < pred_week]\n",
    "pred_games_df = df[df['week'] == pred_week]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Label train & test dataframes. Split X & y (features & results).\n",
    "\n",
    "train_df = comp_games_df\n",
    "test_df = pred_games_df\n",
    "\n",
    "X_train = train_df.drop(columns = ['away_name', 'away_abbr', 'home_name', 'home_abbr', 'week','result'])\n",
    "y_train = train_df[['result']] \n",
    "X_test = test_df.drop(columns = ['away_name', 'away_abbr', 'home_name', 'home_abbr', 'week','result'])\n",
    "y_test = test_df[['result']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The Pittsburgh Steelers have a probability of 44% of beating the Minnesota Vikings.\n",
      "The San Francisco 49ers have a probability of 41% of beating the Cincinnati Bengals.\n",
      "The Atlanta Falcons have a probability of 77% of beating the Carolina Panthers.\n",
      "The Dallas Cowboys have a probability of 63% of beating the Washington Football Team.\n",
      "The Jacksonville Jaguars have a probability of 32% of beating the Tennessee Titans.\n",
      "The New Orleans Saints have a probability of 54% of beating the New York Jets.\n",
      "The Las Vegas Raiders have a probability of 22% of beating the Kansas City Chiefs.\n",
      "The Seattle Seahawks have a probability of 57% of beating the Houston Texans.\n",
      "The Baltimore Ravens have a probability of 85% of beating the Cleveland Browns.\n",
      "The New York Giants have a probability of 23% of beating the Los Angeles Chargers.\n",
      "The Detroit Lions have a probability of 21% of beating the Denver Broncos.\n",
      "The Buffalo Bills have a probability of 60% of beating the Tampa Bay Buccaneers.\n",
      "The Chicago Bears have a probability of 13% of beating the Green Bay Packers.\n",
      "The Los Angeles Rams have a probability of 56% of beating the Arizona Cardinals.\n"
     ]
    }
   ],
   "source": [
    "# Create a random forest classifier\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.metrics import classification_report\n",
    "\n",
    "rf_model = RandomForestClassifier(n_estimators=100, random_state=1)\n",
    "\n",
    "# Fitting the model\n",
    "rf_fitted = rf_model.fit(X_train, np.ravel(y_train.values))\n",
    "\n",
    "# Making predictions using the testing data\n",
    "y_pred = rf_fitted.predict_proba(X_test)\n",
    "y_pred = y_pred[:,1]\n",
    "y = rf_fitted.predict(X_test)\n",
    "\n",
    "# print(\"RandomForest - Unscaled \\n\")\n",
    "display(y_pred, test_df)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Random Forest Feature Importance"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<zip at 0x7fdf32a82050>"
      ]
     },
     "execution_count": 38,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Random Forests in sklearn will automatically calculate feature importance\n",
    "importances = rf_model.feature_importances_\n",
    "\n",
    "important_features = zip(X_test.columns,rf_model.feature_importances_)\n",
    "\n",
    "important_features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create a dataframe of the important features\n",
    "importances_df = pd.DataFrame(important_features)\n",
    "\n",
    "# Rename the columns\n",
    "importances_df = importances_df.rename(columns={0: 'Feature', 1: 'Importance'})\n",
    "\n",
    "# Set the index\n",
    "importances_df = importances_df.set_index('Feature')\n",
    "\n",
    "# Sort the dataframe by feature importance\n",
    "importances_df = importances_df.sort_values(by='Importance',ascending=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 1440x576 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Plot the top 10 most important features\n",
    "importances_df[0:10].sort_values('Importance', ascending=True).plot(\n",
    "    kind='barh', \n",
    "    color='blue', \n",
    "    title= 'Random Forest Feature Importance', \n",
    "    figsize=[20, 8],\n",
    "    legend=True)\n",
    "\n",
    "plt.savefig('Resources\\RF_Feature_Importance_Week_14.png')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Make a for loop to get the accuracy for each week of the random forest model.\n",
    "def accuracy_score_random_forest(df):\n",
    "    \n",
    "    accuracy = pd.DataFrame(columns=['week', 'Random Forest Accuracy', 'Random Forest - drop 40% - 60%'])\n",
    "    \n",
    "    for w in df['week'].unique()[1:-1]:\n",
    "        train_df = df[df['week'] < w]\n",
    "        test_df = df[df['week'] == w]\n",
    "        \n",
    "        X_train = train_df.drop(columns = ['away_name', 'away_abbr', 'home_name', 'home_abbr', 'week','result'])\n",
    "        y_train = train_df[['result']] \n",
    "        X_test = test_df.drop(columns = ['away_name', 'away_abbr', 'home_name', 'home_abbr', 'week','result'])\n",
    "        y_test = test_df[['result']]\n",
    "        \n",
    "        # Fitting the model\n",
    "        classifier = RandomForestClassifier(n_estimators=100, random_state=1)\n",
    "        classifier.fit(X_train, np.ravel(y_train.values))\n",
    "        y_pred = classifier.predict(X_test)\n",
    "        y_pred_percent =  classifier.predict_proba(X_test)[:,1]\n",
    "        \n",
    "        model_accuracy = accuracy_score(y_test, y_pred)\n",
    "        model_accuracy_drop_40_60 = accuracy_score(y_test[(y_pred_percent < .4) | (y_pred_percent > .6)], y_pred[(y_pred_percent < .4) | (y_pred_percent > .6)])\n",
    "\n",
    "        # Assign the accuracy to \n",
    "        accuracy.loc[w,:] = [w, model_accuracy, model_accuracy_drop_40_60]\n",
    "        \n",
    "    return(accuracy)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>week</th>\n",
       "      <th>Random Forest Accuracy</th>\n",
       "      <th>Random Forest - drop 40% - 60%</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>3</td>\n",
       "      <td>0.6</td>\n",
       "      <td>0.75</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>4</td>\n",
       "      <td>0.625</td>\n",
       "      <td>0.666667</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>5</td>\n",
       "      <td>0.625</td>\n",
       "      <td>0.8</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>6</td>\n",
       "      <td>0.785714</td>\n",
       "      <td>0.833333</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>7</td>\n",
       "      <td>0.846154</td>\n",
       "      <td>0.8</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>8</td>\n",
       "      <td>0.6</td>\n",
       "      <td>0.583333</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>9</td>\n",
       "      <td>0.642857</td>\n",
       "      <td>0.6</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>10</td>\n",
       "      <td>0.5</td>\n",
       "      <td>0.555556</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>11</td>\n",
       "      <td>0.8</td>\n",
       "      <td>0.7</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>12</td>\n",
       "      <td>0.466667</td>\n",
       "      <td>0.636364</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>13</td>\n",
       "      <td>0.714286</td>\n",
       "      <td>0.777778</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   week Random Forest Accuracy Random Forest - drop 40% - 60%\n",
       "3     3                    0.6                           0.75\n",
       "4     4                  0.625                       0.666667\n",
       "5     5                  0.625                            0.8\n",
       "6     6               0.785714                       0.833333\n",
       "7     7               0.846154                            0.8\n",
       "8     8                    0.6                       0.583333\n",
       "9     9               0.642857                            0.6\n",
       "10   10                    0.5                       0.555556\n",
       "11   11                    0.8                            0.7\n",
       "12   12               0.466667                       0.636364\n",
       "13   13               0.714286                       0.777778"
      ]
     },
     "execution_count": 41,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "random_forest_accuracy = accuracy_score_random_forest(df)\n",
    "random_forest_accuracy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>week</th>\n",
       "      <th>Logistic Regression Accuracy - Unscaled</th>\n",
       "      <th>Logistic Regeression Accuracy - Scaled</th>\n",
       "      <th>Log Reg - Unscaled - drop 40% to 60%</th>\n",
       "      <th>Log Reg - Scaled - drop 40% to 60%</th>\n",
       "      <th>Tensorflow Accuracy - Unscaled</th>\n",
       "      <th>Random Forest Accuracy</th>\n",
       "      <th>Random Forest - drop 40% - 60%</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>3</td>\n",
       "      <td>0.6</td>\n",
       "      <td>0.533333</td>\n",
       "      <td>0.571429</td>\n",
       "      <td>0.625</td>\n",
       "      <td>0.466667</td>\n",
       "      <td>0.6</td>\n",
       "      <td>0.75</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>4</td>\n",
       "      <td>0.625</td>\n",
       "      <td>0.6875</td>\n",
       "      <td>0.666667</td>\n",
       "      <td>0.692308</td>\n",
       "      <td>0.5</td>\n",
       "      <td>0.625</td>\n",
       "      <td>0.666667</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>5</td>\n",
       "      <td>0.5</td>\n",
       "      <td>0.625</td>\n",
       "      <td>0.466667</td>\n",
       "      <td>0.666667</td>\n",
       "      <td>0.6875</td>\n",
       "      <td>0.625</td>\n",
       "      <td>0.8</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>6</td>\n",
       "      <td>0.857143</td>\n",
       "      <td>0.857143</td>\n",
       "      <td>0.846154</td>\n",
       "      <td>0.909091</td>\n",
       "      <td>0.785714</td>\n",
       "      <td>0.785714</td>\n",
       "      <td>0.833333</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>7</td>\n",
       "      <td>0.769231</td>\n",
       "      <td>0.769231</td>\n",
       "      <td>0.75</td>\n",
       "      <td>0.8</td>\n",
       "      <td>0.692308</td>\n",
       "      <td>0.846154</td>\n",
       "      <td>0.8</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>8</td>\n",
       "      <td>0.466667</td>\n",
       "      <td>0.466667</td>\n",
       "      <td>0.5</td>\n",
       "      <td>0.466667</td>\n",
       "      <td>0.666667</td>\n",
       "      <td>0.6</td>\n",
       "      <td>0.583333</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>9</td>\n",
       "      <td>0.642857</td>\n",
       "      <td>0.714286</td>\n",
       "      <td>0.6</td>\n",
       "      <td>0.636364</td>\n",
       "      <td>0.714286</td>\n",
       "      <td>0.642857</td>\n",
       "      <td>0.6</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>10</td>\n",
       "      <td>0.5</td>\n",
       "      <td>0.5</td>\n",
       "      <td>0.5</td>\n",
       "      <td>0.538462</td>\n",
       "      <td>0.714286</td>\n",
       "      <td>0.5</td>\n",
       "      <td>0.555556</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>11</td>\n",
       "      <td>0.666667</td>\n",
       "      <td>0.6</td>\n",
       "      <td>0.777778</td>\n",
       "      <td>0.777778</td>\n",
       "      <td>0.6</td>\n",
       "      <td>0.8</td>\n",
       "      <td>0.7</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>12</td>\n",
       "      <td>0.733333</td>\n",
       "      <td>0.6</td>\n",
       "      <td>0.8</td>\n",
       "      <td>0.714286</td>\n",
       "      <td>0.466667</td>\n",
       "      <td>0.466667</td>\n",
       "      <td>0.636364</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>13</td>\n",
       "      <td>0.571429</td>\n",
       "      <td>0.571429</td>\n",
       "      <td>0.6</td>\n",
       "      <td>0.6</td>\n",
       "      <td>0.571429</td>\n",
       "      <td>0.714286</td>\n",
       "      <td>0.777778</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   week Logistic Regression Accuracy - Unscaled  \\\n",
       "3     3                                     0.6   \n",
       "4     4                                   0.625   \n",
       "5     5                                     0.5   \n",
       "6     6                                0.857143   \n",
       "7     7                                0.769231   \n",
       "8     8                                0.466667   \n",
       "9     9                                0.642857   \n",
       "10   10                                     0.5   \n",
       "11   11                                0.666667   \n",
       "12   12                                0.733333   \n",
       "13   13                                0.571429   \n",
       "\n",
       "   Logistic Regeression Accuracy - Scaled  \\\n",
       "3                                0.533333   \n",
       "4                                  0.6875   \n",
       "5                                   0.625   \n",
       "6                                0.857143   \n",
       "7                                0.769231   \n",
       "8                                0.466667   \n",
       "9                                0.714286   \n",
       "10                                    0.5   \n",
       "11                                    0.6   \n",
       "12                                    0.6   \n",
       "13                               0.571429   \n",
       "\n",
       "   Log Reg - Unscaled - drop 40% to 60% Log Reg - Scaled - drop 40% to 60%  \\\n",
       "3                              0.571429                              0.625   \n",
       "4                              0.666667                           0.692308   \n",
       "5                              0.466667                           0.666667   \n",
       "6                              0.846154                           0.909091   \n",
       "7                                  0.75                                0.8   \n",
       "8                                   0.5                           0.466667   \n",
       "9                                   0.6                           0.636364   \n",
       "10                                  0.5                           0.538462   \n",
       "11                             0.777778                           0.777778   \n",
       "12                                  0.8                           0.714286   \n",
       "13                                  0.6                                0.6   \n",
       "\n",
       "   Tensorflow Accuracy - Unscaled Random Forest Accuracy  \\\n",
       "3                        0.466667                    0.6   \n",
       "4                             0.5                  0.625   \n",
       "5                          0.6875                  0.625   \n",
       "6                        0.785714               0.785714   \n",
       "7                        0.692308               0.846154   \n",
       "8                        0.666667                    0.6   \n",
       "9                        0.714286               0.642857   \n",
       "10                       0.714286                    0.5   \n",
       "11                            0.6                    0.8   \n",
       "12                       0.466667               0.466667   \n",
       "13                       0.571429               0.714286   \n",
       "\n",
       "   Random Forest - drop 40% - 60%  \n",
       "3                            0.75  \n",
       "4                        0.666667  \n",
       "5                             0.8  \n",
       "6                        0.833333  \n",
       "7                             0.8  \n",
       "8                        0.583333  \n",
       "9                             0.6  \n",
       "10                       0.555556  \n",
       "11                            0.7  \n",
       "12                       0.636364  \n",
       "13                       0.777778  "
      ]
     },
     "execution_count": 42,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "accuracy_df = pd.concat(\n",
    "    [logistic_regression_accuracy, \n",
    "     tensorflow_accuracy.drop(columns=['week']),\n",
    "     random_forest_accuracy.drop(columns=['week'])], \n",
    "    axis=1)\n",
    "\n",
    "accuracy_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [],
   "source": [
    "accuracy_df.to_csv('Resources/accuracy_df.csv')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Model Plots"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [
    {
     "data": {},
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.holoviews_exec.v0+json": "",
      "text/html": [
       "<div id='5171'>\n",
       "\n",
       "\n",
       "\n",
       "\n",
       "\n",
       "  <div class=\"bk-root\" id=\"1730e070-6324-49a0-9477-7faf8e2538c1\" data-root-id=\"5171\"></div>\n",
       "</div>\n",
       "<script type=\"application/javascript\">(function(root) {\n",
       "  function embed_document(root) {\n",
       "    var docs_json = {\"153614c9-8106-4f6c-b3ee-ec7941c69367\":{\"defs\":[{\"extends\":null,\"module\":null,\"name\":\"ReactiveHTML1\",\"overrides\":[],\"properties\":[]},{\"extends\":null,\"module\":null,\"name\":\"FlexBox1\",\"overrides\":[],\"properties\":[{\"default\":\"flex-start\",\"kind\":null,\"name\":\"align_content\"},{\"default\":\"flex-start\",\"kind\":null,\"name\":\"align_items\"},{\"default\":\"row\",\"kind\":null,\"name\":\"flex_direction\"},{\"default\":\"wrap\",\"kind\":null,\"name\":\"flex_wrap\"},{\"default\":\"flex-start\",\"kind\":null,\"name\":\"justify_content\"}]},{\"extends\":null,\"module\":null,\"name\":\"TemplateActions1\",\"overrides\":[],\"properties\":[{\"default\":0,\"kind\":null,\"name\":\"open_modal\"},{\"default\":0,\"kind\":null,\"name\":\"close_modal\"}]},{\"extends\":null,\"module\":null,\"name\":\"MaterialTemplateActions1\",\"overrides\":[],\"properties\":[{\"default\":0,\"kind\":null,\"name\":\"open_modal\"},{\"default\":0,\"kind\":null,\"name\":\"close_modal\"}]}],\"roots\":{\"references\":[{\"attributes\":{\"below\":[{\"id\":\"5188\"}],\"center\":[{\"id\":\"5191\"},{\"id\":\"5195\"}],\"frame_height\":400,\"frame_width\":1000,\"height\":null,\"left\":[{\"id\":\"5192\"}],\"margin\":[5,5,5,5],\"min_border_bottom\":10,\"min_border_left\":10,\"min_border_right\":10,\"min_border_top\":10,\"renderers\":[{\"id\":\"5226\"},{\"id\":\"5246\"},{\"id\":\"5267\"},{\"id\":\"5290\"}],\"right\":[{\"id\":\"5237\"}],\"sizing_mode\":\"fixed\",\"title\":{\"id\":\"5180\"},\"toolbar\":{\"id\":\"5202\"},\"width\":null,\"x_range\":{\"id\":\"5173\"},\"x_scale\":{\"id\":\"5184\"},\"y_range\":{\"id\":\"5174\"},\"y_scale\":{\"id\":\"5186\"}},\"id\":\"5179\",\"subtype\":\"Figure\",\"type\":\"Plot\"},{\"attributes\":{\"line_color\":\"#30a2da\",\"line_width\":2,\"x\":{\"field\":\"week\"},\"y\":{\"field\":\"value\"}},\"id\":\"5223\",\"type\":\"Line\"},{\"attributes\":{\"line_alpha\":0.1,\"line_color\":\"#30a2da\",\"line_width\":2,\"x\":{\"field\":\"week\"},\"y\":{\"field\":\"value\"}},\"id\":\"5224\",\"type\":\"Line\"},{\"attributes\":{\"axis\":{\"id\":\"5192\"},\"dimension\":1,\"ticker\":{\"id\":\"5193\"}},\"id\":\"5195\",\"type\":\"Grid\"},{\"attributes\":{},\"id\":\"5257\",\"type\":\"UnionRenderers\"},{\"attributes\":{\"label\":{\"value\":\"Logistic Regeression Accuracy - Scaled\"},\"renderers\":[{\"id\":\"5246\"}]},\"id\":\"5259\",\"type\":\"LegendItem\"},{\"attributes\":{\"data\":{\"Variable\":[\"Logistic Regeression Accuracy - Scaled\",\"Logistic Regeression Accuracy - Scaled\",\"Logistic Regeression Accuracy - Scaled\",\"Logistic Regeression Accuracy - Scaled\",\"Logistic Regeression Accuracy - Scaled\",\"Logistic Regeression Accuracy - Scaled\",\"Logistic Regeression Accuracy - Scaled\",\"Logistic Regeression Accuracy - Scaled\",\"Logistic Regeression Accuracy - Scaled\",\"Logistic Regeression Accuracy - Scaled\",\"Logistic Regeression Accuracy - Scaled\"],\"value\":{\"__ndarray__\":\"ERERERER4T8AAAAAAADmPwAAAAAAAOQ/27Zt27Zt6z/ZiZ3YiZ3oP97d3d3d3d0/t23btm3b5j8AAAAAAADgPzMzMzMzM+M/MzMzMzMz4z+SJEmSJEniPw==\",\"dtype\":\"float64\",\"order\":\"little\",\"shape\":[11]},\"week\":[3,4,5,6,7,8,9,10,11,12,13]},\"selected\":{\"id\":\"5241\"},\"selection_policy\":{\"id\":\"5257\"}},\"id\":\"5240\",\"type\":\"ColumnDataSource\"},{\"attributes\":{},\"id\":\"5186\",\"type\":\"LinearScale\"},{\"attributes\":{\"line_alpha\":0.2,\"line_color\":\"#e5ae38\",\"line_width\":2,\"x\":{\"field\":\"week\"},\"y\":{\"field\":\"value\"}},\"id\":\"5266\",\"type\":\"Line\"},{\"attributes\":{},\"id\":\"5235\",\"type\":\"UnionRenderers\"},{\"attributes\":{\"line_color\":\"#fc4f30\",\"line_width\":2,\"x\":{\"field\":\"week\"},\"y\":{\"field\":\"value\"}},\"id\":\"5260\",\"type\":\"Line\"},{\"attributes\":{\"label\":{\"value\":\"Tensorflow Accuracy - Unscaled\"},\"renderers\":[{\"id\":\"5267\"}]},\"id\":\"5282\",\"type\":\"LegendItem\"},{\"attributes\":{\"data_source\":{\"id\":\"5261\"},\"glyph\":{\"id\":\"5264\"},\"hover_glyph\":null,\"muted_glyph\":{\"id\":\"5266\"},\"nonselection_glyph\":{\"id\":\"5265\"},\"selection_glyph\":{\"id\":\"5283\"},\"view\":{\"id\":\"5268\"}},\"id\":\"5267\",\"type\":\"GlyphRenderer\"},{\"attributes\":{\"axis\":{\"id\":\"5188\"},\"ticker\":{\"id\":\"5189\"}},\"id\":\"5191\",\"type\":\"Grid\"},{\"attributes\":{},\"id\":\"5189\",\"type\":\"BasicTicker\"},{\"attributes\":{\"text\":\"Model Accuracy Comparison by Week\",\"text_color\":\"black\",\"text_font_size\":\"12pt\"},\"id\":\"5180\",\"type\":\"Title\"},{\"attributes\":{\"line_alpha\":0.1,\"line_color\":\"#e5ae38\",\"line_width\":2,\"x\":{\"field\":\"week\"},\"y\":{\"field\":\"value\"}},\"id\":\"5265\",\"type\":\"Line\"},{\"attributes\":{\"axis_label\":\"Week\",\"formatter\":{\"id\":\"5211\"},\"major_label_policy\":{\"id\":\"5210\"},\"ticker\":{\"id\":\"5189\"}},\"id\":\"5188\",\"type\":\"LinearAxis\"},{\"attributes\":{\"source\":{\"id\":\"5261\"}},\"id\":\"5268\",\"type\":\"CDSView\"},{\"attributes\":{\"callback\":null,\"renderers\":[{\"id\":\"5226\"},{\"id\":\"5246\"},{\"id\":\"5267\"},{\"id\":\"5290\"}],\"tags\":[\"hv_created\"],\"tooltips\":[[\"Variable\",\"@{Variable}\"],[\"week\",\"@{week}\"],[\"value\",\"@{value}\"]]},\"id\":\"5175\",\"type\":\"HoverTool\"},{\"attributes\":{\"line_color\":\"#e5ae38\",\"line_width\":2,\"x\":{\"field\":\"week\"},\"y\":{\"field\":\"value\"}},\"id\":\"5264\",\"type\":\"Line\"},{\"attributes\":{},\"id\":\"5193\",\"type\":\"BasicTicker\"},{\"attributes\":{\"axis_label\":\"Correct Prediction %\",\"formatter\":{\"id\":\"5209\"},\"major_label_policy\":{\"id\":\"5213\"},\"ticker\":{\"id\":\"5193\"}},\"id\":\"5192\",\"type\":\"LinearAxis\"},{\"attributes\":{\"data\":{\"Variable\":[\"Logistic Regression Accuracy - Unscaled\",\"Logistic Regression Accuracy - Unscaled\",\"Logistic Regression Accuracy - Unscaled\",\"Logistic Regression Accuracy - Unscaled\",\"Logistic Regression Accuracy - Unscaled\",\"Logistic Regression Accuracy - Unscaled\",\"Logistic Regression Accuracy - Unscaled\",\"Logistic Regression Accuracy - Unscaled\",\"Logistic Regression Accuracy - Unscaled\",\"Logistic Regression Accuracy - Unscaled\",\"Logistic Regression Accuracy - Unscaled\"],\"value\":{\"__ndarray__\":\"MzMzMzMz4z8AAAAAAADkPwAAAAAAAOA/27Zt27Zt6z/ZiZ3YiZ3oP97d3d3d3d0/JUmSJEmS5D8AAAAAAADgP1VVVVVVVeU/d3d3d3d35z+SJEmSJEniPw==\",\"dtype\":\"float64\",\"order\":\"little\",\"shape\":[11]},\"week\":[3,4,5,6,7,8,9,10,11,12,13]},\"selected\":{\"id\":\"5221\"},\"selection_policy\":{\"id\":\"5235\"}},\"id\":\"5220\",\"type\":\"ColumnDataSource\"},{\"attributes\":{},\"id\":\"5213\",\"type\":\"AllLabels\"},{\"attributes\":{\"format\":\"%.2f\"},\"id\":\"5209\",\"type\":\"PrintfTickFormatter\"},{\"attributes\":{\"line_color\":\"#6d904f\",\"line_width\":2,\"x\":{\"field\":\"week\"},\"y\":{\"field\":\"value\"}},\"id\":\"5308\",\"type\":\"Line\"},{\"attributes\":{},\"id\":\"5221\",\"type\":\"Selection\"},{\"attributes\":{\"end\":13.0,\"reset_end\":13.0,\"reset_start\":3.0,\"start\":3.0,\"tags\":[[[\"week\",\"week\",null]]]},\"id\":\"5173\",\"type\":\"Range1d\"},{\"attributes\":{\"data_source\":{\"id\":\"5220\"},\"glyph\":{\"id\":\"5223\"},\"hover_glyph\":null,\"muted_glyph\":{\"id\":\"5225\"},\"nonselection_glyph\":{\"id\":\"5224\"},\"selection_glyph\":{\"id\":\"5239\"},\"view\":{\"id\":\"5227\"}},\"id\":\"5226\",\"type\":\"GlyphRenderer\"},{\"attributes\":{},\"id\":\"5262\",\"type\":\"Selection\"},{\"attributes\":{\"active_multi\":null,\"tools\":[{\"id\":\"5175\"},{\"id\":\"5196\"},{\"id\":\"5197\"},{\"id\":\"5198\"},{\"id\":\"5199\"},{\"id\":\"5200\"}]},\"id\":\"5202\",\"type\":\"Toolbar\"},{\"attributes\":{},\"id\":\"5280\",\"type\":\"UnionRenderers\"},{\"attributes\":{},\"id\":\"5196\",\"type\":\"SaveTool\"},{\"attributes\":{},\"id\":\"5197\",\"type\":\"PanTool\"},{\"attributes\":{\"click_policy\":\"mute\",\"items\":[{\"id\":\"5238\"},{\"id\":\"5259\"},{\"id\":\"5282\"},{\"id\":\"5307\"}],\"location\":[0,0],\"title\":\"Variable\"},\"id\":\"5237\",\"type\":\"Legend\"},{\"attributes\":{},\"id\":\"5198\",\"type\":\"WheelZoomTool\"},{\"attributes\":{\"line_color\":\"#e5ae38\",\"line_width\":2,\"x\":{\"field\":\"week\"},\"y\":{\"field\":\"value\"}},\"id\":\"5283\",\"type\":\"Line\"},{\"attributes\":{\"data_source\":{\"id\":\"5284\"},\"glyph\":{\"id\":\"5287\"},\"hover_glyph\":null,\"muted_glyph\":{\"id\":\"5289\"},\"nonselection_glyph\":{\"id\":\"5288\"},\"selection_glyph\":{\"id\":\"5308\"},\"view\":{\"id\":\"5291\"}},\"id\":\"5290\",\"type\":\"GlyphRenderer\"},{\"attributes\":{\"overlay\":{\"id\":\"5201\"}},\"id\":\"5199\",\"type\":\"BoxZoomTool\"},{\"attributes\":{\"line_alpha\":0.2,\"line_color\":\"#30a2da\",\"line_width\":2,\"x\":{\"field\":\"week\"},\"y\":{\"field\":\"value\"}},\"id\":\"5225\",\"type\":\"Line\"},{\"attributes\":{},\"id\":\"5285\",\"type\":\"Selection\"},{\"attributes\":{},\"id\":\"5200\",\"type\":\"ResetTool\"},{\"attributes\":{\"line_alpha\":0.2,\"line_color\":\"#fc4f30\",\"line_width\":2,\"x\":{\"field\":\"week\"},\"y\":{\"field\":\"value\"}},\"id\":\"5245\",\"type\":\"Line\"},{\"attributes\":{\"line_color\":\"#30a2da\",\"line_width\":2,\"x\":{\"field\":\"week\"},\"y\":{\"field\":\"value\"}},\"id\":\"5239\",\"type\":\"Line\"},{\"attributes\":{\"data\":{\"Variable\":[\"Tensorflow Accuracy - Unscaled\",\"Tensorflow Accuracy - Unscaled\",\"Tensorflow Accuracy - Unscaled\",\"Tensorflow Accuracy - Unscaled\",\"Tensorflow Accuracy - Unscaled\",\"Tensorflow Accuracy - Unscaled\",\"Tensorflow Accuracy - Unscaled\",\"Tensorflow Accuracy - Unscaled\",\"Tensorflow Accuracy - Unscaled\",\"Tensorflow Accuracy - Unscaled\",\"Tensorflow Accuracy - Unscaled\"],\"value\":{\"__ndarray__\":\"AAAA4N3d3T8AAAAAAADgPwAAAAAAAOY/AAAAQJIk6T8AAACAYifmPwAAAGBVVeU/AAAAwG3b5j8AAADAbdvmPwAAAEAzM+M/AAAA4N3d3T8AAACgJEniPw==\",\"dtype\":\"float64\",\"order\":\"little\",\"shape\":[11]},\"week\":[3,4,5,6,7,8,9,10,11,12,13]},\"selected\":{\"id\":\"5262\"},\"selection_policy\":{\"id\":\"5280\"}},\"id\":\"5261\",\"type\":\"ColumnDataSource\"},{\"attributes\":{\"data\":{\"Variable\":[\"Random Forest Accuracy\",\"Random Forest Accuracy\",\"Random Forest Accuracy\",\"Random Forest Accuracy\",\"Random Forest Accuracy\",\"Random Forest Accuracy\",\"Random Forest Accuracy\",\"Random Forest Accuracy\",\"Random Forest Accuracy\",\"Random Forest Accuracy\",\"Random Forest Accuracy\"],\"value\":{\"__ndarray__\":\"MzMzMzMz4z8AAAAAAADkPwAAAAAAAOQ/SZIkSZIk6T87sRM7sRPrPzMzMzMzM+M/JUmSJEmS5D8AAAAAAADgP5qZmZmZmek/3t3d3d3d3T+3bdu2bdvmPw==\",\"dtype\":\"float64\",\"order\":\"little\",\"shape\":[11]},\"week\":[3,4,5,6,7,8,9,10,11,12,13]},\"selected\":{\"id\":\"5285\"},\"selection_policy\":{\"id\":\"5305\"}},\"id\":\"5284\",\"type\":\"ColumnDataSource\"},{\"attributes\":{\"line_color\":\"#6d904f\",\"line_width\":2,\"x\":{\"field\":\"week\"},\"y\":{\"field\":\"value\"}},\"id\":\"5287\",\"type\":\"Line\"},{\"attributes\":{},\"id\":\"5305\",\"type\":\"UnionRenderers\"},{\"attributes\":{\"source\":{\"id\":\"5220\"}},\"id\":\"5227\",\"type\":\"CDSView\"},{\"attributes\":{\"margin\":[5,5,5,5],\"name\":\"HSpacer10619\",\"sizing_mode\":\"stretch_width\"},\"id\":\"5172\",\"type\":\"Spacer\"},{\"attributes\":{\"line_alpha\":0.1,\"line_color\":\"#6d904f\",\"line_width\":2,\"x\":{\"field\":\"week\"},\"y\":{\"field\":\"value\"}},\"id\":\"5288\",\"type\":\"Line\"},{\"attributes\":{\"source\":{\"id\":\"5284\"}},\"id\":\"5291\",\"type\":\"CDSView\"},{\"attributes\":{\"line_alpha\":0.1,\"line_color\":\"#fc4f30\",\"line_width\":2,\"x\":{\"field\":\"week\"},\"y\":{\"field\":\"value\"}},\"id\":\"5244\",\"type\":\"Line\"},{\"attributes\":{},\"id\":\"5211\",\"type\":\"BasicTickFormatter\"},{\"attributes\":{\"source\":{\"id\":\"5240\"}},\"id\":\"5247\",\"type\":\"CDSView\"},{\"attributes\":{\"data_source\":{\"id\":\"5240\"},\"glyph\":{\"id\":\"5243\"},\"hover_glyph\":null,\"muted_glyph\":{\"id\":\"5245\"},\"nonselection_glyph\":{\"id\":\"5244\"},\"selection_glyph\":{\"id\":\"5260\"},\"view\":{\"id\":\"5247\"}},\"id\":\"5246\",\"type\":\"GlyphRenderer\"},{\"attributes\":{\"line_alpha\":0.2,\"line_color\":\"#6d904f\",\"line_width\":2,\"x\":{\"field\":\"week\"},\"y\":{\"field\":\"value\"}},\"id\":\"5289\",\"type\":\"Line\"},{\"attributes\":{\"end\":0.8961904761904761,\"reset_end\":0.8961904761904761,\"reset_start\":0.4276190476190476,\"start\":0.4276190476190476,\"tags\":[[[\"value\",\"value\",null]]]},\"id\":\"5174\",\"type\":\"Range1d\"},{\"attributes\":{\"label\":{\"value\":\"Random Forest Accuracy\"},\"renderers\":[{\"id\":\"5290\"}]},\"id\":\"5307\",\"type\":\"LegendItem\"},{\"attributes\":{\"label\":{\"value\":\"Logistic Regression Accuracy - Unscaled\"},\"renderers\":[{\"id\":\"5226\"}]},\"id\":\"5238\",\"type\":\"LegendItem\"},{\"attributes\":{},\"id\":\"5210\",\"type\":\"AllLabels\"},{\"attributes\":{\"children\":[{\"id\":\"5172\"},{\"id\":\"5179\"},{\"id\":\"5444\"}],\"margin\":[0,0,0,0],\"name\":\"Row10615\",\"tags\":[\"embedded\"]},\"id\":\"5171\",\"type\":\"Row\"},{\"attributes\":{\"line_color\":\"#fc4f30\",\"line_width\":2,\"x\":{\"field\":\"week\"},\"y\":{\"field\":\"value\"}},\"id\":\"5243\",\"type\":\"Line\"},{\"attributes\":{\"bottom_units\":\"screen\",\"fill_alpha\":0.5,\"fill_color\":\"lightgrey\",\"left_units\":\"screen\",\"level\":\"overlay\",\"line_alpha\":1.0,\"line_color\":\"black\",\"line_dash\":[4,4],\"line_width\":2,\"right_units\":\"screen\",\"syncable\":false,\"top_units\":\"screen\"},\"id\":\"5201\",\"type\":\"BoxAnnotation\"},{\"attributes\":{\"margin\":[5,5,5,5],\"name\":\"HSpacer10620\",\"sizing_mode\":\"stretch_width\"},\"id\":\"5444\",\"type\":\"Spacer\"},{\"attributes\":{},\"id\":\"5184\",\"type\":\"LinearScale\"},{\"attributes\":{},\"id\":\"5241\",\"type\":\"Selection\"}],\"root_ids\":[\"5171\"]},\"title\":\"Bokeh Application\",\"version\":\"2.3.2\"}};\n",
       "    var render_items = [{\"docid\":\"153614c9-8106-4f6c-b3ee-ec7941c69367\",\"root_ids\":[\"5171\"],\"roots\":{\"5171\":\"1730e070-6324-49a0-9477-7faf8e2538c1\"}}];\n",
       "    root.Bokeh.embed.embed_items_notebook(docs_json, render_items);\n",
       "  }\n",
       "  if (root.Bokeh !== undefined && root.Bokeh.Panel !== undefined) {\n",
       "    embed_document(root);\n",
       "  } else {\n",
       "    var attempts = 0;\n",
       "    var timer = setInterval(function(root) {\n",
       "      if (root.Bokeh !== undefined && root.Bokeh.Panel !== undefined) {\n",
       "        clearInterval(timer);\n",
       "        embed_document(root);\n",
       "      } else if (document.readyState == \"complete\") {\n",
       "        attempts++;\n",
       "        if (attempts > 200) {\n",
       "          clearInterval(timer);\n",
       "          console.log(\"Bokeh: ERROR: Unable to run BokehJS code because BokehJS library is missing\");\n",
       "        }\n",
       "      }\n",
       "    }, 25, root)\n",
       "  }\n",
       "})(window);</script>"
      ],
      "text/plain": [
       ":NdOverlay   [Variable]\n",
       "   :Curve   [week]   (value)"
      ]
     },
     "execution_count": 60,
     "metadata": {
      "application/vnd.holoviews_exec.v0+json": {
       "id": "5171"
      }
     },
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Plot accuracy of all models without dropping any predictions.\n",
    "plot1 = accuracy_df.drop(columns=['Log Reg - Unscaled - drop 40% to 60%','Log Reg - Scaled - drop 40% to 60%','Random Forest - drop 40% - 60%'])\n",
    "plot1.hvplot(\n",
    "    x='week',\n",
    "    frame_height=400,\n",
    "    frame_width=1000,\n",
    "    grid=True,\n",
    "    xlabel='Week',\n",
    "    ylabel='Correct Prediction %',\n",
    "    yformatter='%.2f',\n",
    "    title='Model Accuracy Comparison by Week')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {},
   "outputs": [
    {
     "data": {},
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.holoviews_exec.v0+json": "",
      "text/html": [
       "<div id='6517'>\n",
       "\n",
       "\n",
       "\n",
       "\n",
       "\n",
       "  <div class=\"bk-root\" id=\"4a3e1da6-a5de-4319-ac33-a91bf21a863e\" data-root-id=\"6517\"></div>\n",
       "</div>\n",
       "<script type=\"application/javascript\">(function(root) {\n",
       "  function embed_document(root) {\n",
       "    var docs_json = {\"12600ebd-e742-4f85-9a56-fbc8e90fbf45\":{\"defs\":[{\"extends\":null,\"module\":null,\"name\":\"ReactiveHTML1\",\"overrides\":[],\"properties\":[]},{\"extends\":null,\"module\":null,\"name\":\"FlexBox1\",\"overrides\":[],\"properties\":[{\"default\":\"flex-start\",\"kind\":null,\"name\":\"align_content\"},{\"default\":\"flex-start\",\"kind\":null,\"name\":\"align_items\"},{\"default\":\"row\",\"kind\":null,\"name\":\"flex_direction\"},{\"default\":\"wrap\",\"kind\":null,\"name\":\"flex_wrap\"},{\"default\":\"flex-start\",\"kind\":null,\"name\":\"justify_content\"}]},{\"extends\":null,\"module\":null,\"name\":\"TemplateActions1\",\"overrides\":[],\"properties\":[{\"default\":0,\"kind\":null,\"name\":\"open_modal\"},{\"default\":0,\"kind\":null,\"name\":\"close_modal\"}]},{\"extends\":null,\"module\":null,\"name\":\"MaterialTemplateActions1\",\"overrides\":[],\"properties\":[{\"default\":0,\"kind\":null,\"name\":\"open_modal\"},{\"default\":0,\"kind\":null,\"name\":\"close_modal\"}]}],\"roots\":{\"references\":[{\"attributes\":{},\"id\":\"6542\",\"type\":\"PanTool\"},{\"attributes\":{\"line_color\":\"#e5ae38\",\"line_width\":2,\"x\":{\"field\":\"week\"},\"y\":{\"field\":\"value\"}},\"id\":\"6609\",\"type\":\"Line\"},{\"attributes\":{},\"id\":\"6529\",\"type\":\"LinearScale\"},{\"attributes\":{\"label\":{\"value\":\"Log Reg - Scaled - drop 40% to 60%\"},\"renderers\":[{\"id\":\"6591\"}]},\"id\":\"6604\",\"type\":\"LegendItem\"},{\"attributes\":{},\"id\":\"6543\",\"type\":\"WheelZoomTool\"},{\"attributes\":{\"below\":[{\"id\":\"6533\"}],\"center\":[{\"id\":\"6536\"},{\"id\":\"6540\"}],\"frame_height\":400,\"frame_width\":1000,\"height\":null,\"left\":[{\"id\":\"6537\"}],\"margin\":[5,5,5,5],\"min_border_bottom\":10,\"min_border_left\":10,\"min_border_right\":10,\"min_border_top\":10,\"renderers\":[{\"id\":\"6571\"},{\"id\":\"6591\"},{\"id\":\"6612\"}],\"right\":[{\"id\":\"6582\"}],\"sizing_mode\":\"fixed\",\"title\":{\"id\":\"6525\"},\"toolbar\":{\"id\":\"6547\"},\"width\":null,\"x_range\":{\"id\":\"6519\"},\"x_scale\":{\"id\":\"6529\"},\"y_range\":{\"id\":\"6520\"},\"y_scale\":{\"id\":\"6531\"}},\"id\":\"6524\",\"subtype\":\"Figure\",\"type\":\"Plot\"},{\"attributes\":{\"data\":{\"Variable\":[\"Log Reg - Unscaled - drop 40% to 60%\",\"Log Reg - Unscaled - drop 40% to 60%\",\"Log Reg - Unscaled - drop 40% to 60%\",\"Log Reg - Unscaled - drop 40% to 60%\",\"Log Reg - Unscaled - drop 40% to 60%\",\"Log Reg - Unscaled - drop 40% to 60%\",\"Log Reg - Unscaled - drop 40% to 60%\",\"Log Reg - Unscaled - drop 40% to 60%\",\"Log Reg - Unscaled - drop 40% to 60%\",\"Log Reg - Unscaled - drop 40% to 60%\",\"Log Reg - Unscaled - drop 40% to 60%\"],\"value\":{\"__ndarray__\":\"kiRJkiRJ4j9VVVVVVVXlP97d3d3d3d0/O7ETO7ET6z8AAAAAAADoPwAAAAAAAOA/MzMzMzMz4z8AAAAAAADgPzmO4ziO4+g/mpmZmZmZ6T8zMzMzMzPjPw==\",\"dtype\":\"float64\",\"order\":\"little\",\"shape\":[11]},\"week\":[3,4,5,6,7,8,9,10,11,12,13]},\"selected\":{\"id\":\"6566\"},\"selection_policy\":{\"id\":\"6580\"}},\"id\":\"6565\",\"type\":\"ColumnDataSource\"},{\"attributes\":{\"children\":[{\"id\":\"6518\"},{\"id\":\"6524\"},{\"id\":\"6746\"}],\"margin\":[0,0,0,0],\"name\":\"Row13492\",\"tags\":[\"embedded\"]},\"id\":\"6517\",\"type\":\"Row\"},{\"attributes\":{\"overlay\":{\"id\":\"6546\"}},\"id\":\"6544\",\"type\":\"BoxZoomTool\"},{\"attributes\":{\"line_alpha\":0.1,\"line_color\":\"#e5ae38\",\"line_width\":2,\"x\":{\"field\":\"week\"},\"y\":{\"field\":\"value\"}},\"id\":\"6610\",\"type\":\"Line\"},{\"attributes\":{\"text\":\"Model Accuracy Comparison by Week - Dropped < 60% confident games\",\"text_color\":\"black\",\"text_font_size\":\"12pt\"},\"id\":\"6525\",\"type\":\"Title\"},{\"attributes\":{\"line_color\":\"#e5ae38\",\"line_width\":2,\"x\":{\"field\":\"week\"},\"y\":{\"field\":\"value\"}},\"id\":\"6628\",\"type\":\"Line\"},{\"attributes\":{\"source\":{\"id\":\"6565\"}},\"id\":\"6572\",\"type\":\"CDSView\"},{\"attributes\":{\"data_source\":{\"id\":\"6585\"},\"glyph\":{\"id\":\"6588\"},\"hover_glyph\":null,\"muted_glyph\":{\"id\":\"6590\"},\"nonselection_glyph\":{\"id\":\"6589\"},\"selection_glyph\":{\"id\":\"6605\"},\"view\":{\"id\":\"6592\"}},\"id\":\"6591\",\"type\":\"GlyphRenderer\"},{\"attributes\":{\"axis\":{\"id\":\"6537\"},\"dimension\":1,\"ticker\":{\"id\":\"6538\"}},\"id\":\"6540\",\"type\":\"Grid\"},{\"attributes\":{\"data_source\":{\"id\":\"6606\"},\"glyph\":{\"id\":\"6609\"},\"hover_glyph\":null,\"muted_glyph\":{\"id\":\"6611\"},\"nonselection_glyph\":{\"id\":\"6610\"},\"selection_glyph\":{\"id\":\"6628\"},\"view\":{\"id\":\"6613\"}},\"id\":\"6612\",\"type\":\"GlyphRenderer\"},{\"attributes\":{},\"id\":\"6541\",\"type\":\"SaveTool\"},{\"attributes\":{},\"id\":\"6545\",\"type\":\"ResetTool\"},{\"attributes\":{\"line_color\":\"#30a2da\",\"line_width\":2,\"x\":{\"field\":\"week\"},\"y\":{\"field\":\"value\"}},\"id\":\"6584\",\"type\":\"Line\"},{\"attributes\":{},\"id\":\"6625\",\"type\":\"UnionRenderers\"},{\"attributes\":{\"callback\":null,\"renderers\":[{\"id\":\"6571\"},{\"id\":\"6591\"},{\"id\":\"6612\"}],\"tags\":[\"hv_created\"],\"tooltips\":[[\"Variable\",\"@{Variable}\"],[\"week\",\"@{week}\"],[\"value\",\"@{value}\"]]},\"id\":\"6521\",\"type\":\"HoverTool\"},{\"attributes\":{\"line_color\":\"#30a2da\",\"line_width\":2,\"x\":{\"field\":\"week\"},\"y\":{\"field\":\"value\"}},\"id\":\"6568\",\"type\":\"Line\"},{\"attributes\":{},\"id\":\"6556\",\"type\":\"BasicTickFormatter\"},{\"attributes\":{},\"id\":\"6586\",\"type\":\"Selection\"},{\"attributes\":{\"click_policy\":\"mute\",\"items\":[{\"id\":\"6583\"},{\"id\":\"6604\"},{\"id\":\"6627\"}],\"location\":[0,0],\"title\":\"Variable\"},\"id\":\"6582\",\"type\":\"Legend\"},{\"attributes\":{},\"id\":\"6531\",\"type\":\"LinearScale\"},{\"attributes\":{\"line_alpha\":0.2,\"line_color\":\"#fc4f30\",\"line_width\":2,\"x\":{\"field\":\"week\"},\"y\":{\"field\":\"value\"}},\"id\":\"6590\",\"type\":\"Line\"},{\"attributes\":{},\"id\":\"6534\",\"type\":\"BasicTicker\"},{\"attributes\":{\"data\":{\"Variable\":[\"Log Reg - Scaled - drop 40% to 60%\",\"Log Reg - Scaled - drop 40% to 60%\",\"Log Reg - Scaled - drop 40% to 60%\",\"Log Reg - Scaled - drop 40% to 60%\",\"Log Reg - Scaled - drop 40% to 60%\",\"Log Reg - Scaled - drop 40% to 60%\",\"Log Reg - Scaled - drop 40% to 60%\",\"Log Reg - Scaled - drop 40% to 60%\",\"Log Reg - Scaled - drop 40% to 60%\",\"Log Reg - Scaled - drop 40% to 60%\",\"Log Reg - Scaled - drop 40% to 60%\"],\"value\":{\"__ndarray__\":\"AAAAAAAA5D92Yid2YifmP1VVVVVVVeU/F1100UUX7T+amZmZmZnpP97d3d3d3d0/XXTRRRdd5D+xEzuxEzvhPzmO4ziO4+g/t23btm3b5j8zMzMzMzPjPw==\",\"dtype\":\"float64\",\"order\":\"little\",\"shape\":[11]},\"week\":[3,4,5,6,7,8,9,10,11,12,13]},\"selected\":{\"id\":\"6586\"},\"selection_policy\":{\"id\":\"6602\"}},\"id\":\"6585\",\"type\":\"ColumnDataSource\"},{\"attributes\":{\"source\":{\"id\":\"6585\"}},\"id\":\"6592\",\"type\":\"CDSView\"},{\"attributes\":{\"margin\":[5,5,5,5],\"name\":\"HSpacer13496\",\"sizing_mode\":\"stretch_width\"},\"id\":\"6518\",\"type\":\"Spacer\"},{\"attributes\":{\"axis_label\":\"Week\",\"formatter\":{\"id\":\"6556\"},\"major_label_policy\":{\"id\":\"6555\"},\"ticker\":{\"id\":\"6534\"}},\"id\":\"6533\",\"type\":\"LinearAxis\"},{\"attributes\":{},\"id\":\"6602\",\"type\":\"UnionRenderers\"},{\"attributes\":{\"data_source\":{\"id\":\"6565\"},\"glyph\":{\"id\":\"6568\"},\"hover_glyph\":null,\"muted_glyph\":{\"id\":\"6570\"},\"nonselection_glyph\":{\"id\":\"6569\"},\"selection_glyph\":{\"id\":\"6584\"},\"view\":{\"id\":\"6572\"}},\"id\":\"6571\",\"type\":\"GlyphRenderer\"},{\"attributes\":{\"line_alpha\":0.1,\"line_color\":\"#fc4f30\",\"line_width\":2,\"x\":{\"field\":\"week\"},\"y\":{\"field\":\"value\"}},\"id\":\"6589\",\"type\":\"Line\"},{\"attributes\":{\"axis\":{\"id\":\"6533\"},\"ticker\":{\"id\":\"6534\"}},\"id\":\"6536\",\"type\":\"Grid\"},{\"attributes\":{\"line_alpha\":0.1,\"line_color\":\"#30a2da\",\"line_width\":2,\"x\":{\"field\":\"week\"},\"y\":{\"field\":\"value\"}},\"id\":\"6569\",\"type\":\"Line\"},{\"attributes\":{\"line_alpha\":0.2,\"line_color\":\"#30a2da\",\"line_width\":2,\"x\":{\"field\":\"week\"},\"y\":{\"field\":\"value\"}},\"id\":\"6570\",\"type\":\"Line\"},{\"attributes\":{},\"id\":\"6607\",\"type\":\"Selection\"},{\"attributes\":{\"end\":0.9533333333333333,\"reset_end\":0.9533333333333333,\"reset_start\":0.4224242424242424,\"start\":0.4224242424242424,\"tags\":[[[\"value\",\"value\",null]]]},\"id\":\"6520\",\"type\":\"Range1d\"},{\"attributes\":{},\"id\":\"6538\",\"type\":\"BasicTicker\"},{\"attributes\":{\"axis_label\":\"Correct Prediction %\",\"formatter\":{\"id\":\"6554\"},\"major_label_policy\":{\"id\":\"6558\"},\"ticker\":{\"id\":\"6538\"}},\"id\":\"6537\",\"type\":\"LinearAxis\"},{\"attributes\":{\"data\":{\"Variable\":[\"Random Forest - drop 40% - 60%\",\"Random Forest - drop 40% - 60%\",\"Random Forest - drop 40% - 60%\",\"Random Forest - drop 40% - 60%\",\"Random Forest - drop 40% - 60%\",\"Random Forest - drop 40% - 60%\",\"Random Forest - drop 40% - 60%\",\"Random Forest - drop 40% - 60%\",\"Random Forest - drop 40% - 60%\",\"Random Forest - drop 40% - 60%\",\"Random Forest - drop 40% - 60%\"],\"value\":{\"__ndarray__\":\"AAAAAAAA6D9VVVVVVVXlP5qZmZmZmek/q6qqqqqq6j+amZmZmZnpP6uqqqqqquI/MzMzMzMz4z9yHMdxHMfhP2ZmZmZmZuY/XXTRRRdd5D85juM4juPoPw==\",\"dtype\":\"float64\",\"order\":\"little\",\"shape\":[11]},\"week\":[3,4,5,6,7,8,9,10,11,12,13]},\"selected\":{\"id\":\"6607\"},\"selection_policy\":{\"id\":\"6625\"}},\"id\":\"6606\",\"type\":\"ColumnDataSource\"},{\"attributes\":{\"line_color\":\"#fc4f30\",\"line_width\":2,\"x\":{\"field\":\"week\"},\"y\":{\"field\":\"value\"}},\"id\":\"6605\",\"type\":\"Line\"},{\"attributes\":{\"label\":{\"value\":\"Log Reg - Unscaled - drop 40% to 60%\"},\"renderers\":[{\"id\":\"6571\"}]},\"id\":\"6583\",\"type\":\"LegendItem\"},{\"attributes\":{\"source\":{\"id\":\"6606\"}},\"id\":\"6613\",\"type\":\"CDSView\"},{\"attributes\":{},\"id\":\"6580\",\"type\":\"UnionRenderers\"},{\"attributes\":{\"line_color\":\"#fc4f30\",\"line_width\":2,\"x\":{\"field\":\"week\"},\"y\":{\"field\":\"value\"}},\"id\":\"6588\",\"type\":\"Line\"},{\"attributes\":{},\"id\":\"6555\",\"type\":\"AllLabels\"},{\"attributes\":{},\"id\":\"6558\",\"type\":\"AllLabels\"},{\"attributes\":{\"line_alpha\":0.2,\"line_color\":\"#e5ae38\",\"line_width\":2,\"x\":{\"field\":\"week\"},\"y\":{\"field\":\"value\"}},\"id\":\"6611\",\"type\":\"Line\"},{\"attributes\":{\"bottom_units\":\"screen\",\"fill_alpha\":0.5,\"fill_color\":\"lightgrey\",\"left_units\":\"screen\",\"level\":\"overlay\",\"line_alpha\":1.0,\"line_color\":\"black\",\"line_dash\":[4,4],\"line_width\":2,\"right_units\":\"screen\",\"syncable\":false,\"top_units\":\"screen\"},\"id\":\"6546\",\"type\":\"BoxAnnotation\"},{\"attributes\":{\"label\":{\"value\":\"Random Forest - drop 40% - 60%\"},\"renderers\":[{\"id\":\"6612\"}]},\"id\":\"6627\",\"type\":\"LegendItem\"},{\"attributes\":{},\"id\":\"6566\",\"type\":\"Selection\"},{\"attributes\":{\"end\":13.0,\"reset_end\":13.0,\"reset_start\":3.0,\"start\":3.0,\"tags\":[[[\"week\",\"week\",null]]]},\"id\":\"6519\",\"type\":\"Range1d\"},{\"attributes\":{\"active_multi\":null,\"tools\":[{\"id\":\"6521\"},{\"id\":\"6541\"},{\"id\":\"6542\"},{\"id\":\"6543\"},{\"id\":\"6544\"},{\"id\":\"6545\"}]},\"id\":\"6547\",\"type\":\"Toolbar\"},{\"attributes\":{\"margin\":[5,5,5,5],\"name\":\"HSpacer13497\",\"sizing_mode\":\"stretch_width\"},\"id\":\"6746\",\"type\":\"Spacer\"},{\"attributes\":{\"format\":\"%.2f\"},\"id\":\"6554\",\"type\":\"PrintfTickFormatter\"}],\"root_ids\":[\"6517\"]},\"title\":\"Bokeh Application\",\"version\":\"2.3.2\"}};\n",
       "    var render_items = [{\"docid\":\"12600ebd-e742-4f85-9a56-fbc8e90fbf45\",\"root_ids\":[\"6517\"],\"roots\":{\"6517\":\"4a3e1da6-a5de-4319-ac33-a91bf21a863e\"}}];\n",
       "    root.Bokeh.embed.embed_items_notebook(docs_json, render_items);\n",
       "  }\n",
       "  if (root.Bokeh !== undefined && root.Bokeh.Panel !== undefined) {\n",
       "    embed_document(root);\n",
       "  } else {\n",
       "    var attempts = 0;\n",
       "    var timer = setInterval(function(root) {\n",
       "      if (root.Bokeh !== undefined && root.Bokeh.Panel !== undefined) {\n",
       "        clearInterval(timer);\n",
       "        embed_document(root);\n",
       "      } else if (document.readyState == \"complete\") {\n",
       "        attempts++;\n",
       "        if (attempts > 200) {\n",
       "          clearInterval(timer);\n",
       "          console.log(\"Bokeh: ERROR: Unable to run BokehJS code because BokehJS library is missing\");\n",
       "        }\n",
       "      }\n",
       "    }, 25, root)\n",
       "  }\n",
       "})(window);</script>"
      ],
      "text/plain": [
       ":NdOverlay   [Variable]\n",
       "   :Curve   [week]   (value)"
      ]
     },
     "execution_count": 66,
     "metadata": {
      "application/vnd.holoviews_exec.v0+json": {
       "id": "6517"
      }
     },
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Plot accuracy of all models with \"close\" gams dropped (60% or less confidence games)\n",
    "plot2 = accuracy_df[['week','Log Reg - Unscaled - drop 40% to 60%','Log Reg - Scaled - drop 40% to 60%','Random Forest - drop 40% - 60%']]\n",
    "plot2.hvplot(\n",
    "    x='week',\n",
    "    frame_height=400,\n",
    "    frame_width=1000,\n",
    "    grid=True,\n",
    "    xlabel='Week',\n",
    "    ylabel='Correct Prediction %',\n",
    "    yformatter='%.2f',\n",
    "    title='Model Accuracy Comparison by Week - Dropped < 60% confident games')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "metadata": {},
   "outputs": [
    {
     "data": {},
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.holoviews_exec.v0+json": "",
      "text/html": [
       "<div id='8279'>\n",
       "\n",
       "\n",
       "\n",
       "\n",
       "\n",
       "  <div class=\"bk-root\" id=\"93f8b036-0dca-43c4-a05a-c21cd47abe65\" data-root-id=\"8279\"></div>\n",
       "</div>\n",
       "<script type=\"application/javascript\">(function(root) {\n",
       "  function embed_document(root) {\n",
       "    var docs_json = {\"b489b4bb-ccb3-404d-9a19-b231b45c4938\":{\"defs\":[{\"extends\":null,\"module\":null,\"name\":\"ReactiveHTML1\",\"overrides\":[],\"properties\":[]},{\"extends\":null,\"module\":null,\"name\":\"FlexBox1\",\"overrides\":[],\"properties\":[{\"default\":\"flex-start\",\"kind\":null,\"name\":\"align_content\"},{\"default\":\"flex-start\",\"kind\":null,\"name\":\"align_items\"},{\"default\":\"row\",\"kind\":null,\"name\":\"flex_direction\"},{\"default\":\"wrap\",\"kind\":null,\"name\":\"flex_wrap\"},{\"default\":\"flex-start\",\"kind\":null,\"name\":\"justify_content\"}]},{\"extends\":null,\"module\":null,\"name\":\"TemplateActions1\",\"overrides\":[],\"properties\":[{\"default\":0,\"kind\":null,\"name\":\"open_modal\"},{\"default\":0,\"kind\":null,\"name\":\"close_modal\"}]},{\"extends\":null,\"module\":null,\"name\":\"MaterialTemplateActions1\",\"overrides\":[],\"properties\":[{\"default\":0,\"kind\":null,\"name\":\"open_modal\"},{\"default\":0,\"kind\":null,\"name\":\"close_modal\"}]}],\"roots\":{\"references\":[{\"attributes\":{\"bottom_units\":\"screen\",\"fill_alpha\":0.5,\"fill_color\":\"lightgrey\",\"left_units\":\"screen\",\"level\":\"overlay\",\"line_alpha\":1.0,\"line_color\":\"black\",\"line_dash\":[4,4],\"line_width\":2,\"right_units\":\"screen\",\"syncable\":false,\"top_units\":\"screen\"},\"id\":\"8305\",\"type\":\"BoxAnnotation\"},{\"attributes\":{},\"id\":\"8291\",\"type\":\"CategoricalScale\"},{\"attributes\":{\"axis_label\":\"\",\"formatter\":{\"id\":\"8326\"},\"major_label_policy\":{\"id\":\"8325\"},\"ticker\":{\"id\":\"8298\"}},\"id\":\"8297\",\"type\":\"CategoricalAxis\"},{\"attributes\":{},\"id\":\"8289\",\"type\":\"LinearScale\"},{\"attributes\":{\"below\":[{\"id\":\"8293\"}],\"center\":[{\"id\":\"8296\"},{\"id\":\"8299\"}],\"frame_width\":700,\"height\":300,\"left\":[{\"id\":\"8297\"}],\"margin\":[5,5,5,5],\"min_border_bottom\":10,\"min_border_left\":10,\"min_border_right\":10,\"min_border_top\":10,\"renderers\":[{\"id\":\"8319\"}],\"sizing_mode\":\"fixed\",\"title\":{\"id\":\"8285\"},\"toolbar\":{\"id\":\"8306\"},\"width\":null,\"x_range\":{\"id\":\"8281\"},\"x_scale\":{\"id\":\"8289\"},\"y_range\":{\"id\":\"8282\"},\"y_scale\":{\"id\":\"8291\"}},\"id\":\"8284\",\"subtype\":\"Figure\",\"type\":\"Plot\"},{\"attributes\":{},\"id\":\"8304\",\"type\":\"ResetTool\"},{\"attributes\":{\"fill_alpha\":{\"value\":1.0},\"fill_color\":{\"value\":\"#30a2da\"},\"hatch_alpha\":{\"value\":1.0},\"hatch_color\":{\"value\":\"black\"},\"hatch_scale\":{\"value\":12.0},\"hatch_weight\":{\"value\":1.0},\"height\":{\"value\":0.8},\"left\":{\"value\":0},\"line_alpha\":{\"value\":1.0},\"line_cap\":{\"value\":\"butt\"},\"line_color\":{\"value\":\"black\"},\"line_dash\":{\"value\":[]},\"line_dash_offset\":{\"value\":0},\"line_join\":{\"value\":\"bevel\"},\"line_width\":{\"value\":1},\"right\":{\"field\":\"A_0\"},\"y\":{\"field\":\"index\"}},\"id\":\"8321\",\"type\":\"HBar\"},{\"attributes\":{\"fill_alpha\":{\"value\":0.1},\"fill_color\":{\"value\":\"#30a2da\"},\"height\":{\"value\":0.8},\"line_alpha\":{\"value\":0.1},\"right\":{\"field\":\"A_0\"},\"y\":{\"field\":\"index\"}},\"id\":\"8317\",\"type\":\"HBar\"},{\"attributes\":{\"source\":{\"id\":\"8313\"}},\"id\":\"8320\",\"type\":\"CDSView\"},{\"attributes\":{\"data_source\":{\"id\":\"8313\"},\"glyph\":{\"id\":\"8316\"},\"hover_glyph\":null,\"muted_glyph\":{\"id\":\"8318\"},\"nonselection_glyph\":{\"id\":\"8317\"},\"selection_glyph\":{\"id\":\"8321\"},\"view\":{\"id\":\"8320\"}},\"id\":\"8319\",\"type\":\"GlyphRenderer\"},{\"attributes\":{},\"id\":\"8301\",\"type\":\"PanTool\"},{\"attributes\":{\"fill_color\":{\"value\":\"#30a2da\"},\"height\":{\"value\":0.8},\"right\":{\"field\":\"A_0\"},\"y\":{\"field\":\"index\"}},\"id\":\"8316\",\"type\":\"HBar\"},{\"attributes\":{},\"id\":\"8338\",\"type\":\"UnionRenderers\"},{\"attributes\":{},\"id\":\"8322\",\"type\":\"AllLabels\"},{\"attributes\":{\"children\":[{\"id\":\"8280\"},{\"id\":\"8284\"},{\"id\":\"8350\"}],\"margin\":[0,0,0,0],\"name\":\"Row16128\",\"tags\":[\"embedded\"]},\"id\":\"8279\",\"type\":\"Row\"},{\"attributes\":{\"margin\":[5,5,5,5],\"name\":\"HSpacer16132\",\"sizing_mode\":\"stretch_width\"},\"id\":\"8280\",\"type\":\"Spacer\"},{\"attributes\":{},\"id\":\"8323\",\"type\":\"BasicTickFormatter\"},{\"attributes\":{},\"id\":\"8325\",\"type\":\"AllLabels\"},{\"attributes\":{\"axis_label\":\"\",\"formatter\":{\"id\":\"8323\"},\"major_label_policy\":{\"id\":\"8322\"},\"ticker\":{\"id\":\"8294\"}},\"id\":\"8293\",\"type\":\"LinearAxis\"},{\"attributes\":{},\"id\":\"8302\",\"type\":\"WheelZoomTool\"},{\"attributes\":{\"margin\":[5,5,5,5],\"name\":\"HSpacer16133\",\"sizing_mode\":\"stretch_width\"},\"id\":\"8350\",\"type\":\"Spacer\"},{\"attributes\":{\"active_multi\":null,\"tools\":[{\"id\":\"8283\"},{\"id\":\"8300\"},{\"id\":\"8301\"},{\"id\":\"8302\"},{\"id\":\"8303\"},{\"id\":\"8304\"}]},\"id\":\"8306\",\"type\":\"Toolbar\"},{\"attributes\":{},\"id\":\"8326\",\"type\":\"CategoricalTickFormatter\"},{\"attributes\":{},\"id\":\"8300\",\"type\":\"SaveTool\"},{\"attributes\":{\"data\":{\"A_0\":{\"__ndarray__\":\"IFS2NrEq5D+r1sfx7STkP8HgUTWyl+Q/sQdokc6a5T+MLroI8fjjPwdbU8FD9uQ/rw25IKho5j8=\",\"dtype\":\"float64\",\"order\":\"little\",\"shape\":[7]},\"index\":[\"Logistic Regression Accuracy - Unscaled\",\"Logistic Regeression Accuracy - Scaled\",\"Log Reg - Unscaled - drop 40% to 60%\",\"Log Reg - Scaled - drop 40% to 60%\",\"Tensorflow Accuracy - Unscaled\",\"Random Forest Accuracy\",\"Random Forest - drop 40% - 60%\"]},\"selected\":{\"id\":\"8314\"},\"selection_policy\":{\"id\":\"8338\"}},\"id\":\"8313\",\"type\":\"ColumnDataSource\"},{\"attributes\":{\"factors\":[\"Logistic Regression Accuracy - Unscaled\",\"Logistic Regeression Accuracy - Scaled\",\"Log Reg - Unscaled - drop 40% to 60%\",\"Log Reg - Scaled - drop 40% to 60%\",\"Tensorflow Accuracy - Unscaled\",\"Random Forest Accuracy\",\"Random Forest - drop 40% - 60%\"],\"tags\":[[[\"index\",\"index\",null]]]},\"id\":\"8282\",\"type\":\"FactorRange\"},{\"attributes\":{\"axis\":{\"id\":\"8293\"},\"ticker\":{\"id\":\"8294\"}},\"id\":\"8296\",\"type\":\"Grid\"},{\"attributes\":{\"overlay\":{\"id\":\"8305\"}},\"id\":\"8303\",\"type\":\"BoxZoomTool\"},{\"attributes\":{\"reset_end\":1.0,\"reset_start\":0,\"tags\":[[[\"0\",\"0\",null]]]},\"id\":\"8281\",\"type\":\"Range1d\"},{\"attributes\":{},\"id\":\"8314\",\"type\":\"Selection\"},{\"attributes\":{\"axis\":{\"id\":\"8297\"},\"dimension\":1,\"ticker\":{\"id\":\"8298\"}},\"id\":\"8299\",\"type\":\"Grid\"},{\"attributes\":{},\"id\":\"8294\",\"type\":\"BasicTicker\"},{\"attributes\":{\"fill_alpha\":{\"value\":0.2},\"fill_color\":{\"value\":\"#30a2da\"},\"height\":{\"value\":0.8},\"line_alpha\":{\"value\":0.2},\"right\":{\"field\":\"A_0\"},\"y\":{\"field\":\"index\"}},\"id\":\"8318\",\"type\":\"HBar\"},{\"attributes\":{\"callback\":null,\"renderers\":[{\"id\":\"8319\"}],\"tags\":[\"hv_created\"],\"tooltips\":[[\"index\",\"@{index}\"],[\"0\",\"@{A_0}\"]]},\"id\":\"8283\",\"type\":\"HoverTool\"},{\"attributes\":{\"text\":\"All Model Predictions - Average Accuracy up to Week 13\",\"text_color\":\"black\",\"text_font_size\":\"12pt\"},\"id\":\"8285\",\"type\":\"Title\"},{\"attributes\":{},\"id\":\"8298\",\"type\":\"CategoricalTicker\"}],\"root_ids\":[\"8279\"]},\"title\":\"Bokeh Application\",\"version\":\"2.3.2\"}};\n",
       "    var render_items = [{\"docid\":\"b489b4bb-ccb3-404d-9a19-b231b45c4938\",\"root_ids\":[\"8279\"],\"roots\":{\"8279\":\"93f8b036-0dca-43c4-a05a-c21cd47abe65\"}}];\n",
       "    root.Bokeh.embed.embed_items_notebook(docs_json, render_items);\n",
       "  }\n",
       "  if (root.Bokeh !== undefined && root.Bokeh.Panel !== undefined) {\n",
       "    embed_document(root);\n",
       "  } else {\n",
       "    var attempts = 0;\n",
       "    var timer = setInterval(function(root) {\n",
       "      if (root.Bokeh !== undefined && root.Bokeh.Panel !== undefined) {\n",
       "        clearInterval(timer);\n",
       "        embed_document(root);\n",
       "      } else if (document.readyState == \"complete\") {\n",
       "        attempts++;\n",
       "        if (attempts > 200) {\n",
       "          clearInterval(timer);\n",
       "          console.log(\"Bokeh: ERROR: Unable to run BokehJS code because BokehJS library is missing\");\n",
       "        }\n",
       "      }\n",
       "    }, 25, root)\n",
       "  }\n",
       "})(window);</script>"
      ],
      "text/plain": [
       ":Bars   [index]   (0)"
      ]
     },
     "execution_count": 88,
     "metadata": {
      "application/vnd.holoviews_exec.v0+json": {
       "id": "8279"
      }
     },
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Plot all model iterations average over the season thus far.\n",
    "plot3 = accuracy_df.mean(axis=0)\n",
    "plot3 = plot3.drop(index='week')\n",
    "y_lim=list([0,1.0])\n",
    "plot3.hvplot.bar(\n",
    "    invert=True,\n",
    "    grid=True,\n",
    "    ylim=y_lim,\n",
    "    title='All Model Predictions - Average Accuracy up to Week 13',\n",
    "    frame_width=700)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 89,
   "metadata": {},
   "outputs": [
    {
     "ename": "SyntaxError",
     "evalue": "invalid syntax (<ipython-input-89-6920a75e6989>, line 4)",
     "output_type": "error",
     "traceback": [
      "\u001b[0;36m  File \u001b[0;32m\"<ipython-input-89-6920a75e6989>\"\u001b[0;36m, line \u001b[0;32m4\u001b[0m\n\u001b[0;31m    <div class='tableauPlaceholder' id='viz1638998595666' style='position: relative'><noscript><a href='#'><img alt=' ' src='https:&#47;&#47;public.tableau.com&#47;static&#47;images&#47;NF&#47;NFLPredictionModelAccuracy&#47;NFLPredictionModelAccuracy&#47;1_rss.png' style='border: none' /></a></noscript><object class='tableauViz'  style='display:none;'><param name='host_url' value='https%3A%2F%2Fpublic.tableau.com%2F' /> <param name='embed_code_version' value='3' /> <param name='site_root' value='' /><param name='name' value='NFLPredictionModelAccuracy&#47;NFLPredictionModelAccuracy' /><param name='tabs' value='yes' /><param name='toolbar' value='yes' /><param name='static_image' value='https:&#47;&#47;public.tableau.com&#47;static&#47;images&#47;NF&#47;NFLPredictionModelAccuracy&#47;NFLPredictionModelAccuracy&#47;1.png' /> <param name='animate_transition' value='yes' /><param name='display_static_image' value='yes' /><param name='display_spinner' value='yes' /><param name='display_overlay' value='yes' /><param name='display_count' value='yes' /><param name='language' value='en-US' /><param name='filter' value='publish=yes' /></object></div>                <script type='text/javascript'>                    var divElement = document.getElementById('viz1638998595666');                    var vizElement = divElement.getElementsByTagName('object')[0];                    if ( divElement.offsetWidth > 800 ) { vizElement.style.minWidth='800px';vizElement.style.maxWidth='100%';vizElement.style.minHeight='1250px';vizElement.style.maxHeight=(divElement.offsetWidth*0.75)+'px';} else if ( divElement.offsetWidth > 500 ) { vizElement.style.minWidth='800px';vizElement.style.maxWidth='100%';vizElement.style.minHeight='1250px';vizElement.style.maxHeight=(divElement.offsetWidth*0.75)+'px';} else { vizElement.style.width='100%';vizElement.style.minHeight='800px';vizElement.style.maxHeight=(divElement.offsetWidth*1.77)+'px';}                     var scriptElement = document.createElement('script');                    scriptElement.src = 'https://public.tableau.com/javascripts/api/viz_v1.js';                    vizElement.parentNode.insertBefore(scriptElement, vizElement);                </script>\u001b[0m\n\u001b[0m    ^\u001b[0m\n\u001b[0;31mSyntaxError\u001b[0m\u001b[0;31m:\u001b[0m invalid syntax\n"
     ]
    }
   ],
   "source": [
    "# Tableau interactive chart showing all weekly model accuracy. \n",
    "# Currently broken\n",
    "\n",
    "%%HTML\n",
    "<div class='tableauPlaceholder' id='viz1638998595666' style='position: relative'><noscript><a href='#'><img alt=' ' src='https:&#47;&#47;public.tableau.com&#47;static&#47;images&#47;NF&#47;NFLPredictionModelAccuracy&#47;NFLPredictionModelAccuracy&#47;1_rss.png' style='border: none' /></a></noscript><object class='tableauViz'  style='display:none;'><param name='host_url' value='https%3A%2F%2Fpublic.tableau.com%2F' /> <param name='embed_code_version' value='3' /> <param name='site_root' value='' /><param name='name' value='NFLPredictionModelAccuracy&#47;NFLPredictionModelAccuracy' /><param name='tabs' value='yes' /><param name='toolbar' value='yes' /><param name='static_image' value='https:&#47;&#47;public.tableau.com&#47;static&#47;images&#47;NF&#47;NFLPredictionModelAccuracy&#47;NFLPredictionModelAccuracy&#47;1.png' /> <param name='animate_transition' value='yes' /><param name='display_static_image' value='yes' /><param name='display_spinner' value='yes' /><param name='display_overlay' value='yes' /><param name='display_count' value='yes' /><param name='language' value='en-US' /><param name='filter' value='publish=yes' /></object></div>                <script type='text/javascript'>                    var divElement = document.getElementById('viz1638998595666');                    var vizElement = divElement.getElementsByTagName('object')[0];                    if ( divElement.offsetWidth > 800 ) { vizElement.style.minWidth='800px';vizElement.style.maxWidth='100%';vizElement.style.minHeight='1250px';vizElement.style.maxHeight=(divElement.offsetWidth*0.75)+'px';} else if ( divElement.offsetWidth > 500 ) { vizElement.style.minWidth='800px';vizElement.style.maxWidth='100%';vizElement.style.minHeight='1250px';vizElement.style.maxHeight=(divElement.offsetWidth*0.75)+'px';} else { vizElement.style.width='100%';vizElement.style.minHeight='800px';vizElement.style.maxHeight=(divElement.offsetWidth*1.77)+'px';}                     var scriptElement = document.createElement('script');                    scriptElement.src = 'https://public.tableau.com/javascripts/api/viz_v1.js';                    vizElement.parentNode.insertBefore(scriptElement, vizElement);                </script>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
